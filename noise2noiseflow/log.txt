nohup: ignoring input
13:19:55 | INFO | Logging initialized (level=INFO)
13:19:55 | INFO | Seed set to 0 | device=cuda | n_bins=1024
13:19:55 | WARNING | Removed existing logdir /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/ due to --no_resume
13:19:55 | INFO | Experiment artifacts will be saved under /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/
13:19:55 | INFO | Initialized train dataset at ./data/train with 12000 scenes (patches per image=1)
13:19:55 | INFO | Initialized val dataset at ./data/val with 4000 scenes (patches per image=1)
13:19:55 | INFO | Initialized eval dataset at ./data/val with 4000 scenes (patches per image=1)
13:19:55 | INFO | Custom loaders ready | train=12000 (patches=12000) | val=4000 | test=4000 | batch=8/8
13:19:55 | INFO | Skipping SIDD baseline stats for custom dataset
13:19:55 | INFO | Model ready | total params=262761 | flow=1449 | denoiser=261312 | pretrained=False
13:19:55 | INFO | No checkpoint found in /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models; starting fresh
13:19:55 | INFO | Result loggers and TensorBoard writer initialized at epoch 1
13:19:55 | INFO | Epoch 1 started | validation=True
13:19:55 | INFO | Epoch 1 | train | batches=1500
13:20:13 | INFO | Epoch 1 | train batch 300/1500 | loss=-3.1769 | nll=-3.2934 | mse=0.0000
13:20:33 | INFO | Epoch 1 | train batch 600/1500 | loss=-6.1568 | nll=-6.2621 | mse=0.0000
13:20:51 | INFO | Epoch 1 | train batch 900/1500 | loss=-7.0448 | nll=-7.1538 | mse=0.0000
13:21:11 | INFO | Epoch 1 | train batch 1200/1500 | loss=-8.0189 | nll=-8.1742 | mse=0.0000
13:21:28 | INFO | Epoch 1 | train batch 1500/1500 | loss=-8.8172 | nll=-8.9734 | mse=0.0000
13:21:28 | INFO | Epoch 1 | train complete | mean_loss=-5.4999 | duration=93.0s
13:21:28 | INFO | Epoch 1 | val   | batches=500
13:21:31 | INFO | Epoch 1 | val batch 125/500 | loss=2911.9275 | nll=2911.7759 | mse=0.0000
13:21:34 | INFO | Epoch 1 | val batch 250/500 | loss=2912.0151 | nll=2911.8684 | mse=0.0000
13:21:37 | INFO | Epoch 1 | val batch 375/500 | loss=2911.9448 | nll=2911.8008 | mse=0.0000
13:21:43 | INFO | Epoch 1 | val batch 500/500 | loss=2911.8733 | nll=2911.7222 | mse=0.0000
13:21:43 | INFO | Epoch 1 | val complete   | mean_loss=2911.9194 | duration=14.3s
13:21:43 | INFO | Epoch 1 | test  | batches=500
13:21:45 | INFO | Epoch 1 | test batch 125/500 | nll=2917.5977 | mse=0.0000 | psnr=62.40
13:21:47 | INFO | Epoch 1 | test batch 250/500 | nll=2923.0396 | mse=0.0000 | psnr=62.55
13:21:50 | INFO | Epoch 1 | test batch 375/500 | nll=2922.1946 | mse=0.0000 | psnr=62.63
13:21:52 | INFO | Epoch 1 | test batch 500/500 | nll=2927.4629 | mse=0.0000 | psnr=62.43
13:21:52 | INFO | Epoch 1 | test complete  | mean_nll=2924.0381 | duration=9.4s
13:21:52 | INFO | Checkpoint saved to /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models/epoch_1_nf_model_net.pth (epoch 1)
13:21:52 | INFO | Checkpoint saved to /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models/best_model.pth (epoch 1)
13:21:52 | INFO | Epoch 1 summary | train=-5.4999 | val=2911.9194 | test=2924.0381 | smpl=0.0000 | best=True
13:21:52 | INFO | Epoch 2 started | validation=True
13:21:52 | INFO | Epoch 2 | train | batches=1500
13:22:10 | INFO | Epoch 2 | train batch 300/1500 | loss=-9.2312 | nll=-9.3758 | mse=0.0000
13:22:30 | INFO | Epoch 2 | train batch 600/1500 | loss=-8.4500 | nll=-8.6022 | mse=0.0000
13:22:47 | INFO | Epoch 2 | train batch 900/1500 | loss=-9.2205 | nll=-9.3730 | mse=0.0000
13:23:08 | INFO | Epoch 2 | train batch 1200/1500 | loss=-9.6366 | nll=-9.7854 | mse=0.0000
13:23:25 | INFO | Epoch 2 | train batch 1500/1500 | loss=-9.2282 | nll=-9.3860 | mse=0.0000
13:23:25 | INFO | Epoch 2 | train complete | mean_loss=-9.1206 | duration=92.3s
13:23:25 | INFO | Epoch 2 | val   | batches=500
13:23:31 | INFO | Epoch 2 | val batch 125/500 | loss=47978.9609 | nll=47978.8086 | mse=0.0000
13:23:34 | INFO | Epoch 2 | val batch 250/500 | loss=47978.8516 | nll=47978.7031 | mse=0.0000
13:23:36 | INFO | Epoch 2 | val batch 375/500 | loss=47978.7148 | nll=47978.5703 | mse=0.0000
13:23:39 | INFO | Epoch 2 | val batch 500/500 | loss=47978.8945 | nll=47978.7422 | mse=0.0000
13:23:39 | INFO | Epoch 2 | val complete   | mean_loss=47978.8853 | duration=14.7s
13:23:39 | INFO | Epoch 2 | test  | batches=500
13:23:42 | INFO | Epoch 2 | test batch 125/500 | nll=47985.8359 | mse=0.0000 | psnr=62.40
13:23:44 | INFO | Epoch 2 | test batch 250/500 | nll=47993.4375 | mse=0.0000 | psnr=62.55
13:23:46 | INFO | Epoch 2 | test batch 375/500 | nll=47992.0703 | mse=0.0000 | psnr=62.63
13:23:48 | INFO | Epoch 2 | test batch 500/500 | nll=48000.2148 | mse=0.0000 | psnr=62.43
13:23:48 | INFO | Epoch 2 | test complete  | mean_nll=47995.2722 | duration=9.1s
13:23:48 | INFO | Checkpoint saved to /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models/epoch_2_nf_model_net.pth (epoch 2)
13:23:48 | INFO | Epoch 2 summary | train=-9.1206 | val=47978.8853 | test=47995.2722 | smpl=0.0000 | best=False
13:23:48 | INFO | Epoch 3 started | validation=True
13:23:48 | INFO | Epoch 3 | train | batches=1500
13:24:09 | INFO | Epoch 3 | train batch 300/1500 | loss=-9.5748 | nll=-9.7203 | mse=0.0000
13:24:26 | INFO | Epoch 3 | train batch 600/1500 | loss=-9.8818 | nll=-10.0291 | mse=0.0000
13:24:46 | INFO | Epoch 3 | train batch 900/1500 | loss=-8.9864 | nll=-9.1369 | mse=0.0000
13:25:04 | INFO | Epoch 3 | train batch 1200/1500 | loss=-8.0289 | nll=-8.1833 | mse=0.0000
13:25:24 | INFO | Epoch 3 | train batch 1500/1500 | loss=-8.9355 | nll=-9.0834 | mse=0.0000
13:25:24 | INFO | Epoch 3 | train complete | mean_loss=-9.0771 | duration=95.5s
13:25:24 | INFO | Epoch 3 | val   | batches=500
13:25:27 | INFO | Epoch 3 | val batch 125/500 | loss=1038.0460 | nll=1037.8943 | mse=0.0000
13:25:29 | INFO | Epoch 3 | val batch 250/500 | loss=1038.3125 | nll=1038.1658 | mse=0.0000
13:25:32 | INFO | Epoch 3 | val batch 375/500 | loss=1038.2609 | nll=1038.1169 | mse=0.0000
13:25:35 | INFO | Epoch 3 | val batch 500/500 | loss=1037.8333 | nll=1037.6821 | mse=0.0000
13:25:35 | INFO | Epoch 3 | val complete   | mean_loss=1038.0728 | duration=11.2s
13:25:35 | INFO | Epoch 3 | test  | batches=500
13:25:37 | INFO | Epoch 3 | test batch 125/500 | nll=1038.5164 | mse=0.0000 | psnr=62.40
13:25:40 | INFO | Epoch 3 | test batch 250/500 | nll=1038.4929 | mse=0.0000 | psnr=62.55
13:25:42 | INFO | Epoch 3 | test batch 375/500 | nll=1038.5591 | mse=0.0000 | psnr=62.63
13:25:44 | INFO | Epoch 3 | test batch 500/500 | nll=1038.8198 | mse=0.0000 | psnr=62.43
13:25:44 | INFO | Epoch 3 | test complete  | mean_nll=1038.4763 | duration=9.2s
13:25:44 | INFO | Checkpoint saved to /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models/epoch_3_nf_model_net.pth (epoch 3)
13:25:44 | INFO | Checkpoint saved to /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models/best_model.pth (epoch 3)
13:25:44 | INFO | Epoch 3 summary | train=-9.0771 | val=1038.0728 | test=1038.4763 | smpl=0.0000 | best=True
13:25:44 | INFO | Epoch 4 started | validation=True
13:25:44 | INFO | Epoch 4 | train | batches=1500
13:26:05 | INFO | Epoch 4 | train batch 300/1500 | loss=-9.6899 | nll=-9.8396 | mse=0.0000
13:26:22 | INFO | Epoch 4 | train batch 600/1500 | loss=-9.8586 | nll=-10.0101 | mse=0.0000
13:26:43 | INFO | Epoch 4 | train batch 900/1500 | loss=-9.8565 | nll=-10.0032 | mse=0.0000
13:27:03 | INFO | Epoch 4 | train batch 1200/1500 | loss=-9.7408 | nll=-9.8864 | mse=0.0000
13:27:20 | INFO | Epoch 4 | train batch 1500/1500 | loss=-7.4339 | nll=-7.5821 | mse=0.0000
13:27:20 | INFO | Epoch 4 | train complete | mean_loss=-9.1740 | duration=95.9s
13:27:20 | INFO | Epoch 4 | val   | batches=500
13:27:23 | INFO | Epoch 4 | val batch 125/500 | loss=-7.1065 | nll=-7.2582 | mse=0.0000
13:27:26 | INFO | Epoch 4 | val batch 250/500 | loss=-7.1194 | nll=-7.2660 | mse=0.0000
13:27:29 | INFO | Epoch 4 | val batch 375/500 | loss=-7.1300 | nll=-7.2739 | mse=0.0000
13:27:32 | INFO | Epoch 4 | val batch 500/500 | loss=-7.1094 | nll=-7.2605 | mse=0.0000
13:27:32 | INFO | Epoch 4 | val complete   | mean_loss=-7.1150 | duration=11.3s
13:27:32 | INFO | Epoch 4 | test  | batches=500
13:27:37 | INFO | Epoch 4 | test batch 125/500 | nll=-7.2436 | mse=0.0000 | psnr=62.40
13:27:39 | INFO | Epoch 4 | test batch 250/500 | nll=-7.2529 | mse=0.0000 | psnr=62.55
13:27:42 | INFO | Epoch 4 | test batch 375/500 | nll=-7.2626 | mse=0.0000 | psnr=62.63
13:27:44 | INFO | Epoch 4 | test batch 500/500 | nll=-7.2479 | mse=0.0000 | psnr=62.43
13:27:44 | INFO | Epoch 4 | test complete  | mean_nll=-7.2522 | duration=12.3s
13:27:44 | INFO | Checkpoint saved to /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models/epoch_4_nf_model_net.pth (epoch 4)
13:27:44 | INFO | Checkpoint saved to /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models/best_model.pth (epoch 4)
13:27:44 | INFO | Epoch 4 summary | train=-9.1740 | val=-7.1150 | test=-7.2522 | smpl=0.0000 | best=True
13:27:44 | INFO | Epoch 5 started | validation=True
13:27:44 | INFO | Epoch 5 | train | batches=1500
13:28:02 | INFO | Epoch 5 | train batch 300/1500 | loss=-8.0792 | nll=-8.2197 | mse=0.0000
13:28:22 | INFO | Epoch 5 | train batch 600/1500 | loss=-8.6542 | nll=-8.8119 | mse=0.0000
13:28:39 | INFO | Epoch 5 | train batch 900/1500 | loss=-9.0860 | nll=-9.2340 | mse=0.0000
13:28:59 | INFO | Epoch 5 | train batch 1200/1500 | loss=-9.3444 | nll=-9.5004 | mse=0.0000
13:29:17 | INFO | Epoch 5 | train batch 1500/1500 | loss=-9.5744 | nll=-9.7214 | mse=0.0000
13:29:17 | INFO | Epoch 5 | train complete | mean_loss=-8.7305 | duration=92.4s
13:29:17 | INFO | Epoch 5 | val   | batches=500
13:29:19 | INFO | Epoch 5 | val batch 125/500 | loss=45821.2852 | nll=45821.1328 | mse=0.0000
13:29:25 | INFO | Epoch 5 | val batch 250/500 | loss=45810.1602 | nll=45810.0117 | mse=0.0000
13:29:28 | INFO | Epoch 5 | val batch 375/500 | loss=45801.5508 | nll=45801.4062 | mse=0.0000
13:29:31 | INFO | Epoch 5 | val batch 500/500 | loss=45807.7773 | nll=45807.6250 | mse=0.0000
13:29:31 | INFO | Epoch 5 | val complete   | mean_loss=45808.2635 | duration=14.3s
13:29:31 | INFO | Epoch 5 | test  | batches=500
13:29:33 | INFO | Epoch 5 | test batch 125/500 | nll=45758.0234 | mse=0.0000 | psnr=62.40
13:29:35 | INFO | Epoch 5 | test batch 250/500 | nll=45709.3828 | mse=0.0000 | psnr=62.55
13:29:38 | INFO | Epoch 5 | test batch 375/500 | nll=45708.6680 | mse=0.0000 | psnr=62.63
13:29:40 | INFO | Epoch 5 | test batch 500/500 | nll=45676.4414 | mse=0.0000 | psnr=62.43
13:29:40 | INFO | Epoch 5 | test complete  | mean_nll=45705.0445 | duration=9.4s
13:29:40 | INFO | Checkpoint saved to /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models/epoch_5_nf_model_net.pth (epoch 5)
13:29:40 | INFO | Epoch 5 summary | train=-8.7305 | val=45808.2635 | test=45705.0445 | smpl=0.0000 | best=False
13:29:40 | INFO | Epoch 6 started | validation=True
13:29:40 | INFO | Epoch 6 | train | batches=1500
13:30:01 | INFO | Epoch 6 | train batch 300/1500 | loss=-9.5535 | nll=-9.7019 | mse=0.0000
13:30:18 | INFO | Epoch 6 | train batch 600/1500 | loss=-9.4223 | nll=-9.5768 | mse=0.0000
13:30:38 | INFO | Epoch 6 | train batch 900/1500 | loss=-9.7002 | nll=-9.8546 | mse=0.0000
13:30:55 | INFO | Epoch 6 | train batch 1200/1500 | loss=-9.5882 | nll=-9.7420 | mse=0.0000
13:31:16 | INFO | Epoch 6 | train batch 1500/1500 | loss=-9.6007 | nll=-9.7563 | mse=0.0000
13:31:16 | INFO | Epoch 6 | train complete | mean_loss=-9.3442 | duration=95.4s
13:31:16 | INFO | Epoch 6 | val   | batches=500
13:31:18 | INFO | Epoch 6 | val batch 125/500 | loss=9822.9990 | nll=9822.8477 | mse=0.0000
13:31:21 | INFO | Epoch 6 | val batch 250/500 | loss=9826.1387 | nll=9825.9922 | mse=0.0000
13:31:24 | INFO | Epoch 6 | val batch 375/500 | loss=9827.8740 | nll=9827.7305 | mse=0.0000
13:31:27 | INFO | Epoch 6 | val batch 500/500 | loss=9826.5596 | nll=9826.4082 | mse=0.0000
13:31:27 | INFO | Epoch 6 | val complete   | mean_loss=9826.3864 | duration=11.2s
13:31:27 | INFO | Epoch 6 | test  | batches=500
13:31:29 | INFO | Epoch 6 | test batch 125/500 | nll=9826.7402 | mse=0.0000 | psnr=62.40
13:31:31 | INFO | Epoch 6 | test batch 250/500 | nll=9822.3115 | mse=0.0000 | psnr=62.55
13:31:34 | INFO | Epoch 6 | test batch 375/500 | nll=9826.2422 | mse=0.0000 | psnr=62.63
13:31:36 | INFO | Epoch 6 | test batch 500/500 | nll=9815.5283 | mse=0.0000 | psnr=62.43
13:31:36 | INFO | Epoch 6 | test complete  | mean_nll=9820.2542 | duration=9.3s
13:31:36 | INFO | Checkpoint saved to /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models/epoch_6_nf_model_net.pth (epoch 6)
13:31:36 | INFO | Epoch 6 summary | train=-9.3442 | val=9826.3864 | test=9820.2542 | smpl=0.0000 | best=False
13:31:36 | INFO | Epoch 7 started | validation=True
13:31:36 | INFO | Epoch 7 | train | batches=1500
13:31:56 | INFO | Epoch 7 | train batch 300/1500 | loss=-9.6607 | nll=-9.8202 | mse=0.0000
13:32:14 | INFO | Epoch 7 | train batch 600/1500 | loss=-9.8836 | nll=-10.0303 | mse=0.0000
13:32:34 | INFO | Epoch 7 | train batch 900/1500 | loss=-9.4538 | nll=-9.6087 | mse=0.0000
13:32:51 | INFO | Epoch 7 | train batch 1200/1500 | loss=-9.9120 | nll=-10.0593 | mse=0.0000
13:33:12 | INFO | Epoch 7 | train batch 1500/1500 | loss=-9.1955 | nll=-9.3627 | mse=0.0000
13:33:12 | INFO | Epoch 7 | train complete | mean_loss=-9.3664 | duration=95.9s
13:33:12 | INFO | Epoch 7 | val   | batches=500
13:33:15 | INFO | Epoch 7 | val batch 125/500 | loss=131.6727 | nll=131.5211 | mse=0.0000
13:33:17 | INFO | Epoch 7 | val batch 250/500 | loss=131.6422 | nll=131.4955 | mse=0.0000
13:33:20 | INFO | Epoch 7 | val batch 375/500 | loss=131.6243 | nll=131.4803 | mse=0.0000
13:33:23 | INFO | Epoch 7 | val batch 500/500 | loss=131.6537 | nll=131.5026 | mse=0.0000
13:33:23 | INFO | Epoch 7 | val complete   | mean_loss=131.6543 | duration=10.8s
13:33:23 | INFO | Epoch 7 | test  | batches=500
13:33:25 | INFO | Epoch 7 | test batch 125/500 | nll=131.4197 | mse=0.0000 | psnr=62.40
13:33:27 | INFO | Epoch 7 | test batch 250/500 | nll=131.2051 | mse=0.0000 | psnr=62.55
13:33:32 | INFO | Epoch 7 | test batch 375/500 | nll=131.2121 | mse=0.0000 | psnr=62.63
13:33:35 | INFO | Epoch 7 | test batch 500/500 | nll=131.0693 | mse=0.0000 | psnr=62.43
13:33:35 | INFO | Epoch 7 | test complete  | mean_nll=131.1729 | duration=11.7s
13:33:35 | INFO | Checkpoint saved to /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models/epoch_7_nf_model_net.pth (epoch 7)
13:33:35 | INFO | Epoch 7 summary | train=-9.3664 | val=131.6543 | test=131.1729 | smpl=0.0000 | best=False
13:33:35 | INFO | Epoch 8 started | validation=True
13:33:35 | INFO | Epoch 8 | train | batches=1500
13:33:52 | INFO | Epoch 8 | train batch 300/1500 | loss=-9.1562 | nll=-9.3111 | mse=0.0000
13:34:13 | INFO | Epoch 8 | train batch 600/1500 | loss=-9.8867 | nll=-10.0422 | mse=0.0000
13:34:31 | INFO | Epoch 8 | train batch 900/1500 | loss=-9.6990 | nll=-9.8511 | mse=0.0000
13:34:51 | INFO | Epoch 8 | train batch 1200/1500 | loss=-9.6612 | nll=-9.8051 | mse=0.0000
13:35:09 | INFO | Epoch 8 | train batch 1500/1500 | loss=-8.7200 | nll=-8.8664 | mse=0.0000
13:35:09 | INFO | Epoch 8 | train complete | mean_loss=-9.3316 | duration=94.2s
13:35:09 | INFO | Epoch 8 | val   | batches=500
13:35:12 | INFO | Epoch 8 | val batch 125/500 | loss=24.2115 | nll=24.0598 | mse=0.0000
13:35:17 | INFO | Epoch 8 | val batch 250/500 | loss=24.1686 | nll=24.0219 | mse=0.0000
13:35:20 | INFO | Epoch 8 | val batch 375/500 | loss=24.1571 | nll=24.0132 | mse=0.0000
13:35:23 | INFO | Epoch 8 | val batch 500/500 | loss=24.1877 | nll=24.0366 | mse=0.0000
13:35:23 | INFO | Epoch 8 | val complete   | mean_loss=24.1892 | duration=14.1s
13:35:23 | INFO | Epoch 8 | test  | batches=500
13:35:25 | INFO | Epoch 8 | test batch 125/500 | nll=23.9958 | mse=0.0000 | psnr=62.40
13:35:27 | INFO | Epoch 8 | test batch 250/500 | nll=23.8907 | mse=0.0000 | psnr=62.55
13:35:29 | INFO | Epoch 8 | test batch 375/500 | nll=23.8856 | mse=0.0000 | psnr=62.63
13:35:31 | INFO | Epoch 8 | test batch 500/500 | nll=23.8448 | mse=0.0000 | psnr=62.43
13:35:31 | INFO | Epoch 8 | test complete  | mean_nll=23.8915 | duration=8.1s
13:35:31 | INFO | Checkpoint saved to /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models/epoch_8_nf_model_net.pth (epoch 8)
13:35:31 | INFO | Epoch 8 summary | train=-9.3316 | val=24.1892 | test=23.8915 | smpl=0.0000 | best=False
13:35:31 | INFO | Epoch 9 started | validation=True
13:35:31 | INFO | Epoch 9 | train | batches=1500
13:35:49 | INFO | Epoch 9 | train batch 300/1500 | loss=-9.1326 | nll=-9.2866 | mse=0.0000
13:36:10 | INFO | Epoch 9 | train batch 600/1500 | loss=-9.6729 | nll=-9.8171 | mse=0.0000
13:36:30 | INFO | Epoch 9 | train batch 900/1500 | loss=-8.9084 | nll=-9.0693 | mse=0.0000
13:36:48 | INFO | Epoch 9 | train batch 1200/1500 | loss=-9.4768 | nll=-9.6302 | mse=0.0000
13:37:09 | INFO | Epoch 9 | train batch 1500/1500 | loss=-9.7032 | nll=-9.8583 | mse=0.0000
13:37:09 | INFO | Epoch 9 | train complete | mean_loss=-9.3649 | duration=97.9s
13:37:09 | INFO | Epoch 9 | val   | batches=500
13:37:12 | INFO | Epoch 9 | val batch 125/500 | loss=262093.0000 | nll=262092.8438 | mse=0.0000
13:37:15 | INFO | Epoch 9 | val batch 250/500 | loss=262113.5000 | nll=262113.3594 | mse=0.0000
13:37:18 | INFO | Epoch 9 | val batch 375/500 | loss=262199.6875 | nll=262199.5312 | mse=0.0000
13:37:20 | INFO | Epoch 9 | val batch 500/500 | loss=262166.4688 | nll=262166.3125 | mse=0.0000
13:37:20 | INFO | Epoch 9 | val complete   | mean_loss=262146.0570 | duration=11.1s
13:37:20 | INFO | Epoch 9 | test  | batches=500
13:37:22 | INFO | Epoch 9 | test batch 125/500 | nll=262146.3438 | mse=0.0000 | psnr=62.40
13:37:24 | INFO | Epoch 9 | test batch 250/500 | nll=262128.7812 | mse=0.0000 | psnr=62.55
13:37:26 | INFO | Epoch 9 | test batch 375/500 | nll=262216.9375 | mse=0.0000 | psnr=62.63
13:37:29 | INFO | Epoch 9 | test batch 500/500 | nll=262110.6094 | mse=0.0000 | psnr=62.43
13:37:29 | INFO | Epoch 9 | test complete  | mean_nll=262153.0604 | duration=8.4s
13:37:29 | INFO | Checkpoint saved to /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models/epoch_9_nf_model_net.pth (epoch 9)
13:37:29 | INFO | Epoch 9 summary | train=-9.3649 | val=262146.0570 | test=262153.0604 | smpl=0.0000 | best=False
13:37:29 | INFO | Epoch 10 started | validation=True
13:37:29 | INFO | Epoch 10 | train | batches=1500
13:37:49 | INFO | Epoch 10 | train batch 300/1500 | loss=-10.0008 | nll=-10.1508 | mse=0.0000
13:38:07 | INFO | Epoch 10 | train batch 600/1500 | loss=-9.9172 | nll=-10.0687 | mse=0.0000
13:38:28 | INFO | Epoch 10 | train batch 900/1500 | loss=-7.9968 | nll=-8.1474 | mse=0.0000
13:38:46 | INFO | Epoch 10 | train batch 1200/1500 | loss=-8.6991 | nll=-8.8400 | mse=0.0000
13:39:06 | INFO | Epoch 10 | train batch 1500/1500 | loss=-9.1178 | nll=-9.2610 | mse=0.0000
13:39:06 | INFO | Epoch 10 | train complete | mean_loss=-8.8231 | duration=97.9s
13:39:06 | INFO | Epoch 10 | val   | batches=500
13:39:09 | INFO | Epoch 10 | val batch 125/500 | loss=48.7772 | nll=48.6256 | mse=0.0000
13:39:12 | INFO | Epoch 10 | val batch 250/500 | loss=49.0359 | nll=48.8892 | mse=0.0000
13:39:15 | INFO | Epoch 10 | val batch 375/500 | loss=49.7212 | nll=49.5772 | mse=0.0000
13:39:18 | INFO | Epoch 10 | val batch 500/500 | loss=49.0795 | nll=48.9284 | mse=0.0000
13:39:18 | INFO | Epoch 10 | val complete   | mean_loss=49.0977 | duration=11.2s
13:39:18 | INFO | Epoch 10 | test  | batches=500
13:39:20 | INFO | Epoch 10 | test batch 125/500 | nll=50.1540 | mse=0.0000 | psnr=62.40
13:39:25 | INFO | Epoch 10 | test batch 250/500 | nll=48.3511 | mse=0.0000 | psnr=62.55
13:39:27 | INFO | Epoch 10 | test batch 375/500 | nll=49.5054 | mse=0.0000 | psnr=62.63
13:39:29 | INFO | Epoch 10 | test batch 500/500 | nll=47.8604 | mse=0.0000 | psnr=62.43
13:39:29 | INFO | Epoch 10 | test complete  | mean_nll=48.2790 | duration=11.1s
13:39:29 | INFO | Checkpoint saved to /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models/epoch_10_nf_model_net.pth (epoch 10)
13:39:29 | INFO | Epoch 10 summary | train=-8.8231 | val=49.0977 | test=48.2790 | smpl=0.0000 | best=False
13:39:29 | INFO | Epoch 11 started | validation=False
13:39:29 | INFO | Epoch 11 | train | batches=1500
13:39:47 | INFO | Epoch 11 | train batch 300/1500 | loss=-9.3685 | nll=-9.5084 | mse=0.0000
13:40:07 | INFO | Epoch 11 | train batch 600/1500 | loss=-9.6551 | nll=-9.7994 | mse=0.0000
13:40:25 | INFO | Epoch 11 | train batch 900/1500 | loss=-8.8283 | nll=-8.9705 | mse=0.0000
13:40:45 | INFO | Epoch 11 | train batch 1200/1500 | loss=-9.5967 | nll=-9.7399 | mse=0.0000
13:41:03 | INFO | Epoch 11 | train batch 1500/1500 | loss=-5.0215 | nll=-5.1694 | mse=0.0000
13:41:03 | INFO | Epoch 11 | train complete | mean_loss=-9.0582 | duration=94.2s
13:41:03 | INFO | Epoch 11 summary | train=-9.0582 (validation skipped)
13:41:03 | INFO | Epoch 12 started | validation=False
13:41:03 | INFO | Epoch 12 | train | batches=1500
13:41:24 | INFO | Epoch 12 | train batch 300/1500 | loss=-9.8054 | nll=-9.9574 | mse=0.0000
13:41:41 | INFO | Epoch 12 | train batch 600/1500 | loss=-8.2215 | nll=-8.3787 | mse=0.0000
13:42:02 | INFO | Epoch 12 | train batch 900/1500 | loss=-9.6689 | nll=-9.8139 | mse=0.0000
13:42:23 | INFO | Epoch 12 | train batch 1200/1500 | loss=0.0075 | nll=-0.1514 | mse=0.0000
13:42:40 | INFO | Epoch 12 | train batch 1500/1500 | loss=-8.1695 | nll=-8.3193 | mse=0.0000
13:42:40 | INFO | Epoch 12 | train complete | mean_loss=-8.7365 | duration=97.1s
13:42:40 | INFO | Epoch 12 summary | train=-8.7365 (validation skipped)
13:42:40 | INFO | Epoch 13 started | validation=False
13:42:40 | INFO | Epoch 13 | train | batches=1500
13:43:01 | INFO | Epoch 13 | train batch 300/1500 | loss=-8.4899 | nll=-8.6507 | mse=0.0000
13:43:18 | INFO | Epoch 13 | train batch 600/1500 | loss=-8.9877 | nll=-9.1393 | mse=0.0000
13:43:39 | INFO | Epoch 13 | train batch 900/1500 | loss=-9.5389 | nll=-9.6930 | mse=0.0000
13:43:57 | INFO | Epoch 13 | train batch 1200/1500 | loss=-9.7246 | nll=-9.8799 | mse=0.0000
13:44:18 | INFO | Epoch 13 | train batch 1500/1500 | loss=-9.5861 | nll=-9.7293 | mse=0.0000
13:44:18 | INFO | Epoch 13 | train complete | mean_loss=-9.1574 | duration=97.6s
13:44:18 | INFO | Epoch 13 summary | train=-9.1574 (validation skipped)
13:44:18 | INFO | Epoch 14 started | validation=False
13:44:18 | INFO | Epoch 14 | train | batches=1500
13:44:35 | INFO | Epoch 14 | train batch 300/1500 | loss=-10.0505 | nll=-10.1930 | mse=0.0000
13:44:56 | INFO | Epoch 14 | train batch 600/1500 | loss=-9.9416 | nll=-10.0845 | mse=0.0000
13:45:13 | INFO | Epoch 14 | train batch 900/1500 | loss=-8.5167 | nll=-8.6774 | mse=0.0000
13:45:35 | INFO | Epoch 14 | train batch 1200/1500 | loss=-9.5135 | nll=-9.6610 | mse=0.0000
13:45:55 | INFO | Epoch 14 | train batch 1500/1500 | loss=-9.5093 | nll=-9.6422 | mse=0.0000
13:45:55 | INFO | Epoch 14 | train complete | mean_loss=-9.5840 | duration=97.3s
13:45:55 | INFO | Epoch 14 summary | train=-9.5840 (validation skipped)
13:45:55 | INFO | Epoch 15 started | validation=False
13:45:55 | INFO | Epoch 15 | train | batches=1500
13:46:13 | INFO | Epoch 15 | train batch 300/1500 | loss=-9.1662 | nll=-9.3280 | mse=0.0000
13:46:34 | INFO | Epoch 15 | train batch 600/1500 | loss=-9.5474 | nll=-9.6971 | mse=0.0000
13:46:51 | INFO | Epoch 15 | train batch 900/1500 | loss=-9.2724 | nll=-9.4331 | mse=0.0000
13:47:12 | INFO | Epoch 15 | train batch 1200/1500 | loss=-9.4993 | nll=-9.6510 | mse=0.0000
13:47:29 | INFO | Epoch 15 | train batch 1500/1500 | loss=-9.9197 | nll=-10.0669 | mse=0.0000
13:47:29 | INFO | Epoch 15 | train complete | mean_loss=-9.3106 | duration=94.3s
13:47:29 | INFO | Epoch 15 summary | train=-9.3106 (validation skipped)
13:47:29 | INFO | Epoch 16 started | validation=False
13:47:29 | INFO | Epoch 16 | train | batches=1500
13:47:50 | INFO | Epoch 16 | train batch 300/1500 | loss=-9.0702 | nll=-9.2147 | mse=0.0000
13:48:08 | INFO | Epoch 16 | train batch 600/1500 | loss=-9.6028 | nll=-9.7516 | mse=0.0000
13:48:28 | INFO | Epoch 16 | train batch 900/1500 | loss=-9.0813 | nll=-9.2359 | mse=0.0000
13:48:46 | INFO | Epoch 16 | train batch 1200/1500 | loss=-9.9472 | nll=-10.1060 | mse=0.0000
13:49:07 | INFO | Epoch 16 | train batch 1500/1500 | loss=-2.1464 | nll=-2.2863 | mse=0.0000
13:49:07 | INFO | Epoch 16 | train complete | mean_loss=-9.4885 | duration=97.4s
13:49:07 | INFO | Epoch 16 summary | train=-9.4885 (validation skipped)
13:49:07 | INFO | Epoch 17 started | validation=False
13:49:07 | INFO | Epoch 17 | train | batches=1500
13:49:27 | INFO | Epoch 17 | train batch 300/1500 | loss=-8.1185 | nll=-8.2658 | mse=0.0000
13:49:45 | INFO | Epoch 17 | train batch 600/1500 | loss=-8.7544 | nll=-8.8949 | mse=0.0000
13:50:06 | INFO | Epoch 17 | train batch 900/1500 | loss=-9.2847 | nll=-9.4314 | mse=0.0000
13:50:24 | INFO | Epoch 17 | train batch 1200/1500 | loss=-10.0976 | nll=-10.2475 | mse=0.0000
13:50:44 | INFO | Epoch 17 | train batch 1500/1500 | loss=-8.8027 | nll=-8.9533 | mse=0.0000
13:50:44 | INFO | Epoch 17 | train complete | mean_loss=-8.8017 | duration=97.5s
13:50:44 | INFO | Epoch 17 summary | train=-8.8017 (validation skipped)
13:50:44 | INFO | Epoch 18 started | validation=False
13:50:44 | INFO | Epoch 18 | train | batches=1500
13:51:02 | INFO | Epoch 18 | train batch 300/1500 | loss=-10.1541 | nll=-10.3024 | mse=0.0000
13:51:23 | INFO | Epoch 18 | train batch 600/1500 | loss=-7.8286 | nll=-7.9819 | mse=0.0000
13:51:41 | INFO | Epoch 18 | train batch 900/1500 | loss=-10.1159 | nll=-10.2611 | mse=0.0000
13:52:02 | INFO | Epoch 18 | train batch 1200/1500 | loss=-10.3107 | nll=-10.4600 | mse=0.0000
13:52:19 | INFO | Epoch 18 | train batch 1500/1500 | loss=-8.3030 | nll=-8.4511 | mse=0.0000
13:52:19 | INFO | Epoch 18 | train complete | mean_loss=-8.8118 | duration=95.0s
13:52:19 | INFO | Epoch 18 summary | train=-8.8118 (validation skipped)
13:52:19 | INFO | Epoch 19 started | validation=False
13:52:19 | INFO | Epoch 19 | train | batches=1500
13:52:40 | INFO | Epoch 19 | train batch 300/1500 | loss=-9.2536 | nll=-9.4067 | mse=0.0000
13:53:01 | INFO | Epoch 19 | train batch 600/1500 | loss=-9.5007 | nll=-9.6566 | mse=0.0000
13:53:19 | INFO | Epoch 19 | train batch 900/1500 | loss=-9.6591 | nll=-9.8089 | mse=0.0000
13:53:40 | INFO | Epoch 19 | train batch 1200/1500 | loss=-9.5522 | nll=-9.6863 | mse=0.0000
13:53:58 | INFO | Epoch 19 | train batch 1500/1500 | loss=-9.6869 | nll=-9.8350 | mse=0.0000
13:53:58 | INFO | Epoch 19 | train complete | mean_loss=-9.4011 | duration=98.3s
13:53:58 | INFO | Epoch 19 summary | train=-9.4011 (validation skipped)
13:53:58 | INFO | Epoch 20 started | validation=True
13:53:58 | INFO | Epoch 20 | train | batches=1500
13:54:19 | INFO | Epoch 20 | train batch 300/1500 | loss=-9.3368 | nll=-9.4880 | mse=0.0000
13:54:36 | INFO | Epoch 20 | train batch 600/1500 | loss=-10.1990 | nll=-10.3438 | mse=0.0000
13:54:57 | INFO | Epoch 20 | train batch 900/1500 | loss=-10.1869 | nll=-10.3362 | mse=0.0000
13:55:15 | INFO | Epoch 20 | train batch 1200/1500 | loss=-10.1371 | nll=-10.2836 | mse=0.0000
13:55:36 | INFO | Epoch 20 | train batch 1500/1500 | loss=-10.2669 | nll=-10.3997 | mse=0.0000
13:55:36 | INFO | Epoch 20 | train complete | mean_loss=-9.7763 | duration=98.5s
13:55:36 | INFO | Epoch 20 | val   | batches=500
13:55:39 | INFO | Epoch 20 | val batch 125/500 | loss=258.3024 | nll=258.1508 | mse=0.0000
13:55:42 | INFO | Epoch 20 | val batch 250/500 | loss=258.2503 | nll=258.1036 | mse=0.0000
13:55:44 | INFO | Epoch 20 | val batch 375/500 | loss=258.2489 | nll=258.1049 | mse=0.0000
13:55:47 | INFO | Epoch 20 | val batch 500/500 | loss=258.2634 | nll=258.1122 | mse=0.0000
13:55:47 | INFO | Epoch 20 | val complete   | mean_loss=258.2704 | duration=11.0s
13:55:47 | INFO | Epoch 20 | test  | batches=500
13:55:49 | INFO | Epoch 20 | test batch 125/500 | nll=258.3206 | mse=0.0000 | psnr=62.40
13:55:51 | INFO | Epoch 20 | test batch 250/500 | nll=258.6145 | mse=0.0000 | psnr=62.55
13:55:53 | INFO | Epoch 20 | test batch 375/500 | nll=258.5832 | mse=0.0000 | psnr=62.63
13:55:58 | INFO | Epoch 20 | test batch 500/500 | nll=258.9770 | mse=0.0000 | psnr=62.43
13:55:58 | INFO | Epoch 20 | test complete  | mean_nll=258.7414 | duration=11.4s
13:55:59 | INFO | Checkpoint saved to /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models/epoch_20_nf_model_net.pth (epoch 20)
13:55:59 | INFO | Epoch 20 summary | train=-9.7763 | val=258.2704 | test=258.7414 | smpl=0.0000 | best=False
13:55:59 | INFO | Epoch 21 started | validation=False
13:55:59 | INFO | Epoch 21 | train | batches=1500
13:56:16 | INFO | Epoch 21 | train batch 300/1500 | loss=-10.1850 | nll=-10.3339 | mse=0.0000
13:56:37 | INFO | Epoch 21 | train batch 600/1500 | loss=-10.4442 | nll=-10.5973 | mse=0.0000
13:56:55 | INFO | Epoch 21 | train batch 900/1500 | loss=-9.5462 | nll=-9.7023 | mse=0.0000
13:57:15 | INFO | Epoch 21 | train batch 1200/1500 | loss=-9.9432 | nll=-10.0882 | mse=0.0000
13:57:33 | INFO | Epoch 21 | train batch 1500/1500 | loss=-7.9883 | nll=-8.1423 | mse=0.0000
13:57:33 | INFO | Epoch 21 | train complete | mean_loss=-9.5265 | duration=94.4s
13:57:33 | INFO | Epoch 21 summary | train=-9.5265 (validation skipped)
13:57:33 | INFO | Epoch 22 started | validation=False
13:57:33 | INFO | Epoch 22 | train | batches=1500
13:57:54 | INFO | Epoch 22 | train batch 300/1500 | loss=-8.4019 | nll=-8.5474 | mse=0.0000
13:58:11 | INFO | Epoch 22 | train batch 600/1500 | loss=-8.9686 | nll=-9.1043 | mse=0.0000
13:58:32 | INFO | Epoch 22 | train batch 900/1500 | loss=-9.0013 | nll=-9.1396 | mse=0.0000
13:58:49 | INFO | Epoch 22 | train batch 1200/1500 | loss=-8.4241 | nll=-8.5870 | mse=0.0000
13:59:09 | INFO | Epoch 22 | train batch 1500/1500 | loss=-8.9755 | nll=-9.1242 | mse=0.0000
13:59:09 | INFO | Epoch 22 | train complete | mean_loss=-8.5323 | duration=96.4s
13:59:09 | INFO | Epoch 22 summary | train=-8.5323 (validation skipped)
13:59:09 | INFO | Epoch 23 started | validation=False
13:59:09 | INFO | Epoch 23 | train | batches=1500
13:59:30 | INFO | Epoch 23 | train batch 300/1500 | loss=-9.3297 | nll=-9.4760 | mse=0.0000
13:59:47 | INFO | Epoch 23 | train batch 600/1500 | loss=-9.6878 | nll=-9.8453 | mse=0.0000
14:00:08 | INFO | Epoch 23 | train batch 900/1500 | loss=-9.7525 | nll=-9.9080 | mse=0.0000
14:00:26 | INFO | Epoch 23 | train batch 1200/1500 | loss=-9.5906 | nll=-9.7343 | mse=0.0000
14:00:47 | INFO | Epoch 23 | train batch 1500/1500 | loss=-9.0470 | nll=-9.1994 | mse=0.0000
14:00:47 | INFO | Epoch 23 | train complete | mean_loss=-9.4547 | duration=97.1s
14:00:47 | INFO | Epoch 23 summary | train=-9.4547 (validation skipped)
14:00:47 | INFO | Epoch 24 started | validation=False
14:00:47 | INFO | Epoch 24 | train | batches=1500
14:01:04 | INFO | Epoch 24 | train batch 300/1500 | loss=-9.6374 | nll=-9.7912 | mse=0.0000
14:01:25 | INFO | Epoch 24 | train batch 600/1500 | loss=-10.1252 | nll=-10.2780 | mse=0.0000
14:01:42 | INFO | Epoch 24 | train batch 900/1500 | loss=-10.1070 | nll=-10.2605 | mse=0.0000
14:02:03 | INFO | Epoch 24 | train batch 1200/1500 | loss=-10.0764 | nll=-10.2207 | mse=0.0000
14:02:21 | INFO | Epoch 24 | train batch 1500/1500 | loss=-9.9492 | nll=-10.0957 | mse=0.0000
14:02:21 | INFO | Epoch 24 | train complete | mean_loss=-9.7010 | duration=94.7s
14:02:21 | INFO | Epoch 24 summary | train=-9.7010 (validation skipped)
14:02:21 | INFO | Epoch 25 started | validation=False
14:02:21 | INFO | Epoch 25 | train | batches=1500
14:02:42 | INFO | Epoch 25 | train batch 300/1500 | loss=-9.7621 | nll=-9.9109 | mse=0.0000
14:02:59 | INFO | Epoch 25 | train batch 600/1500 | loss=-9.9610 | nll=-10.1208 | mse=0.0000
14:03:19 | INFO | Epoch 25 | train batch 900/1500 | loss=-9.4864 | nll=-9.6356 | mse=0.0000
14:03:40 | INFO | Epoch 25 | train batch 1200/1500 | loss=-8.8902 | nll=-9.0507 | mse=0.0000
14:03:57 | INFO | Epoch 25 | train batch 1500/1500 | loss=-10.4133 | nll=-10.5534 | mse=0.0000
14:03:57 | INFO | Epoch 25 | train complete | mean_loss=-9.8200 | duration=95.9s
14:03:57 | INFO | Epoch 25 summary | train=-9.8200 (validation skipped)
14:03:57 | INFO | Epoch 26 started | validation=False
14:03:57 | INFO | Epoch 26 | train | batches=1500
14:04:18 | INFO | Epoch 26 | train batch 300/1500 | loss=-9.3619 | nll=-9.5165 | mse=0.0000
14:04:35 | INFO | Epoch 26 | train batch 600/1500 | loss=-9.9467 | nll=-10.0879 | mse=0.0000
14:04:55 | INFO | Epoch 26 | train batch 900/1500 | loss=-10.3145 | nll=-10.4647 | mse=0.0000
14:05:12 | INFO | Epoch 26 | train batch 1200/1500 | loss=-10.3429 | nll=-10.4867 | mse=0.0000
14:05:33 | INFO | Epoch 26 | train batch 1500/1500 | loss=-10.2929 | nll=-10.4518 | mse=0.0000
14:05:33 | INFO | Epoch 26 | train complete | mean_loss=-9.7957 | duration=95.5s
14:05:33 | INFO | Epoch 26 summary | train=-9.7957 (validation skipped)
14:05:33 | INFO | Epoch 27 started | validation=False
14:05:33 | INFO | Epoch 27 | train | batches=1500
14:05:50 | INFO | Epoch 27 | train batch 300/1500 | loss=-10.2653 | nll=-10.4026 | mse=0.0000
14:06:10 | INFO | Epoch 27 | train batch 600/1500 | loss=-10.0010 | nll=-10.1449 | mse=0.0000
14:06:27 | INFO | Epoch 27 | train batch 900/1500 | loss=-10.4619 | nll=-10.6124 | mse=0.0000
14:06:48 | INFO | Epoch 27 | train batch 1200/1500 | loss=-10.2415 | nll=-10.3940 | mse=0.0000
14:07:05 | INFO | Epoch 27 | train batch 1500/1500 | loss=-10.4583 | nll=-10.6050 | mse=0.0000
14:07:05 | INFO | Epoch 27 | train complete | mean_loss=-9.9207 | duration=92.1s
14:07:05 | INFO | Epoch 27 summary | train=-9.9207 (validation skipped)
14:07:05 | INFO | Epoch 28 started | validation=False
14:07:05 | INFO | Epoch 28 | train | batches=1500
14:07:25 | INFO | Epoch 28 | train batch 300/1500 | loss=-10.5612 | nll=-10.7094 | mse=0.0000
14:07:42 | INFO | Epoch 28 | train batch 600/1500 | loss=-9.3264 | nll=-9.4728 | mse=0.0000
14:08:03 | INFO | Epoch 28 | train batch 900/1500 | loss=-10.2863 | nll=-10.4448 | mse=0.0000
14:08:20 | INFO | Epoch 28 | train batch 1200/1500 | loss=-9.5775 | nll=-9.7308 | mse=0.0000
14:08:41 | INFO | Epoch 28 | train batch 1500/1500 | loss=-10.5233 | nll=-10.6682 | mse=0.0000
14:08:41 | INFO | Epoch 28 | train complete | mean_loss=-10.0571 | duration=95.7s
14:08:41 | INFO | Epoch 28 summary | train=-10.0571 (validation skipped)
14:08:41 | INFO | Epoch 29 started | validation=False
14:08:41 | INFO | Epoch 29 | train | batches=1500
14:09:01 | INFO | Epoch 29 | train batch 300/1500 | loss=-10.3075 | nll=-10.4708 | mse=0.0000
14:09:18 | INFO | Epoch 29 | train batch 600/1500 | loss=-9.0713 | nll=-9.2206 | mse=0.0000
14:09:38 | INFO | Epoch 29 | train batch 900/1500 | loss=-10.4058 | nll=-10.5561 | mse=0.0000
14:09:56 | INFO | Epoch 29 | train batch 1200/1500 | loss=-10.5841 | nll=-10.7198 | mse=0.0000
14:10:16 | INFO | Epoch 29 | train batch 1500/1500 | loss=-10.2779 | nll=-10.4376 | mse=0.0000
14:10:16 | INFO | Epoch 29 | train complete | mean_loss=-10.0220 | duration=95.4s
14:10:16 | INFO | Epoch 29 summary | train=-10.0220 (validation skipped)
14:10:16 | INFO | Epoch 30 started | validation=True
14:10:16 | INFO | Epoch 30 | train | batches=1500
14:10:34 | INFO | Epoch 30 | train batch 300/1500 | loss=-10.3122 | nll=-10.4652 | mse=0.0000
14:10:54 | INFO | Epoch 30 | train batch 600/1500 | loss=-8.0044 | nll=-8.1516 | mse=0.0000
14:11:11 | INFO | Epoch 30 | train batch 900/1500 | loss=-10.4905 | nll=-10.6352 | mse=0.0000
14:11:31 | INFO | Epoch 30 | train batch 1200/1500 | loss=-8.8216 | nll=-8.9708 | mse=0.0000
14:11:49 | INFO | Epoch 30 | train batch 1500/1500 | loss=-10.5128 | nll=-10.6588 | mse=0.0000
14:11:49 | INFO | Epoch 30 | train complete | mean_loss=-9.8282 | duration=93.2s
14:11:49 | INFO | Epoch 30 | val   | batches=500
14:11:52 | INFO | Epoch 30 | val batch 125/500 | loss=9.2165 | nll=9.0648 | mse=0.0000
14:11:58 | INFO | Epoch 30 | val batch 250/500 | loss=9.2099 | nll=9.0632 | mse=0.0000
14:12:00 | INFO | Epoch 30 | val batch 375/500 | loss=9.2054 | nll=9.0614 | mse=0.0000
14:12:03 | INFO | Epoch 30 | val batch 500/500 | loss=9.2161 | nll=9.0650 | mse=0.0000
14:12:03 | INFO | Epoch 30 | val complete   | mean_loss=9.2140 | duration=14.2s
14:12:03 | INFO | Epoch 30 | test  | batches=500
14:12:06 | INFO | Epoch 30 | test batch 125/500 | nll=9.0915 | mse=0.0000 | psnr=62.40
14:12:08 | INFO | Epoch 30 | test batch 250/500 | nll=9.1198 | mse=0.0000 | psnr=62.55
14:12:10 | INFO | Epoch 30 | test batch 375/500 | nll=9.1112 | mse=0.0000 | psnr=62.63
14:12:12 | INFO | Epoch 30 | test batch 500/500 | nll=9.1450 | mse=0.0000 | psnr=62.43
14:12:12 | INFO | Epoch 30 | test complete  | mean_nll=9.1287 | duration=8.8s
14:12:12 | INFO | Checkpoint saved to /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models/epoch_30_nf_model_net.pth (epoch 30)
14:12:12 | INFO | Epoch 30 summary | train=-9.8282 | val=9.2140 | test=9.1287 | smpl=0.0000 | best=False
14:12:12 | INFO | Epoch 31 started | validation=False
14:12:12 | INFO | Epoch 31 | train | batches=1500
14:12:33 | INFO | Epoch 31 | train batch 300/1500 | loss=-9.9976 | nll=-10.1394 | mse=0.0000
14:12:50 | INFO | Epoch 31 | train batch 600/1500 | loss=-7.8325 | nll=-7.9780 | mse=0.0000
14:13:11 | INFO | Epoch 31 | train batch 900/1500 | loss=-10.5048 | nll=-10.6611 | mse=0.0000
14:13:28 | INFO | Epoch 31 | train batch 1200/1500 | loss=-10.4784 | nll=-10.6231 | mse=0.0000
14:13:49 | INFO | Epoch 31 | train batch 1500/1500 | loss=-10.4325 | nll=-10.5889 | mse=0.0000
14:13:49 | INFO | Epoch 31 | train complete | mean_loss=-9.7260 | duration=97.0s
14:13:49 | INFO | Epoch 31 summary | train=-9.7260 (validation skipped)
14:13:49 | INFO | Epoch 32 started | validation=False
14:13:49 | INFO | Epoch 32 | train | batches=1500
14:14:06 | INFO | Epoch 32 | train batch 300/1500 | loss=-10.5823 | nll=-10.7389 | mse=0.0000
14:14:27 | INFO | Epoch 32 | train batch 600/1500 | loss=-10.5755 | nll=-10.7226 | mse=0.0000
14:14:44 | INFO | Epoch 32 | train batch 900/1500 | loss=-10.1545 | nll=-10.3026 | mse=0.0000
14:15:05 | INFO | Epoch 32 | train batch 1200/1500 | loss=-7.7827 | nll=-7.9303 | mse=0.0000
14:15:23 | INFO | Epoch 32 | train batch 1500/1500 | loss=-10.0790 | nll=-10.2352 | mse=0.0000
14:15:23 | INFO | Epoch 32 | train complete | mean_loss=-9.6426 | duration=93.4s
14:15:23 | INFO | Epoch 32 summary | train=-9.6426 (validation skipped)
14:15:23 | INFO | Epoch 33 started | validation=False
14:15:23 | INFO | Epoch 33 | train | batches=1500
14:15:43 | INFO | Epoch 33 | train batch 300/1500 | loss=-9.5957 | nll=-9.7556 | mse=0.0000
14:16:01 | INFO | Epoch 33 | train batch 600/1500 | loss=-10.5448 | nll=-10.6978 | mse=0.0000
14:16:21 | INFO | Epoch 33 | train batch 900/1500 | loss=-9.1117 | nll=-9.2595 | mse=0.0000
14:16:42 | INFO | Epoch 33 | train batch 1200/1500 | loss=-10.6283 | nll=-10.7767 | mse=0.0000
14:17:00 | INFO | Epoch 33 | train batch 1500/1500 | loss=-9.4942 | nll=-9.6442 | mse=0.0000
14:17:00 | INFO | Epoch 33 | train complete | mean_loss=-9.8312 | duration=97.3s
14:17:00 | INFO | Epoch 33 summary | train=-9.8312 (validation skipped)
14:17:00 | INFO | Epoch 34 started | validation=False
14:17:00 | INFO | Epoch 34 | train | batches=1500
14:17:21 | INFO | Epoch 34 | train batch 300/1500 | loss=-10.6602 | nll=-10.8080 | mse=0.0000
14:17:38 | INFO | Epoch 34 | train batch 600/1500 | loss=-10.4972 | nll=-10.6638 | mse=0.0000
14:17:59 | INFO | Epoch 34 | train batch 900/1500 | loss=-10.1777 | nll=-10.3261 | mse=0.0000
14:18:16 | INFO | Epoch 34 | train batch 1200/1500 | loss=-10.2054 | nll=-10.3568 | mse=0.0000
14:18:37 | INFO | Epoch 34 | train batch 1500/1500 | loss=-10.6459 | nll=-10.8023 | mse=0.0000
14:18:37 | INFO | Epoch 34 | train complete | mean_loss=-9.6983 | duration=97.3s
14:18:37 | INFO | Epoch 34 summary | train=-9.6983 (validation skipped)
14:18:37 | INFO | Epoch 35 started | validation=False
14:18:37 | INFO | Epoch 35 | train | batches=1500
14:18:55 | INFO | Epoch 35 | train batch 300/1500 | loss=-10.5406 | nll=-10.6964 | mse=0.0000
14:19:15 | INFO | Epoch 35 | train batch 600/1500 | loss=-10.4193 | nll=-10.5722 | mse=0.0000
14:19:32 | INFO | Epoch 35 | train batch 900/1500 | loss=-10.5595 | nll=-10.7077 | mse=0.0000
14:19:54 | INFO | Epoch 35 | train batch 1200/1500 | loss=-9.9367 | nll=-10.0892 | mse=0.0000
14:20:11 | INFO | Epoch 35 | train batch 1500/1500 | loss=-10.5300 | nll=-10.6800 | mse=0.0000
14:20:11 | INFO | Epoch 35 | train complete | mean_loss=-9.7580 | duration=93.8s
14:20:11 | INFO | Epoch 35 summary | train=-9.7580 (validation skipped)
14:20:11 | INFO | Epoch 36 started | validation=False
14:20:11 | INFO | Epoch 36 | train | batches=1500
14:20:31 | INFO | Epoch 36 | train batch 300/1500 | loss=-10.5840 | nll=-10.7358 | mse=0.0000
14:20:52 | INFO | Epoch 36 | train batch 600/1500 | loss=-8.5320 | nll=-8.6873 | mse=0.0000
14:21:10 | INFO | Epoch 36 | train batch 900/1500 | loss=-10.3004 | nll=-10.4504 | mse=0.0000
14:21:31 | INFO | Epoch 36 | train batch 1200/1500 | loss=-8.7042 | nll=-8.8497 | mse=0.0000
14:21:48 | INFO | Epoch 36 | train batch 1500/1500 | loss=-10.5237 | nll=-10.6643 | mse=0.0000
14:21:48 | INFO | Epoch 36 | train complete | mean_loss=-9.7975 | duration=97.4s
14:21:48 | INFO | Epoch 36 summary | train=-9.7975 (validation skipped)
14:21:48 | INFO | Epoch 37 started | validation=False
14:21:48 | INFO | Epoch 37 | train | batches=1500
14:22:09 | INFO | Epoch 37 | train batch 300/1500 | loss=-10.0102 | nll=-10.1499 | mse=0.0000
14:22:27 | INFO | Epoch 37 | train batch 600/1500 | loss=-10.2551 | nll=-10.4071 | mse=0.0000
14:22:47 | INFO | Epoch 37 | train batch 900/1500 | loss=-7.4989 | nll=-7.6396 | mse=0.0000
14:23:05 | INFO | Epoch 37 | train batch 1200/1500 | loss=-8.8485 | nll=-9.0033 | mse=0.0000
14:23:26 | INFO | Epoch 37 | train batch 1500/1500 | loss=-10.4062 | nll=-10.5554 | mse=0.0000
14:23:26 | INFO | Epoch 37 | train complete | mean_loss=-9.9955 | duration=97.3s
14:23:26 | INFO | Epoch 37 summary | train=-9.9955 (validation skipped)
14:23:26 | INFO | Epoch 38 started | validation=False
14:23:26 | INFO | Epoch 38 | train | batches=1500
14:23:43 | INFO | Epoch 38 | train batch 300/1500 | loss=-10.7345 | nll=-10.8938 | mse=0.0000
14:24:04 | INFO | Epoch 38 | train batch 600/1500 | loss=-8.9544 | nll=-9.1038 | mse=0.0000
14:24:25 | INFO | Epoch 38 | train batch 900/1500 | loss=-7.9080 | nll=-8.0541 | mse=0.0000
14:24:42 | INFO | Epoch 38 | train batch 1200/1500 | loss=-10.2616 | nll=-10.4153 | mse=0.0000
14:25:03 | INFO | Epoch 38 | train batch 1500/1500 | loss=-8.3068 | nll=-8.4628 | mse=0.0000
14:25:03 | INFO | Epoch 38 | train complete | mean_loss=-9.8822 | duration=97.5s
14:25:03 | INFO | Epoch 38 summary | train=-9.8822 (validation skipped)
14:25:03 | INFO | Epoch 39 started | validation=False
14:25:03 | INFO | Epoch 39 | train | batches=1500
14:25:21 | INFO | Epoch 39 | train batch 300/1500 | loss=-9.2464 | nll=-9.3965 | mse=0.0000
14:25:42 | INFO | Epoch 39 | train batch 600/1500 | loss=-8.9246 | nll=-9.0764 | mse=0.0000
14:25:59 | INFO | Epoch 39 | train batch 900/1500 | loss=-9.1566 | nll=-9.3021 | mse=0.0000
14:26:20 | INFO | Epoch 39 | train batch 1200/1500 | loss=-10.3406 | nll=-10.5002 | mse=0.0000
14:26:38 | INFO | Epoch 39 | train batch 1500/1500 | loss=-10.7112 | nll=-10.8557 | mse=0.0000
14:26:38 | INFO | Epoch 39 | train complete | mean_loss=-9.4937 | duration=94.8s
14:26:38 | INFO | Epoch 39 summary | train=-9.4937 (validation skipped)
14:26:38 | INFO | Epoch 40 started | validation=True
14:26:38 | INFO | Epoch 40 | train | batches=1500
14:26:59 | INFO | Epoch 40 | train batch 300/1500 | loss=-8.4965 | nll=-8.6440 | mse=0.0000
14:27:16 | INFO | Epoch 40 | train batch 600/1500 | loss=-9.1874 | nll=-9.3306 | mse=0.0000
14:27:37 | INFO | Epoch 40 | train batch 900/1500 | loss=-9.4437 | nll=-9.5839 | mse=0.0000
14:27:58 | INFO | Epoch 40 | train batch 1200/1500 | loss=-7.9317 | nll=-8.0866 | mse=0.0000
14:28:16 | INFO | Epoch 40 | train batch 1500/1500 | loss=-9.4440 | nll=-9.5915 | mse=0.0000
14:28:16 | INFO | Epoch 40 | train complete | mean_loss=-8.8260 | duration=98.0s
14:28:16 | INFO | Epoch 40 | val   | batches=500
14:28:19 | INFO | Epoch 40 | val batch 125/500 | loss=101.3240 | nll=101.1723 | mse=0.0000
14:28:21 | INFO | Epoch 40 | val batch 250/500 | loss=101.3176 | nll=101.1709 | mse=0.0000
14:28:24 | INFO | Epoch 40 | val batch 375/500 | loss=101.3155 | nll=101.1715 | mse=0.0000
14:28:27 | INFO | Epoch 40 | val batch 500/500 | loss=101.3230 | nll=101.1719 | mse=0.0000
14:28:27 | INFO | Epoch 40 | val complete   | mean_loss=101.3214 | duration=10.9s
14:28:27 | INFO | Epoch 40 | test  | batches=500
14:28:29 | INFO | Epoch 40 | test batch 125/500 | nll=101.1802 | mse=0.0000 | psnr=62.40
14:28:34 | INFO | Epoch 40 | test batch 250/500 | nll=101.1841 | mse=0.0000 | psnr=62.55
14:28:37 | INFO | Epoch 40 | test batch 375/500 | nll=101.1875 | mse=0.0000 | psnr=62.63
14:28:39 | INFO | Epoch 40 | test batch 500/500 | nll=101.1899 | mse=0.0000 | psnr=62.43
14:28:39 | INFO | Epoch 40 | test complete  | mean_nll=101.1873 | duration=12.0s
14:28:39 | INFO | Checkpoint saved to /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models/epoch_40_nf_model_net.pth (epoch 40)
14:28:39 | INFO | Epoch 40 summary | train=-8.8260 | val=101.3214 | test=101.1873 | smpl=0.0000 | best=False
14:28:39 | INFO | Epoch 41 started | validation=False
14:28:39 | INFO | Epoch 41 | train | batches=1500
14:28:56 | INFO | Epoch 41 | train batch 300/1500 | loss=-10.3892 | nll=-10.5269 | mse=0.0000
14:29:17 | INFO | Epoch 41 | train batch 600/1500 | loss=-10.1207 | nll=-10.2673 | mse=0.0000
14:29:35 | INFO | Epoch 41 | train batch 900/1500 | loss=-10.6517 | nll=-10.8025 | mse=0.0000
14:29:56 | INFO | Epoch 41 | train batch 1200/1500 | loss=-10.6347 | nll=-10.7798 | mse=0.0000
14:30:13 | INFO | Epoch 41 | train batch 1500/1500 | loss=-10.6435 | nll=-10.7927 | mse=0.0000
14:30:13 | INFO | Epoch 41 | train complete | mean_loss=-10.3308 | duration=94.3s
14:30:13 | INFO | Epoch 41 summary | train=-10.3308 (validation skipped)
14:30:13 | INFO | Epoch 42 started | validation=False
14:30:13 | INFO | Epoch 42 | train | batches=1500
14:30:34 | INFO | Epoch 42 | train batch 300/1500 | loss=-10.8476 | nll=-10.9996 | mse=0.0000
14:30:51 | INFO | Epoch 42 | train batch 600/1500 | loss=-10.3761 | nll=-10.5286 | mse=0.0000
14:31:12 | INFO | Epoch 42 | train batch 900/1500 | loss=-10.1360 | nll=-10.2791 | mse=0.0000
14:31:29 | INFO | Epoch 42 | train batch 1200/1500 | loss=-10.6889 | nll=-10.8347 | mse=0.0000
14:31:50 | INFO | Epoch 42 | train batch 1500/1500 | loss=-7.2600 | nll=-7.4150 | mse=0.0000
14:31:50 | INFO | Epoch 42 | train complete | mean_loss=-10.3517 | duration=96.5s
14:31:50 | INFO | Epoch 42 summary | train=-10.3517 (validation skipped)
14:31:50 | INFO | Epoch 43 started | validation=False
14:31:50 | INFO | Epoch 43 | train | batches=1500
14:32:10 | INFO | Epoch 43 | train batch 300/1500 | loss=-8.6696 | nll=-8.8257 | mse=0.0000
14:32:28 | INFO | Epoch 43 | train batch 600/1500 | loss=-10.3720 | nll=-10.5234 | mse=0.0000
14:32:48 | INFO | Epoch 43 | train batch 900/1500 | loss=-10.6746 | nll=-10.8244 | mse=0.0000
14:33:06 | INFO | Epoch 43 | train batch 1200/1500 | loss=-10.4499 | nll=-10.5979 | mse=0.0000
14:33:27 | INFO | Epoch 43 | train batch 1500/1500 | loss=-10.5533 | nll=-10.7042 | mse=0.0000
14:33:27 | INFO | Epoch 43 | train complete | mean_loss=-9.7932 | duration=96.9s
14:33:27 | INFO | Epoch 43 summary | train=-9.7932 (validation skipped)
14:33:27 | INFO | Epoch 44 started | validation=False
14:33:27 | INFO | Epoch 44 | train | batches=1500
14:33:44 | INFO | Epoch 44 | train batch 300/1500 | loss=-10.8936 | nll=-11.0297 | mse=0.0000
14:34:05 | INFO | Epoch 44 | train batch 600/1500 | loss=-10.9854 | nll=-11.1468 | mse=0.0000
14:34:23 | INFO | Epoch 44 | train batch 900/1500 | loss=-10.7994 | nll=-10.9456 | mse=0.0000
14:34:43 | INFO | Epoch 44 | train batch 1200/1500 | loss=-10.9847 | nll=-11.1250 | mse=0.0000
14:35:01 | INFO | Epoch 44 | train batch 1500/1500 | loss=-10.6347 | nll=-10.7829 | mse=0.0000
14:35:01 | INFO | Epoch 44 | train complete | mean_loss=-10.5108 | duration=94.8s
14:35:01 | INFO | Epoch 44 summary | train=-10.5108 (validation skipped)
14:35:01 | INFO | Epoch 45 started | validation=False
14:35:01 | INFO | Epoch 45 | train | batches=1500
14:35:22 | INFO | Epoch 45 | train batch 300/1500 | loss=-10.5116 | nll=-10.6579 | mse=0.0000
14:35:43 | INFO | Epoch 45 | train batch 600/1500 | loss=-8.7501 | nll=-8.9087 | mse=0.0000
14:36:00 | INFO | Epoch 45 | train batch 900/1500 | loss=-10.1907 | nll=-10.3440 | mse=0.0000
14:36:22 | INFO | Epoch 45 | train batch 1200/1500 | loss=-10.2123 | nll=-10.3607 | mse=0.0000
14:36:39 | INFO | Epoch 45 | train batch 1500/1500 | loss=-9.0108 | nll=-9.1656 | mse=0.0000
14:36:39 | INFO | Epoch 45 | train complete | mean_loss=-10.3758 | duration=97.8s
14:36:39 | INFO | Epoch 45 summary | train=-10.3758 (validation skipped)
14:36:39 | INFO | Epoch 46 started | validation=False
14:36:39 | INFO | Epoch 46 | train | batches=1500
14:37:00 | INFO | Epoch 46 | train batch 300/1500 | loss=-10.6955 | nll=-10.8565 | mse=0.0000
14:37:18 | INFO | Epoch 46 | train batch 600/1500 | loss=-8.4055 | nll=-8.5470 | mse=0.0000
14:37:38 | INFO | Epoch 46 | train batch 900/1500 | loss=-10.4350 | nll=-10.5774 | mse=0.0000
14:37:56 | INFO | Epoch 46 | train batch 1200/1500 | loss=-10.8695 | nll=-11.0067 | mse=0.0000
14:38:17 | INFO | Epoch 46 | train batch 1500/1500 | loss=-10.8990 | nll=-11.0547 | mse=0.0000
14:38:17 | INFO | Epoch 46 | train complete | mean_loss=-10.2088 | duration=98.1s
14:38:17 | INFO | Epoch 46 summary | train=-10.2088 (validation skipped)
14:38:17 | INFO | Epoch 47 started | validation=False
14:38:17 | INFO | Epoch 47 | train | batches=1500
14:38:35 | INFO | Epoch 47 | train batch 300/1500 | loss=-10.8729 | nll=-11.0243 | mse=0.0000
14:38:56 | INFO | Epoch 47 | train batch 600/1500 | loss=-10.7773 | nll=-10.9246 | mse=0.0000
14:39:17 | INFO | Epoch 47 | train batch 900/1500 | loss=-10.7152 | nll=-10.8652 | mse=0.0000
14:39:34 | INFO | Epoch 47 | train batch 1200/1500 | loss=-11.0798 | nll=-11.2305 | mse=0.0000
14:39:55 | INFO | Epoch 47 | train batch 1500/1500 | loss=-10.6397 | nll=-10.7813 | mse=0.0000
14:39:55 | INFO | Epoch 47 | train complete | mean_loss=-10.6098 | duration=98.1s
14:39:55 | INFO | Epoch 47 summary | train=-10.6098 (validation skipped)
14:39:55 | INFO | Epoch 48 started | validation=False
14:39:55 | INFO | Epoch 48 | train | batches=1500
14:40:13 | INFO | Epoch 48 | train batch 300/1500 | loss=-10.9675 | nll=-11.1192 | mse=0.0000
14:40:34 | INFO | Epoch 48 | train batch 600/1500 | loss=-11.0089 | nll=-11.1670 | mse=0.0000
14:40:51 | INFO | Epoch 48 | train batch 900/1500 | loss=-9.4043 | nll=-9.5449 | mse=0.0000
14:41:12 | INFO | Epoch 48 | train batch 1200/1500 | loss=-11.1990 | nll=-11.3383 | mse=0.0000
14:41:30 | INFO | Epoch 48 | train batch 1500/1500 | loss=-10.9767 | nll=-11.1314 | mse=0.0000
14:41:30 | INFO | Epoch 48 | train complete | mean_loss=-10.3886 | duration=94.8s
14:41:30 | INFO | Epoch 48 summary | train=-10.3886 (validation skipped)
14:41:30 | INFO | Epoch 49 started | validation=False
14:41:30 | INFO | Epoch 49 | train | batches=1500
14:41:51 | INFO | Epoch 49 | train batch 300/1500 | loss=-11.1703 | nll=-11.3211 | mse=0.0000
14:42:09 | INFO | Epoch 49 | train batch 600/1500 | loss=-9.0308 | nll=-9.1811 | mse=0.0000
14:42:30 | INFO | Epoch 49 | train batch 900/1500 | loss=-11.0817 | nll=-11.2278 | mse=0.0000
14:42:47 | INFO | Epoch 49 | train batch 1200/1500 | loss=-7.8251 | nll=-7.9781 | mse=0.0000
14:43:08 | INFO | Epoch 49 | train batch 1500/1500 | loss=-9.2188 | nll=-9.3638 | mse=0.0000
14:43:08 | INFO | Epoch 49 | train complete | mean_loss=-8.6461 | duration=97.5s
14:43:08 | INFO | Epoch 49 summary | train=-8.6461 (validation skipped)
14:43:08 | INFO | Epoch 50 started | validation=True
14:43:08 | INFO | Epoch 50 | train | batches=1500
14:43:28 | INFO | Epoch 50 | train batch 300/1500 | loss=-9.5667 | nll=-9.7208 | mse=0.0000
14:43:46 | INFO | Epoch 50 | train batch 600/1500 | loss=-9.9970 | nll=-10.1488 | mse=0.0000
14:44:06 | INFO | Epoch 50 | train batch 900/1500 | loss=-10.1663 | nll=-10.3206 | mse=0.0000
14:44:24 | INFO | Epoch 50 | train batch 1200/1500 | loss=-10.3848 | nll=-10.5319 | mse=0.0000
14:44:45 | INFO | Epoch 50 | train batch 1500/1500 | loss=-9.0410 | nll=-9.1903 | mse=0.0000
14:44:45 | INFO | Epoch 50 | train complete | mean_loss=-9.9702 | duration=97.1s
14:44:45 | INFO | Epoch 50 | val   | batches=500
14:44:47 | INFO | Epoch 50 | val batch 125/500 | loss=1.5028 | nll=1.3512 | mse=0.0000
14:44:50 | INFO | Epoch 50 | val batch 250/500 | loss=1.2967 | nll=1.1500 | mse=0.0000
14:44:53 | INFO | Epoch 50 | val batch 375/500 | loss=1.2525 | nll=1.1086 | mse=0.0000
14:44:56 | INFO | Epoch 50 | val batch 500/500 | loss=1.4891 | nll=1.3380 | mse=0.0000
14:44:56 | INFO | Epoch 50 | val complete   | mean_loss=1.3668 | duration=11.2s
14:44:56 | INFO | Epoch 50 | test  | batches=500
14:44:58 | INFO | Epoch 50 | test batch 125/500 | nll=0.9101 | mse=0.0000 | psnr=62.40
14:45:00 | INFO | Epoch 50 | test batch 250/500 | nll=0.7353 | mse=0.0000 | psnr=62.55
14:45:02 | INFO | Epoch 50 | test batch 375/500 | nll=0.6592 | mse=0.0000 | psnr=62.63
14:45:04 | INFO | Epoch 50 | test batch 500/500 | nll=1.0023 | mse=0.0000 | psnr=62.43
14:45:04 | INFO | Epoch 50 | test complete  | mean_nll=0.7905 | duration=8.3s
14:45:04 | INFO | Checkpoint saved to /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models/epoch_50_nf_model_net.pth (epoch 50)
14:45:04 | INFO | Epoch 50 summary | train=-9.9702 | val=1.3668 | test=0.7905 | smpl=0.0000 | best=False
14:45:04 | INFO | Epoch 51 started | validation=False
14:45:04 | INFO | Epoch 51 | train | batches=1500
14:45:25 | INFO | Epoch 51 | train batch 300/1500 | loss=-10.7843 | nll=-10.9348 | mse=0.0000
14:45:42 | INFO | Epoch 51 | train batch 600/1500 | loss=-10.9710 | nll=-11.1101 | mse=0.0000
14:46:03 | INFO | Epoch 51 | train batch 900/1500 | loss=-10.0497 | nll=-10.2006 | mse=0.0000
14:46:21 | INFO | Epoch 51 | train batch 1200/1500 | loss=-8.1260 | nll=-8.2750 | mse=0.0000
14:46:42 | INFO | Epoch 51 | train batch 1500/1500 | loss=-9.2402 | nll=-9.3784 | mse=0.0000
14:46:42 | INFO | Epoch 51 | train complete | mean_loss=-10.5469 | duration=97.6s
14:46:42 | INFO | Epoch 51 summary | train=-10.5469 (validation skipped)
14:46:42 | INFO | Epoch 52 started | validation=False
14:46:42 | INFO | Epoch 52 | train | batches=1500
14:47:02 | INFO | Epoch 52 | train batch 300/1500 | loss=-11.1867 | nll=-11.3286 | mse=0.0000
14:47:20 | INFO | Epoch 52 | train batch 600/1500 | loss=-8.3061 | nll=-8.4486 | mse=0.0000
14:47:41 | INFO | Epoch 52 | train batch 900/1500 | loss=-8.8754 | nll=-9.0253 | mse=0.0000
14:47:59 | INFO | Epoch 52 | train batch 1200/1500 | loss=-9.2085 | nll=-9.3612 | mse=0.0000
14:48:20 | INFO | Epoch 52 | train batch 1500/1500 | loss=-9.5059 | nll=-9.6652 | mse=0.0000
14:48:20 | INFO | Epoch 52 | train complete | mean_loss=-9.6187 | duration=98.0s
14:48:20 | INFO | Epoch 52 summary | train=-9.6187 (validation skipped)
14:48:20 | INFO | Epoch 53 started | validation=False
14:48:20 | INFO | Epoch 53 | train | batches=1500
14:48:37 | INFO | Epoch 53 | train batch 300/1500 | loss=-9.7828 | nll=-9.9341 | mse=0.0000
14:48:58 | INFO | Epoch 53 | train batch 600/1500 | loss=-6.2194 | nll=-6.3620 | mse=0.0000
14:49:15 | INFO | Epoch 53 | train batch 900/1500 | loss=-9.0274 | nll=-9.1647 | mse=0.0000
14:49:36 | INFO | Epoch 53 | train batch 1200/1500 | loss=-9.3552 | nll=-9.5028 | mse=0.0000
14:49:54 | INFO | Epoch 53 | train batch 1500/1500 | loss=-9.7012 | nll=-9.8513 | mse=0.0000
14:49:54 | INFO | Epoch 53 | train complete | mean_loss=-8.6843 | duration=94.2s
14:49:54 | INFO | Epoch 53 summary | train=-8.6843 (validation skipped)
14:49:54 | INFO | Epoch 54 started | validation=False
14:49:54 | INFO | Epoch 54 | train | batches=1500
14:50:15 | INFO | Epoch 54 | train batch 300/1500 | loss=-9.9366 | nll=-10.0915 | mse=0.0000
14:50:32 | INFO | Epoch 54 | train batch 600/1500 | loss=-9.7383 | nll=-9.8930 | mse=0.0000
14:50:53 | INFO | Epoch 54 | train batch 900/1500 | loss=-10.3893 | nll=-10.5472 | mse=0.0000
14:51:14 | INFO | Epoch 54 | train batch 1200/1500 | loss=-10.6423 | nll=-10.7853 | mse=0.0000
14:51:31 | INFO | Epoch 54 | train batch 1500/1500 | loss=-10.5477 | nll=-10.6840 | mse=0.0000
14:51:31 | INFO | Epoch 54 | train complete | mean_loss=-10.1449 | duration=97.2s
14:51:31 | INFO | Epoch 54 summary | train=-10.1449 (validation skipped)
14:51:31 | INFO | Epoch 55 started | validation=False
14:51:31 | INFO | Epoch 55 | train | batches=1500
14:51:52 | INFO | Epoch 55 | train batch 300/1500 | loss=-10.6171 | nll=-10.7590 | mse=0.0000
14:52:10 | INFO | Epoch 55 | train batch 600/1500 | loss=-10.3611 | nll=-10.5071 | mse=0.0000
14:52:30 | INFO | Epoch 55 | train batch 900/1500 | loss=-10.5340 | nll=-10.6785 | mse=0.0000
14:52:48 | INFO | Epoch 55 | train batch 1200/1500 | loss=-10.7901 | nll=-10.9533 | mse=0.0000
14:53:09 | INFO | Epoch 55 | train batch 1500/1500 | loss=-10.4599 | nll=-10.6297 | mse=0.0000
14:53:09 | INFO | Epoch 55 | train complete | mean_loss=-10.1238 | duration=98.1s
14:53:09 | INFO | Epoch 55 summary | train=-10.1238 (validation skipped)
14:53:09 | INFO | Epoch 56 started | validation=False
14:53:09 | INFO | Epoch 56 | train | batches=1500
14:53:27 | INFO | Epoch 56 | train batch 300/1500 | loss=-11.1050 | nll=-11.2544 | mse=0.0000
14:53:48 | INFO | Epoch 56 | train batch 600/1500 | loss=-11.0484 | nll=-11.1919 | mse=0.0000
14:54:05 | INFO | Epoch 56 | train batch 900/1500 | loss=-11.1334 | nll=-11.2760 | mse=0.0000
14:54:26 | INFO | Epoch 56 | train batch 1200/1500 | loss=-9.0699 | nll=-9.2081 | mse=0.0000
14:54:47 | INFO | Epoch 56 | train batch 1500/1500 | loss=-11.1405 | nll=-11.2953 | mse=0.0000
14:54:47 | INFO | Epoch 56 | train complete | mean_loss=-9.9959 | duration=97.6s
14:54:47 | INFO | Epoch 56 summary | train=-9.9959 (validation skipped)
14:54:47 | INFO | Epoch 57 started | validation=False
14:54:47 | INFO | Epoch 57 | train | batches=1500
14:55:04 | INFO | Epoch 57 | train batch 300/1500 | loss=-8.7628 | nll=-8.8894 | mse=0.0000
14:55:25 | INFO | Epoch 57 | train batch 600/1500 | loss=-9.6778 | nll=-9.8280 | mse=0.0000
14:55:43 | INFO | Epoch 57 | train batch 900/1500 | loss=-10.2002 | nll=-10.3481 | mse=0.0000
14:56:04 | INFO | Epoch 57 | train batch 1200/1500 | loss=-7.3369 | nll=-7.4898 | mse=0.0000
14:56:21 | INFO | Epoch 57 | train batch 1500/1500 | loss=-7.8245 | nll=-7.9707 | mse=0.0000
14:56:21 | INFO | Epoch 57 | train complete | mean_loss=-8.1115 | duration=94.5s
14:56:21 | INFO | Epoch 57 summary | train=-8.1115 (validation skipped)
14:56:21 | INFO | Epoch 58 started | validation=False
14:56:21 | INFO | Epoch 58 | train | batches=1500
14:56:42 | INFO | Epoch 58 | train batch 300/1500 | loss=-8.4355 | nll=-8.5872 | mse=0.0000
14:57:00 | INFO | Epoch 58 | train batch 600/1500 | loss=-9.1719 | nll=-9.3087 | mse=0.0000
14:57:21 | INFO | Epoch 58 | train batch 900/1500 | loss=-9.8144 | nll=-9.9655 | mse=0.0000
14:57:38 | INFO | Epoch 58 | train batch 1200/1500 | loss=-10.2906 | nll=-10.4434 | mse=0.0000
14:57:59 | INFO | Epoch 58 | train batch 1500/1500 | loss=-10.3393 | nll=-10.4813 | mse=0.0000
14:57:59 | INFO | Epoch 58 | train complete | mean_loss=-9.3695 | duration=97.8s
14:57:59 | INFO | Epoch 58 summary | train=-9.3695 (validation skipped)
14:57:59 | INFO | Epoch 59 started | validation=False
14:57:59 | INFO | Epoch 59 | train | batches=1500
14:58:20 | INFO | Epoch 59 | train batch 300/1500 | loss=-10.3353 | nll=-10.4828 | mse=0.0000
14:58:37 | INFO | Epoch 59 | train batch 600/1500 | loss=-10.0576 | nll=-10.1996 | mse=0.0000
14:58:58 | INFO | Epoch 59 | train batch 900/1500 | loss=-10.9756 | nll=-11.1230 | mse=0.0000
14:59:16 | INFO | Epoch 59 | train batch 1200/1500 | loss=-10.1666 | nll=-10.3223 | mse=0.0000
14:59:37 | INFO | Epoch 59 | train batch 1500/1500 | loss=-10.8517 | nll=-11.0001 | mse=0.0000
14:59:37 | INFO | Epoch 59 | train complete | mean_loss=-10.3945 | duration=97.8s
14:59:37 | INFO | Epoch 59 summary | train=-10.3945 (validation skipped)
14:59:37 | INFO | Epoch 60 started | validation=True
14:59:37 | INFO | Epoch 60 | train | batches=1500
14:59:54 | INFO | Epoch 60 | train batch 300/1500 | loss=-10.3872 | nll=-10.5396 | mse=0.0000
15:00:15 | INFO | Epoch 60 | train batch 600/1500 | loss=-11.2095 | nll=-11.3620 | mse=0.0000
15:00:32 | INFO | Epoch 60 | train batch 900/1500 | loss=-11.2915 | nll=-11.4342 | mse=0.0000
15:00:53 | INFO | Epoch 60 | train batch 1200/1500 | loss=-11.4370 | nll=-11.5845 | mse=0.0000
15:01:11 | INFO | Epoch 60 | train batch 1500/1500 | loss=-10.1637 | nll=-10.3225 | mse=0.0000
15:01:11 | INFO | Epoch 60 | train complete | mean_loss=-10.7929 | duration=93.8s
15:01:11 | INFO | Epoch 60 | val   | batches=500
15:01:13 | INFO | Epoch 60 | val batch 125/500 | loss=-2.7077 | nll=-2.8594 | mse=0.0000
15:01:19 | INFO | Epoch 60 | val batch 250/500 | loss=-2.8175 | nll=-2.9641 | mse=0.0000
15:01:22 | INFO | Epoch 60 | val batch 375/500 | loss=-3.0640 | nll=-3.2080 | mse=0.0000
15:01:25 | INFO | Epoch 60 | val batch 500/500 | loss=-2.8785 | nll=-3.0296 | mse=0.0000
15:01:25 | INFO | Epoch 60 | val complete   | mean_loss=-2.8491 | duration=13.9s
15:01:25 | INFO | Epoch 60 | test  | batches=500
15:01:27 | INFO | Epoch 60 | test batch 125/500 | nll=-2.5021 | mse=0.0000 | psnr=62.40
15:01:29 | INFO | Epoch 60 | test batch 250/500 | nll=-2.6428 | mse=0.0000 | psnr=62.55
15:01:30 | INFO | Epoch 60 | test batch 375/500 | nll=-2.8133 | mse=0.0000 | psnr=62.63
15:01:33 | INFO | Epoch 60 | test batch 500/500 | nll=-2.5259 | mse=0.0000 | psnr=62.43
15:01:33 | INFO | Epoch 60 | test complete  | mean_nll=-2.6209 | duration=7.9s
15:01:33 | INFO | Checkpoint saved to /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models/epoch_60_nf_model_net.pth (epoch 60)
15:01:33 | INFO | Epoch 60 summary | train=-10.7929 | val=-2.8491 | test=-2.6209 | smpl=0.0000 | best=False
15:01:33 | INFO | Epoch 61 started | validation=False
15:01:33 | INFO | Epoch 61 | train | batches=1500
15:01:50 | INFO | Epoch 61 | train batch 300/1500 | loss=-11.0666 | nll=-11.2216 | mse=0.0000
15:02:11 | INFO | Epoch 61 | train batch 600/1500 | loss=-8.7785 | nll=-8.9301 | mse=0.0000
15:02:31 | INFO | Epoch 61 | train batch 900/1500 | loss=-9.5661 | nll=-9.7076 | mse=0.0000
15:02:48 | INFO | Epoch 61 | train batch 1200/1500 | loss=-10.0171 | nll=-10.1578 | mse=0.0000
15:03:09 | INFO | Epoch 61 | train batch 1500/1500 | loss=-10.1714 | nll=-10.3292 | mse=0.0000
15:03:09 | INFO | Epoch 61 | train complete | mean_loss=-9.1812 | duration=96.6s
15:03:09 | INFO | Epoch 61 summary | train=-9.1812 (validation skipped)
15:03:09 | INFO | Epoch 62 started | validation=False
15:03:09 | INFO | Epoch 62 | train | batches=1500
15:03:27 | INFO | Epoch 62 | train batch 300/1500 | loss=-10.3521 | nll=-10.5026 | mse=0.0000
15:03:47 | INFO | Epoch 62 | train batch 600/1500 | loss=-10.1515 | nll=-10.2888 | mse=0.0000
15:04:04 | INFO | Epoch 62 | train batch 900/1500 | loss=-10.6983 | nll=-10.8421 | mse=0.0000
15:04:25 | INFO | Epoch 62 | train batch 1200/1500 | loss=-10.7732 | nll=-10.9206 | mse=0.0000
15:04:42 | INFO | Epoch 62 | train batch 1500/1500 | loss=-10.8796 | nll=-11.0267 | mse=0.0000
15:04:42 | INFO | Epoch 62 | train complete | mean_loss=-10.5328 | duration=92.7s
15:04:42 | INFO | Epoch 62 summary | train=-10.5328 (validation skipped)
15:04:42 | INFO | Epoch 63 started | validation=False
15:04:42 | INFO | Epoch 63 | train | batches=1500
15:05:02 | INFO | Epoch 63 | train batch 300/1500 | loss=-7.8390 | nll=-7.9949 | mse=0.0000
15:05:20 | INFO | Epoch 63 | train batch 600/1500 | loss=-8.4129 | nll=-8.5548 | mse=0.0000
15:05:40 | INFO | Epoch 63 | train batch 900/1500 | loss=-8.7014 | nll=-8.8492 | mse=0.0000
15:05:58 | INFO | Epoch 63 | train batch 1200/1500 | loss=-9.0625 | nll=-9.2026 | mse=0.0000
15:06:18 | INFO | Epoch 63 | train batch 1500/1500 | loss=-9.4523 | nll=-9.5980 | mse=0.0000
15:06:18 | INFO | Epoch 63 | train complete | mean_loss=-8.8080 | duration=96.6s
15:06:18 | INFO | Epoch 63 summary | train=-8.8080 (validation skipped)
15:06:18 | INFO | Epoch 64 started | validation=False
15:06:18 | INFO | Epoch 64 | train | batches=1500
15:06:39 | INFO | Epoch 64 | train batch 300/1500 | loss=-9.5532 | nll=-9.7091 | mse=0.0000
15:06:57 | INFO | Epoch 64 | train batch 600/1500 | loss=-10.0077 | nll=-10.1508 | mse=0.0000
15:07:17 | INFO | Epoch 64 | train batch 900/1500 | loss=-10.9399 | nll=-11.1025 | mse=0.0000
15:07:35 | INFO | Epoch 64 | train batch 1200/1500 | loss=-9.3108 | nll=-9.4536 | mse=0.0000
15:07:55 | INFO | Epoch 64 | train batch 1500/1500 | loss=-9.5253 | nll=-9.6802 | mse=0.0000
15:07:55 | INFO | Epoch 64 | train complete | mean_loss=-9.7686 | duration=96.8s
15:07:55 | INFO | Epoch 64 summary | train=-9.7686 (validation skipped)
15:07:55 | INFO | Epoch 65 started | validation=False
15:07:55 | INFO | Epoch 65 | train | batches=1500
15:08:13 | INFO | Epoch 65 | train batch 300/1500 | loss=-10.4082 | nll=-10.5500 | mse=0.0000
15:08:34 | INFO | Epoch 65 | train batch 600/1500 | loss=-9.5277 | nll=-9.6689 | mse=0.0000
15:08:51 | INFO | Epoch 65 | train batch 900/1500 | loss=-11.0009 | nll=-11.1625 | mse=0.0000
15:09:12 | INFO | Epoch 65 | train batch 1200/1500 | loss=-11.0107 | nll=-11.1617 | mse=0.0000
15:09:30 | INFO | Epoch 65 | train batch 1500/1500 | loss=-8.8950 | nll=-9.0418 | mse=0.0000
15:09:30 | INFO | Epoch 65 | train complete | mean_loss=-10.1772 | duration=94.4s
15:09:30 | INFO | Epoch 65 summary | train=-10.1772 (validation skipped)
15:09:30 | INFO | Epoch 66 started | validation=False
15:09:30 | INFO | Epoch 66 | train | batches=1500
15:09:51 | INFO | Epoch 66 | train batch 300/1500 | loss=-9.0749 | nll=-9.2239 | mse=0.0000
15:10:08 | INFO | Epoch 66 | train batch 600/1500 | loss=-9.6174 | nll=-9.7852 | mse=0.0000
15:10:29 | INFO | Epoch 66 | train batch 900/1500 | loss=-9.8733 | nll=-10.0215 | mse=0.0000
15:10:50 | INFO | Epoch 66 | train batch 1200/1500 | loss=-10.5651 | nll=-10.7187 | mse=0.0000
15:11:07 | INFO | Epoch 66 | train batch 1500/1500 | loss=-9.5107 | nll=-9.6730 | mse=0.0000
15:11:07 | INFO | Epoch 66 | train complete | mean_loss=-9.5685 | duration=97.6s
15:11:07 | INFO | Epoch 66 summary | train=-9.5685 (validation skipped)
15:11:07 | INFO | Epoch 67 started | validation=False
15:11:07 | INFO | Epoch 67 | train | batches=1500
15:11:28 | INFO | Epoch 67 | train batch 300/1500 | loss=-10.3934 | nll=-10.5431 | mse=0.0000
15:11:46 | INFO | Epoch 67 | train batch 600/1500 | loss=-10.3816 | nll=-10.5259 | mse=0.0000
15:12:06 | INFO | Epoch 67 | train batch 900/1500 | loss=-10.7579 | nll=-10.8980 | mse=0.0000
15:12:24 | INFO | Epoch 67 | train batch 1200/1500 | loss=-8.8420 | nll=-8.9948 | mse=0.0000
15:12:45 | INFO | Epoch 67 | train batch 1500/1500 | loss=-9.9877 | nll=-10.1386 | mse=0.0000
15:12:45 | INFO | Epoch 67 | train complete | mean_loss=-9.7436 | duration=97.4s
15:12:45 | INFO | Epoch 67 summary | train=-9.7436 (validation skipped)
15:12:45 | INFO | Epoch 68 started | validation=False
15:12:45 | INFO | Epoch 68 | train | batches=1500
15:13:02 | INFO | Epoch 68 | train batch 300/1500 | loss=-10.6580 | nll=-10.8118 | mse=0.0000
15:13:23 | INFO | Epoch 68 | train batch 600/1500 | loss=-8.9269 | nll=-9.0807 | mse=0.0000
15:13:41 | INFO | Epoch 68 | train batch 900/1500 | loss=-10.4389 | nll=-10.5872 | mse=0.0000
15:14:02 | INFO | Epoch 68 | train batch 1200/1500 | loss=-6.9332 | nll=-7.0896 | mse=0.0000
15:14:19 | INFO | Epoch 68 | train batch 1500/1500 | loss=-7.2839 | nll=-7.4255 | mse=0.0000
15:14:19 | INFO | Epoch 68 | train complete | mean_loss=-8.4230 | duration=94.1s
15:14:19 | INFO | Epoch 68 summary | train=-8.4230 (validation skipped)
15:14:19 | INFO | Epoch 69 started | validation=False
15:14:19 | INFO | Epoch 69 | train | batches=1500
15:14:40 | INFO | Epoch 69 | train batch 300/1500 | loss=-7.5355 | nll=-7.6826 | mse=0.0000
15:15:01 | INFO | Epoch 69 | train batch 600/1500 | loss=-7.7978 | nll=-7.9399 | mse=0.0000
15:15:18 | INFO | Epoch 69 | train batch 900/1500 | loss=-8.0086 | nll=-8.1512 | mse=0.0000
15:15:39 | INFO | Epoch 69 | train batch 1200/1500 | loss=-8.2321 | nll=-8.3831 | mse=0.0000
15:15:56 | INFO | Epoch 69 | train batch 1500/1500 | loss=-8.6221 | nll=-8.7667 | mse=0.0000
15:15:56 | INFO | Epoch 69 | train complete | mean_loss=-7.8812 | duration=97.6s
15:15:56 | INFO | Epoch 69 summary | train=-7.8812 (validation skipped)
15:15:56 | INFO | Epoch 70 started | validation=True
15:15:56 | INFO | Epoch 70 | train | batches=1500
15:16:18 | INFO | Epoch 70 | train batch 300/1500 | loss=-8.8919 | nll=-9.0397 | mse=0.0000
15:16:35 | INFO | Epoch 70 | train batch 600/1500 | loss=-9.0940 | nll=-9.2372 | mse=0.0000
15:16:56 | INFO | Epoch 70 | train batch 900/1500 | loss=-9.0852 | nll=-9.2406 | mse=0.0000
15:17:14 | INFO | Epoch 70 | train batch 1200/1500 | loss=-9.3761 | nll=-9.5240 | mse=0.0000
15:17:35 | INFO | Epoch 70 | train batch 1500/1500 | loss=-9.1606 | nll=-9.3008 | mse=0.0000
15:17:35 | INFO | Epoch 70 | train complete | mean_loss=-9.1014 | duration=98.2s
15:17:35 | INFO | Epoch 70 | val   | batches=500
15:17:38 | INFO | Epoch 70 | val batch 125/500 | loss=2407.5618 | nll=2407.4102 | mse=0.0000
15:17:40 | INFO | Epoch 70 | val batch 250/500 | loss=2426.4500 | nll=2426.3032 | mse=0.0000
15:17:43 | INFO | Epoch 70 | val batch 375/500 | loss=2446.8794 | nll=2446.7354 | mse=0.0000
15:17:46 | INFO | Epoch 70 | val batch 500/500 | loss=2420.6062 | nll=2420.4551 | mse=0.0000
15:17:46 | INFO | Epoch 70 | val complete   | mean_loss=2424.5870 | duration=10.9s
15:17:46 | INFO | Epoch 70 | test  | batches=500
15:17:48 | INFO | Epoch 70 | test batch 125/500 | nll=2413.9988 | mse=0.0000 | psnr=62.40
15:17:50 | INFO | Epoch 70 | test batch 250/500 | nll=2429.6646 | mse=0.0000 | psnr=62.55
15:17:52 | INFO | Epoch 70 | test batch 375/500 | nll=2454.1812 | mse=0.0000 | psnr=62.63
15:17:54 | INFO | Epoch 70 | test batch 500/500 | nll=2434.3374 | mse=0.0000 | psnr=62.43
15:17:54 | INFO | Epoch 70 | test complete  | mean_nll=2434.5986 | duration=8.3s
15:17:54 | INFO | Checkpoint saved to /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models/epoch_70_nf_model_net.pth (epoch 70)
15:17:54 | INFO | Epoch 70 summary | train=-9.1014 | val=2424.5870 | test=2434.5986 | smpl=0.0000 | best=False
15:17:54 | INFO | Epoch 71 started | validation=False
15:17:54 | INFO | Epoch 71 | train | batches=1500
15:18:15 | INFO | Epoch 71 | train batch 300/1500 | loss=-9.6234 | nll=-9.7688 | mse=0.0000
15:18:33 | INFO | Epoch 71 | train batch 600/1500 | loss=-9.7944 | nll=-9.9275 | mse=0.0000
15:18:54 | INFO | Epoch 71 | train batch 900/1500 | loss=-10.1351 | nll=-10.2796 | mse=0.0000
15:19:15 | INFO | Epoch 71 | train batch 1200/1500 | loss=-10.5625 | nll=-10.7057 | mse=0.0000
15:19:32 | INFO | Epoch 71 | train batch 1500/1500 | loss=-10.2924 | nll=-10.4470 | mse=0.0000
15:19:32 | INFO | Epoch 71 | train complete | mean_loss=-9.9087 | duration=98.3s
15:19:32 | INFO | Epoch 71 summary | train=-9.9087 (validation skipped)
15:19:32 | INFO | Epoch 72 started | validation=False
15:19:32 | INFO | Epoch 72 | train | batches=1500
15:19:53 | INFO | Epoch 72 | train batch 300/1500 | loss=-10.7558 | nll=-10.8902 | mse=0.0000
15:20:11 | INFO | Epoch 72 | train batch 600/1500 | loss=-10.9738 | nll=-11.1260 | mse=0.0000
15:20:32 | INFO | Epoch 72 | train batch 900/1500 | loss=-8.7299 | nll=-8.8792 | mse=0.0000
15:20:50 | INFO | Epoch 72 | train batch 1200/1500 | loss=-8.9481 | nll=-9.0973 | mse=0.0000
15:21:11 | INFO | Epoch 72 | train batch 1500/1500 | loss=-9.1741 | nll=-9.3179 | mse=0.0000
15:21:11 | INFO | Epoch 72 | train complete | mean_loss=-9.2821 | duration=98.7s
15:21:11 | INFO | Epoch 72 summary | train=-9.2821 (validation skipped)
15:21:11 | INFO | Epoch 73 started | validation=False
15:21:11 | INFO | Epoch 73 | train | batches=1500
15:21:29 | INFO | Epoch 73 | train batch 300/1500 | loss=-9.3932 | nll=-9.5485 | mse=0.0000
15:21:50 | INFO | Epoch 73 | train batch 600/1500 | loss=-9.6494 | nll=-9.8057 | mse=0.0000
15:22:07 | INFO | Epoch 73 | train batch 900/1500 | loss=-9.1290 | nll=-9.2771 | mse=0.0000
15:22:29 | INFO | Epoch 73 | train batch 1200/1500 | loss=-9.8452 | nll=-9.9898 | mse=0.0000
15:22:50 | INFO | Epoch 73 | train batch 1500/1500 | loss=-10.3286 | nll=-10.4775 | mse=0.0000
15:22:50 | INFO | Epoch 73 | train complete | mean_loss=-9.2396 | duration=98.8s
15:22:50 | INFO | Epoch 73 summary | train=-9.2396 (validation skipped)
15:22:50 | INFO | Epoch 74 started | validation=False
15:22:50 | INFO | Epoch 74 | train | batches=1500
15:23:07 | INFO | Epoch 74 | train batch 300/1500 | loss=-10.7698 | nll=-10.9208 | mse=0.0000
15:23:29 | INFO | Epoch 74 | train batch 600/1500 | loss=-11.1363 | nll=-11.2734 | mse=0.0000
15:23:46 | INFO | Epoch 74 | train batch 900/1500 | loss=-11.1056 | nll=-11.2550 | mse=0.0000
15:24:07 | INFO | Epoch 74 | train batch 1200/1500 | loss=-9.0019 | nll=-9.1410 | mse=0.0000
15:24:25 | INFO | Epoch 74 | train batch 1500/1500 | loss=-9.2945 | nll=-9.4420 | mse=0.0000
15:24:25 | INFO | Epoch 74 | train complete | mean_loss=-10.0082 | duration=95.2s
15:24:25 | INFO | Epoch 74 summary | train=-10.0082 (validation skipped)
15:24:25 | INFO | Epoch 75 started | validation=False
15:24:25 | INFO | Epoch 75 | train | batches=1500
15:24:46 | INFO | Epoch 75 | train batch 300/1500 | loss=-9.5304 | nll=-9.6858 | mse=0.0000
15:25:04 | INFO | Epoch 75 | train batch 600/1500 | loss=-9.7903 | nll=-9.9381 | mse=0.0000
15:25:25 | INFO | Epoch 75 | train batch 900/1500 | loss=-9.9321 | nll=-10.0816 | mse=0.0000
15:25:42 | INFO | Epoch 75 | train batch 1200/1500 | loss=-9.7667 | nll=-9.9154 | mse=0.0000
15:26:04 | INFO | Epoch 75 | train batch 1500/1500 | loss=-11.0600 | nll=-11.2108 | mse=0.0000
15:26:04 | INFO | Epoch 75 | train complete | mean_loss=-9.7196 | duration=98.6s
15:26:04 | INFO | Epoch 75 summary | train=-9.7196 (validation skipped)
15:26:04 | INFO | Epoch 76 started | validation=False
15:26:04 | INFO | Epoch 76 | train | batches=1500
15:26:25 | INFO | Epoch 76 | train batch 300/1500 | loss=-9.1717 | nll=-9.3250 | mse=0.0000
15:26:42 | INFO | Epoch 76 | train batch 600/1500 | loss=-10.3802 | nll=-10.5260 | mse=0.0000
15:27:03 | INFO | Epoch 76 | train batch 900/1500 | loss=-10.7414 | nll=-10.8839 | mse=0.0000
15:27:21 | INFO | Epoch 76 | train batch 1200/1500 | loss=-10.8495 | nll=-10.9920 | mse=0.0000
15:27:42 | INFO | Epoch 76 | train batch 1500/1500 | loss=-11.2125 | nll=-11.3583 | mse=0.0000
15:27:42 | INFO | Epoch 76 | train complete | mean_loss=-10.2518 | duration=98.4s
15:27:42 | INFO | Epoch 76 summary | train=-10.2518 (validation skipped)
15:27:42 | INFO | Epoch 77 started | validation=False
15:27:42 | INFO | Epoch 77 | train | batches=1500
15:28:00 | INFO | Epoch 77 | train batch 300/1500 | loss=-10.7678 | nll=-10.9171 | mse=0.0000
15:28:20 | INFO | Epoch 77 | train batch 600/1500 | loss=-11.0623 | nll=-11.2100 | mse=0.0000
15:28:38 | INFO | Epoch 77 | train batch 900/1500 | loss=-2.3330 | nll=-2.4765 | mse=0.0000
15:28:59 | INFO | Epoch 77 | train batch 1200/1500 | loss=-10.0414 | nll=-10.2021 | mse=0.0000
15:29:17 | INFO | Epoch 77 | train batch 1500/1500 | loss=-10.5367 | nll=-10.6907 | mse=0.0000
15:29:17 | INFO | Epoch 77 | train complete | mean_loss=-10.1294 | duration=94.7s
15:29:17 | INFO | Epoch 77 summary | train=-10.1294 (validation skipped)
15:29:17 | INFO | Epoch 78 started | validation=False
15:29:17 | INFO | Epoch 78 | train | batches=1500
15:29:37 | INFO | Epoch 78 | train batch 300/1500 | loss=-10.8928 | nll=-11.0436 | mse=0.0000
15:29:59 | INFO | Epoch 78 | train batch 600/1500 | loss=-11.0740 | nll=-11.2168 | mse=0.0000
15:30:16 | INFO | Epoch 78 | train batch 900/1500 | loss=-11.3385 | nll=-11.4862 | mse=0.0000
15:30:37 | INFO | Epoch 78 | train batch 1200/1500 | loss=-8.1938 | nll=-8.3438 | mse=0.0000
15:30:54 | INFO | Epoch 78 | train batch 1500/1500 | loss=-8.9141 | nll=-9.0634 | mse=0.0000
15:30:54 | INFO | Epoch 78 | train complete | mean_loss=-10.2347 | duration=97.5s
15:30:54 | INFO | Epoch 78 summary | train=-10.2347 (validation skipped)
15:30:54 | INFO | Epoch 79 started | validation=False
15:30:54 | INFO | Epoch 79 | train | batches=1500
15:31:15 | INFO | Epoch 79 | train batch 300/1500 | loss=-9.1769 | nll=-9.3277 | mse=0.0000
15:31:33 | INFO | Epoch 79 | train batch 600/1500 | loss=-9.4870 | nll=-9.6484 | mse=0.0000
15:31:54 | INFO | Epoch 79 | train batch 900/1500 | loss=-10.7479 | nll=-10.8977 | mse=0.0000
15:32:11 | INFO | Epoch 79 | train batch 1200/1500 | loss=-9.4467 | nll=-9.6027 | mse=0.0000
15:32:33 | INFO | Epoch 79 | train batch 1500/1500 | loss=-9.9085 | nll=-10.0511 | mse=0.0000
15:32:33 | INFO | Epoch 79 | train complete | mean_loss=-9.6171 | duration=98.4s
15:32:33 | INFO | Epoch 79 summary | train=-9.6171 (validation skipped)
15:32:33 | INFO | Epoch 80 started | validation=True
15:32:33 | INFO | Epoch 80 | train | batches=1500
15:32:50 | INFO | Epoch 80 | train batch 300/1500 | loss=-9.2654 | nll=-9.4132 | mse=0.0000
15:33:11 | INFO | Epoch 80 | train batch 600/1500 | loss=-9.6140 | nll=-9.7649 | mse=0.0000
15:33:29 | INFO | Epoch 80 | train batch 900/1500 | loss=-10.0411 | nll=-10.1907 | mse=0.0000
15:33:50 | INFO | Epoch 80 | train batch 1200/1500 | loss=-9.3318 | nll=-9.4655 | mse=0.0000
15:34:12 | INFO | Epoch 80 | train batch 1500/1500 | loss=-9.7179 | nll=-9.8630 | mse=0.0000
15:34:12 | INFO | Epoch 80 | train complete | mean_loss=-9.6038 | duration=99.0s
15:34:12 | INFO | Epoch 80 | val   | batches=500
15:34:14 | INFO | Epoch 80 | val batch 125/500 | loss=26.0727 | nll=25.9210 | mse=0.0000
15:34:17 | INFO | Epoch 80 | val batch 250/500 | loss=26.0670 | nll=25.9203 | mse=0.0000
15:34:20 | INFO | Epoch 80 | val batch 375/500 | loss=26.0628 | nll=25.9189 | mse=0.0000
15:34:23 | INFO | Epoch 80 | val batch 500/500 | loss=26.0765 | nll=25.9254 | mse=0.0000
15:34:23 | INFO | Epoch 80 | val complete   | mean_loss=26.0721 | duration=11.3s
15:34:23 | INFO | Epoch 80 | test  | batches=500
15:34:25 | INFO | Epoch 80 | test batch 125/500 | nll=25.9552 | mse=0.0000 | psnr=62.40
15:34:27 | INFO | Epoch 80 | test batch 250/500 | nll=25.9640 | mse=0.0000 | psnr=62.55
15:34:29 | INFO | Epoch 80 | test batch 375/500 | nll=25.9753 | mse=0.0000 | psnr=62.63
15:34:31 | INFO | Epoch 80 | test batch 500/500 | nll=25.9857 | mse=0.0000 | psnr=62.43
15:34:31 | INFO | Epoch 80 | test complete  | mean_nll=25.9734 | duration=8.6s
15:34:32 | INFO | Checkpoint saved to /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models/epoch_80_nf_model_net.pth (epoch 80)
15:34:32 | INFO | Epoch 80 summary | train=-9.6038 | val=26.0721 | test=25.9734 | smpl=0.0000 | best=False
15:34:32 | INFO | Epoch 81 started | validation=False
15:34:32 | INFO | Epoch 81 | train | batches=1500
15:34:53 | INFO | Epoch 81 | train batch 300/1500 | loss=-11.2800 | nll=-11.4282 | mse=0.0000
15:35:10 | INFO | Epoch 81 | train batch 600/1500 | loss=-11.2427 | nll=-11.3873 | mse=0.0000
15:35:32 | INFO | Epoch 81 | train batch 900/1500 | loss=-9.9106 | nll=-10.0595 | mse=0.0000
15:35:50 | INFO | Epoch 81 | train batch 1200/1500 | loss=-11.3009 | nll=-11.4409 | mse=0.0000
15:36:11 | INFO | Epoch 81 | train batch 1500/1500 | loss=-10.7629 | nll=-10.9042 | mse=0.0000
15:36:11 | INFO | Epoch 81 | train complete | mean_loss=-10.4422 | duration=99.2s
15:36:11 | INFO | Epoch 81 summary | train=-10.4422 (validation skipped)
15:36:11 | INFO | Epoch 82 started | validation=False
15:36:11 | INFO | Epoch 82 | train | batches=1500
15:36:28 | INFO | Epoch 82 | train batch 300/1500 | loss=-11.3297 | nll=-11.4826 | mse=0.0000
15:36:50 | INFO | Epoch 82 | train batch 600/1500 | loss=-9.6669 | nll=-9.8266 | mse=0.0000
15:37:11 | INFO | Epoch 82 | train batch 900/1500 | loss=-9.5627 | nll=-9.7255 | mse=0.0000
15:37:31 | INFO | Epoch 82 | train batch 1200/1500 | loss=-8.7330 | nll=-8.8779 | mse=0.0000
15:37:53 | INFO | Epoch 82 | train batch 1500/1500 | loss=-9.9862 | nll=-10.1405 | mse=0.0000
15:37:53 | INFO | Epoch 82 | train complete | mean_loss=-9.7938 | duration=102.3s
15:37:53 | INFO | Epoch 82 summary | train=-9.7938 (validation skipped)
15:37:53 | INFO | Epoch 83 started | validation=False
15:37:53 | INFO | Epoch 83 | train | batches=1500
15:38:11 | INFO | Epoch 83 | train batch 300/1500 | loss=-10.3442 | nll=-10.4962 | mse=0.0000
15:38:32 | INFO | Epoch 83 | train batch 600/1500 | loss=-9.1671 | nll=-9.3232 | mse=0.0000
15:38:50 | INFO | Epoch 83 | train batch 900/1500 | loss=-10.3618 | nll=-10.5159 | mse=0.0000
15:39:11 | INFO | Epoch 83 | train batch 1200/1500 | loss=-8.9966 | nll=-9.1326 | mse=0.0000
15:39:29 | INFO | Epoch 83 | train batch 1500/1500 | loss=-10.8190 | nll=-10.9702 | mse=0.0000
15:39:29 | INFO | Epoch 83 | train complete | mean_loss=-10.2793 | duration=95.6s
15:39:29 | INFO | Epoch 83 summary | train=-10.2793 (validation skipped)
15:39:29 | INFO | Epoch 84 started | validation=False
15:39:29 | INFO | Epoch 84 | train | batches=1500
15:39:50 | INFO | Epoch 84 | train batch 300/1500 | loss=-9.8890 | nll=-10.0367 | mse=0.0000
15:40:11 | INFO | Epoch 84 | train batch 600/1500 | loss=-11.1267 | nll=-11.2744 | mse=0.0000
15:40:28 | INFO | Epoch 84 | train batch 900/1500 | loss=-11.0582 | nll=-11.2097 | mse=0.0000
15:40:49 | INFO | Epoch 84 | train batch 1200/1500 | loss=-9.3107 | nll=-9.4527 | mse=0.0000
15:41:07 | INFO | Epoch 84 | train batch 1500/1500 | loss=-8.4365 | nll=-8.5971 | mse=0.0000
15:41:07 | INFO | Epoch 84 | train complete | mean_loss=-10.0865 | duration=98.3s
15:41:07 | INFO | Epoch 84 summary | train=-10.0865 (validation skipped)
15:41:07 | INFO | Epoch 85 started | validation=False
15:41:07 | INFO | Epoch 85 | train | batches=1500
15:41:28 | INFO | Epoch 85 | train batch 300/1500 | loss=-9.1515 | nll=-9.3097 | mse=0.0000
15:41:46 | INFO | Epoch 85 | train batch 600/1500 | loss=-9.7971 | nll=-9.9423 | mse=0.0000
15:42:07 | INFO | Epoch 85 | train batch 900/1500 | loss=-8.5993 | nll=-8.7479 | mse=0.0000
15:42:24 | INFO | Epoch 85 | train batch 1200/1500 | loss=-9.6357 | nll=-9.7944 | mse=0.0000
15:42:46 | INFO | Epoch 85 | train batch 1500/1500 | loss=-9.9123 | nll=-10.0635 | mse=0.0000
15:42:46 | INFO | Epoch 85 | train complete | mean_loss=-8.6208 | duration=99.0s
15:42:46 | INFO | Epoch 85 summary | train=-8.6208 (validation skipped)
15:42:46 | INFO | Epoch 86 started | validation=False
15:42:46 | INFO | Epoch 86 | train | batches=1500
15:43:04 | INFO | Epoch 86 | train batch 300/1500 | loss=-10.4481 | nll=-10.5949 | mse=0.0000
15:43:25 | INFO | Epoch 86 | train batch 600/1500 | loss=-8.6860 | nll=-8.8295 | mse=0.0000
15:43:47 | INFO | Epoch 86 | train batch 900/1500 | loss=-10.1376 | nll=-10.2796 | mse=0.0000
15:44:06 | INFO | Epoch 86 | train batch 1200/1500 | loss=-10.4487 | nll=-10.6008 | mse=0.0000
15:44:27 | INFO | Epoch 86 | train batch 1500/1500 | loss=-10.3346 | nll=-10.4693 | mse=0.0000
15:44:27 | INFO | Epoch 86 | train complete | mean_loss=-9.8090 | duration=101.3s
15:44:27 | INFO | Epoch 86 summary | train=-9.8090 (validation skipped)
15:44:27 | INFO | Epoch 87 started | validation=False
15:44:27 | INFO | Epoch 87 | train | batches=1500
15:44:45 | INFO | Epoch 87 | train batch 300/1500 | loss=-10.2463 | nll=-10.3910 | mse=0.0000
15:45:06 | INFO | Epoch 87 | train batch 600/1500 | loss=-8.4236 | nll=-8.5734 | mse=0.0000
15:45:24 | INFO | Epoch 87 | train batch 900/1500 | loss=-10.3672 | nll=-10.5366 | mse=0.0000
15:45:45 | INFO | Epoch 87 | train batch 1200/1500 | loss=-8.8658 | nll=-9.0152 | mse=0.0000
15:46:03 | INFO | Epoch 87 | train batch 1500/1500 | loss=-9.2626 | nll=-9.4265 | mse=0.0000
15:46:03 | INFO | Epoch 87 | train complete | mean_loss=-9.5237 | duration=95.4s
15:46:03 | INFO | Epoch 87 summary | train=-9.5237 (validation skipped)
15:46:03 | INFO | Epoch 88 started | validation=False
15:46:03 | INFO | Epoch 88 | train | batches=1500
15:46:24 | INFO | Epoch 88 | train batch 300/1500 | loss=-9.7058 | nll=-9.8461 | mse=0.0000
15:46:45 | INFO | Epoch 88 | train batch 600/1500 | loss=-9.1333 | nll=-9.2848 | mse=0.0000
15:47:03 | INFO | Epoch 88 | train batch 900/1500 | loss=-9.6991 | nll=-9.8395 | mse=0.0000
15:47:24 | INFO | Epoch 88 | train batch 1200/1500 | loss=-8.3617 | nll=-8.5074 | mse=0.0000
15:47:42 | INFO | Epoch 88 | train batch 1500/1500 | loss=-9.4664 | nll=-9.6189 | mse=0.0000
15:47:42 | INFO | Epoch 88 | train complete | mean_loss=-9.5718 | duration=98.9s
15:47:42 | INFO | Epoch 88 summary | train=-9.5718 (validation skipped)
15:47:42 | INFO | Epoch 89 started | validation=False
15:47:42 | INFO | Epoch 89 | train | batches=1500
15:48:03 | INFO | Epoch 89 | train batch 300/1500 | loss=-9.5375 | nll=-9.6758 | mse=0.0000
15:48:20 | INFO | Epoch 89 | train batch 600/1500 | loss=-10.8869 | nll=-11.0325 | mse=0.0000
15:48:42 | INFO | Epoch 89 | train batch 900/1500 | loss=-10.7706 | nll=-10.9231 | mse=0.0000
15:48:59 | INFO | Epoch 89 | train batch 1200/1500 | loss=-8.3843 | nll=-8.5384 | mse=0.0000
15:49:20 | INFO | Epoch 89 | train batch 1500/1500 | loss=-8.9092 | nll=-9.0665 | mse=0.0000
15:49:20 | INFO | Epoch 89 | train complete | mean_loss=-9.7296 | duration=98.7s
15:49:20 | INFO | Epoch 89 summary | train=-9.7296 (validation skipped)
15:49:20 | INFO | Epoch 90 started | validation=True
15:49:20 | INFO | Epoch 90 | train | batches=1500
15:49:38 | INFO | Epoch 90 | train batch 300/1500 | loss=-9.5269 | nll=-9.6680 | mse=0.0000
15:49:59 | INFO | Epoch 90 | train batch 600/1500 | loss=-9.1553 | nll=-9.3107 | mse=0.0000
15:50:20 | INFO | Epoch 90 | train batch 900/1500 | loss=-9.7818 | nll=-9.9233 | mse=0.0000
15:50:38 | INFO | Epoch 90 | train batch 1200/1500 | loss=-9.3594 | nll=-9.5100 | mse=0.0000
15:50:59 | INFO | Epoch 90 | train batch 1500/1500 | loss=-9.2891 | nll=-9.4301 | mse=0.0000
15:50:59 | INFO | Epoch 90 | train complete | mean_loss=-9.4881 | duration=98.7s
15:50:59 | INFO | Epoch 90 | val   | batches=500
15:51:02 | INFO | Epoch 90 | val batch 125/500 | loss=-6.9858 | nll=-7.1374 | mse=0.0000
15:51:05 | INFO | Epoch 90 | val batch 250/500 | loss=-7.0321 | nll=-7.1788 | mse=0.0000
15:51:08 | INFO | Epoch 90 | val batch 375/500 | loss=-7.0206 | nll=-7.1645 | mse=0.0000
15:51:10 | INFO | Epoch 90 | val batch 500/500 | loss=-6.9841 | nll=-7.1353 | mse=0.0000
15:51:10 | INFO | Epoch 90 | val complete   | mean_loss=-7.0041 | duration=11.4s
15:51:10 | INFO | Epoch 90 | test  | batches=500
15:51:13 | INFO | Epoch 90 | test batch 125/500 | nll=-7.1086 | mse=0.0000 | psnr=62.40
15:51:15 | INFO | Epoch 90 | test batch 250/500 | nll=-7.1949 | mse=0.0000 | psnr=62.55
15:51:17 | INFO | Epoch 90 | test batch 375/500 | nll=-7.1751 | mse=0.0000 | psnr=62.63
15:51:19 | INFO | Epoch 90 | test batch 500/500 | nll=-7.1959 | mse=0.0000 | psnr=62.43
15:51:19 | INFO | Epoch 90 | test complete  | mean_nll=-7.1731 | duration=8.7s
15:51:19 | INFO | Checkpoint saved to /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models/epoch_90_nf_model_net.pth (epoch 90)
15:51:19 | INFO | Epoch 90 summary | train=-9.4881 | val=-7.0041 | test=-7.1731 | smpl=0.0000 | best=False
15:51:19 | INFO | Epoch 91 started | validation=False
15:51:19 | INFO | Epoch 91 | train | batches=1500
15:51:41 | INFO | Epoch 91 | train batch 300/1500 | loss=-9.2817 | nll=-9.4266 | mse=0.0000
15:52:01 | INFO | Epoch 91 | train batch 600/1500 | loss=-10.8244 | nll=-10.9798 | mse=0.0000
15:52:24 | INFO | Epoch 91 | train batch 900/1500 | loss=-10.7362 | nll=-10.8827 | mse=0.0000
15:52:45 | INFO | Epoch 91 | train batch 1200/1500 | loss=-10.4516 | nll=-10.5975 | mse=0.0000
15:53:03 | INFO | Epoch 91 | train batch 1500/1500 | loss=-8.2601 | nll=-8.4109 | mse=0.0000
15:53:03 | INFO | Epoch 91 | train complete | mean_loss=-9.4356 | duration=104.0s
15:53:03 | INFO | Epoch 91 summary | train=-9.4356 (validation skipped)
15:53:03 | INFO | Epoch 92 started | validation=False
15:53:03 | INFO | Epoch 92 | train | batches=1500
15:53:24 | INFO | Epoch 92 | train batch 300/1500 | loss=-7.6990 | nll=-7.8469 | mse=0.0000
15:53:42 | INFO | Epoch 92 | train batch 600/1500 | loss=-8.1993 | nll=-8.3598 | mse=0.0000
15:54:03 | INFO | Epoch 92 | train batch 900/1500 | loss=-8.4630 | nll=-8.6179 | mse=0.0000
15:54:21 | INFO | Epoch 92 | train batch 1200/1500 | loss=-8.7305 | nll=-8.8788 | mse=0.0000
15:54:42 | INFO | Epoch 92 | train batch 1500/1500 | loss=-8.9384 | nll=-9.0855 | mse=0.0000
15:54:42 | INFO | Epoch 92 | train complete | mean_loss=-8.4321 | duration=99.3s
15:54:42 | INFO | Epoch 92 summary | train=-8.4321 (validation skipped)
15:54:42 | INFO | Epoch 93 started | validation=False
15:54:42 | INFO | Epoch 93 | train | batches=1500
15:55:00 | INFO | Epoch 93 | train batch 300/1500 | loss=-9.0319 | nll=-9.1879 | mse=0.0000
15:55:21 | INFO | Epoch 93 | train batch 600/1500 | loss=-9.3535 | nll=-9.5007 | mse=0.0000
15:55:43 | INFO | Epoch 93 | train batch 900/1500 | loss=-9.8075 | nll=-9.9645 | mse=0.0000
15:56:00 | INFO | Epoch 93 | train batch 1200/1500 | loss=-10.3599 | nll=-10.5087 | mse=0.0000
15:56:22 | INFO | Epoch 93 | train batch 1500/1500 | loss=-10.5198 | nll=-10.6717 | mse=0.0000
15:56:22 | INFO | Epoch 93 | train complete | mean_loss=-9.5288 | duration=99.1s
15:56:22 | INFO | Epoch 93 summary | train=-9.5288 (validation skipped)
15:56:22 | INFO | Epoch 94 started | validation=False
15:56:22 | INFO | Epoch 94 | train | batches=1500
15:56:39 | INFO | Epoch 94 | train batch 300/1500 | loss=-10.8527 | nll=-10.9963 | mse=0.0000
15:57:01 | INFO | Epoch 94 | train batch 600/1500 | loss=-8.5075 | nll=-8.6624 | mse=0.0000
15:57:18 | INFO | Epoch 94 | train batch 900/1500 | loss=-8.8623 | nll=-9.0042 | mse=0.0000
15:57:40 | INFO | Epoch 94 | train batch 1200/1500 | loss=-9.0189 | nll=-9.1643 | mse=0.0000
15:57:57 | INFO | Epoch 94 | train batch 1500/1500 | loss=-9.2136 | nll=-9.3595 | mse=0.0000
15:57:57 | INFO | Epoch 94 | train complete | mean_loss=-7.8865 | duration=95.8s
15:57:57 | INFO | Epoch 94 summary | train=-7.8865 (validation skipped)
15:57:57 | INFO | Epoch 95 started | validation=False
15:57:57 | INFO | Epoch 95 | train | batches=1500
15:58:19 | INFO | Epoch 95 | train batch 300/1500 | loss=-9.3708 | nll=-9.5240 | mse=0.0000
15:58:36 | INFO | Epoch 95 | train batch 600/1500 | loss=-9.5844 | nll=-9.7325 | mse=0.0000
15:58:58 | INFO | Epoch 95 | train batch 900/1500 | loss=-9.8473 | nll=-9.9954 | mse=0.0000
15:59:19 | INFO | Epoch 95 | train batch 1200/1500 | loss=-10.3302 | nll=-10.4732 | mse=0.0000
15:59:37 | INFO | Epoch 95 | train batch 1500/1500 | loss=-10.4860 | nll=-10.6426 | mse=0.0000
15:59:37 | INFO | Epoch 95 | train complete | mean_loss=-9.7813 | duration=99.4s
15:59:37 | INFO | Epoch 95 summary | train=-9.7813 (validation skipped)
15:59:37 | INFO | Epoch 96 started | validation=False
15:59:37 | INFO | Epoch 96 | train | batches=1500
15:59:58 | INFO | Epoch 96 | train batch 300/1500 | loss=-10.7182 | nll=-10.8693 | mse=0.0000
16:00:16 | INFO | Epoch 96 | train batch 600/1500 | loss=-11.1061 | nll=-11.2583 | mse=0.0000
16:00:39 | INFO | Epoch 96 | train batch 900/1500 | loss=-10.7659 | nll=-10.9179 | mse=0.0000
16:00:59 | INFO | Epoch 96 | train batch 1200/1500 | loss=-11.2860 | nll=-11.4381 | mse=0.0000
16:01:21 | INFO | Epoch 96 | train batch 1500/1500 | loss=-9.2002 | nll=-9.3506 | mse=0.0000
16:01:21 | INFO | Epoch 96 | train complete | mean_loss=-10.4501 | duration=104.2s
16:01:21 | INFO | Epoch 96 summary | train=-10.4501 (validation skipped)
16:01:21 | INFO | Epoch 97 started | validation=False
16:01:21 | INFO | Epoch 97 | train | batches=1500
16:01:42 | INFO | Epoch 97 | train batch 300/1500 | loss=-9.5101 | nll=-9.6661 | mse=0.0000
16:02:00 | INFO | Epoch 97 | train batch 600/1500 | loss=-9.9317 | nll=-10.0801 | mse=0.0000
16:02:22 | INFO | Epoch 97 | train batch 900/1500 | loss=-9.7059 | nll=-9.8508 | mse=0.0000
16:02:39 | INFO | Epoch 97 | train batch 1200/1500 | loss=-10.1514 | nll=-10.3041 | mse=0.0000
16:03:01 | INFO | Epoch 97 | train batch 1500/1500 | loss=-10.1515 | nll=-10.3045 | mse=0.0000
16:03:01 | INFO | Epoch 97 | train complete | mean_loss=-9.6493 | duration=99.8s
16:03:01 | INFO | Epoch 97 summary | train=-9.6493 (validation skipped)
16:03:01 | INFO | Epoch 98 started | validation=False
16:03:01 | INFO | Epoch 98 | train | batches=1500
16:03:19 | INFO | Epoch 98 | train batch 300/1500 | loss=-10.4960 | nll=-10.6455 | mse=0.0000
16:03:40 | INFO | Epoch 98 | train batch 600/1500 | loss=-10.4154 | nll=-10.5740 | mse=0.0000
16:03:58 | INFO | Epoch 98 | train batch 900/1500 | loss=-10.2528 | nll=-10.4091 | mse=0.0000
16:04:19 | INFO | Epoch 98 | train batch 1200/1500 | loss=-10.3825 | nll=-10.5344 | mse=0.0000
16:04:36 | INFO | Epoch 98 | train batch 1500/1500 | loss=-10.7022 | nll=-10.8468 | mse=0.0000
16:04:36 | INFO | Epoch 98 | train complete | mean_loss=-10.1879 | duration=95.5s
16:04:36 | INFO | Epoch 98 summary | train=-10.1879 (validation skipped)
16:04:36 | INFO | Epoch 99 started | validation=False
16:04:36 | INFO | Epoch 99 | train | batches=1500
16:04:57 | INFO | Epoch 99 | train batch 300/1500 | loss=-9.3498 | nll=-9.4956 | mse=0.0000
16:05:19 | INFO | Epoch 99 | train batch 600/1500 | loss=-10.4972 | nll=-10.6459 | mse=0.0000
16:05:36 | INFO | Epoch 99 | train batch 900/1500 | loss=-10.4992 | nll=-10.6443 | mse=0.0000
16:05:58 | INFO | Epoch 99 | train batch 1200/1500 | loss=-10.0793 | nll=-10.2278 | mse=0.0000
16:06:16 | INFO | Epoch 99 | train batch 1500/1500 | loss=-10.7110 | nll=-10.8738 | mse=0.0000
16:06:16 | INFO | Epoch 99 | train complete | mean_loss=-9.9621 | duration=99.4s
16:06:16 | INFO | Epoch 99 summary | train=-9.9621 (validation skipped)
16:06:16 | INFO | Epoch 100 started | validation=True
16:06:16 | INFO | Epoch 100 | train | batches=1500
16:06:37 | INFO | Epoch 100 | train batch 300/1500 | loss=-10.3337 | nll=-10.4622 | mse=0.0000
16:06:55 | INFO | Epoch 100 | train batch 600/1500 | loss=-10.1940 | nll=-10.3483 | mse=0.0000
16:07:16 | INFO | Epoch 100 | train batch 900/1500 | loss=-7.6633 | nll=-7.8086 | mse=0.0000
16:07:33 | INFO | Epoch 100 | train batch 1200/1500 | loss=-8.8086 | nll=-8.9585 | mse=0.0000
16:07:55 | INFO | Epoch 100 | train batch 1500/1500 | loss=-9.6402 | nll=-9.7844 | mse=0.0000
16:07:55 | INFO | Epoch 100 | train complete | mean_loss=-9.4624 | duration=99.1s
16:07:55 | INFO | Epoch 100 | val   | batches=500
16:07:57 | INFO | Epoch 100 | val batch 125/500 | loss=7.3208 | nll=7.1692 | mse=0.0000
16:08:00 | INFO | Epoch 100 | val batch 250/500 | loss=7.3457 | nll=7.1991 | mse=0.0000
16:08:03 | INFO | Epoch 100 | val batch 375/500 | loss=7.2998 | nll=7.1559 | mse=0.0000
16:08:06 | INFO | Epoch 100 | val batch 500/500 | loss=7.3581 | nll=7.2069 | mse=0.0000
16:08:06 | INFO | Epoch 100 | val complete   | mean_loss=7.3123 | duration=11.1s
16:08:06 | INFO | Epoch 100 | test  | batches=500
16:08:08 | INFO | Epoch 100 | test batch 125/500 | nll=7.2696 | mse=0.0000 | psnr=62.40
16:08:10 | INFO | Epoch 100 | test batch 250/500 | nll=7.5406 | mse=0.0000 | psnr=62.55
16:08:12 | INFO | Epoch 100 | test batch 375/500 | nll=7.4857 | mse=0.0000 | psnr=62.63
16:08:18 | INFO | Epoch 100 | test batch 500/500 | nll=7.7877 | mse=0.0000 | psnr=62.43
16:08:18 | INFO | Epoch 100 | test complete  | mean_nll=7.5820 | duration=12.2s
16:08:18 | INFO | Checkpoint saved to /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models/epoch_100_nf_model_net.pth (epoch 100)
16:08:18 | INFO | Epoch 100 summary | train=-9.4624 | val=7.3123 | test=7.5820 | smpl=0.0000 | best=False
16:08:18 | INFO | Epoch 101 started | validation=False
16:08:18 | INFO | Epoch 101 | train | batches=1500
16:08:36 | INFO | Epoch 101 | train batch 300/1500 | loss=-10.3997 | nll=-10.5427 | mse=0.0000
16:08:57 | INFO | Epoch 101 | train batch 600/1500 | loss=-10.9859 | nll=-11.1302 | mse=0.0000
16:09:15 | INFO | Epoch 101 | train batch 900/1500 | loss=-9.5767 | nll=-9.7313 | mse=0.0000
16:09:37 | INFO | Epoch 101 | train batch 1200/1500 | loss=-9.4554 | nll=-9.6145 | mse=0.0000
16:09:55 | INFO | Epoch 101 | train batch 1500/1500 | loss=-10.2375 | nll=-10.3864 | mse=0.0000
16:09:55 | INFO | Epoch 101 | train complete | mean_loss=-9.8338 | duration=96.8s
16:09:55 | INFO | Epoch 101 summary | train=-9.8338 (validation skipped)
16:09:55 | INFO | Epoch 102 started | validation=False
16:09:55 | INFO | Epoch 102 | train | batches=1500
16:10:16 | INFO | Epoch 102 | train batch 300/1500 | loss=-10.8288 | nll=-10.9767 | mse=0.0000
16:10:34 | INFO | Epoch 102 | train batch 600/1500 | loss=-8.0499 | nll=-8.1935 | mse=0.0000
16:10:55 | INFO | Epoch 102 | train batch 900/1500 | loss=-8.5427 | nll=-8.6919 | mse=0.0000
16:11:13 | INFO | Epoch 102 | train batch 1200/1500 | loss=-9.4143 | nll=-9.5798 | mse=0.0000
16:11:35 | INFO | Epoch 102 | train batch 1500/1500 | loss=-6.8028 | nll=-6.9496 | mse=0.0000
16:11:35 | INFO | Epoch 102 | train complete | mean_loss=-8.8973 | duration=100.4s
16:11:35 | INFO | Epoch 102 summary | train=-8.8973 (validation skipped)
16:11:35 | INFO | Epoch 103 started | validation=False
16:11:35 | INFO | Epoch 103 | train | batches=1500
16:11:57 | INFO | Epoch 103 | train batch 300/1500 | loss=-9.5193 | nll=-9.6696 | mse=0.0000
16:12:15 | INFO | Epoch 103 | train batch 600/1500 | loss=-9.9958 | nll=-10.1327 | mse=0.0000
16:12:38 | INFO | Epoch 103 | train batch 900/1500 | loss=-8.1561 | nll=-8.2983 | mse=0.0000
16:12:57 | INFO | Epoch 103 | train batch 1200/1500 | loss=-4.8390 | nll=-4.9927 | mse=0.0000
16:13:19 | INFO | Epoch 103 | train batch 1500/1500 | loss=-7.5062 | nll=-7.6660 | mse=0.0000
16:13:19 | INFO | Epoch 103 | train complete | mean_loss=-8.8257 | duration=104.1s
16:13:19 | INFO | Epoch 103 summary | train=-8.8257 (validation skipped)
16:13:19 | INFO | Epoch 104 started | validation=False
16:13:19 | INFO | Epoch 104 | train | batches=1500
16:13:42 | INFO | Epoch 104 | train batch 300/1500 | loss=-7.8658 | nll=-8.0093 | mse=0.0000
16:14:02 | INFO | Epoch 104 | train batch 600/1500 | loss=-8.1521 | nll=-8.2879 | mse=0.0000
16:14:24 | INFO | Epoch 104 | train batch 900/1500 | loss=-8.4354 | nll=-8.5833 | mse=0.0000
16:14:44 | INFO | Epoch 104 | train batch 1200/1500 | loss=-8.7348 | nll=-8.8939 | mse=0.0000
16:15:07 | INFO | Epoch 104 | train batch 1500/1500 | loss=-9.1508 | nll=-9.2874 | mse=0.0000
16:15:07 | INFO | Epoch 104 | train complete | mean_loss=-8.2785 | duration=107.2s
16:15:07 | INFO | Epoch 104 summary | train=-8.2785 (validation skipped)
16:15:07 | INFO | Epoch 105 started | validation=False
16:15:07 | INFO | Epoch 105 | train | batches=1500
16:15:28 | INFO | Epoch 105 | train batch 300/1500 | loss=-9.7884 | nll=-9.9373 | mse=0.0000
16:15:47 | INFO | Epoch 105 | train batch 600/1500 | loss=-10.5976 | nll=-10.7388 | mse=0.0000
16:16:09 | INFO | Epoch 105 | train batch 900/1500 | loss=-7.0404 | nll=-7.1859 | mse=0.0000
16:16:28 | INFO | Epoch 105 | train batch 1200/1500 | loss=-7.6121 | nll=-7.7683 | mse=0.0000
16:16:49 | INFO | Epoch 105 | train batch 1500/1500 | loss=-7.8675 | nll=-8.0110 | mse=0.0000
16:16:49 | INFO | Epoch 105 | train complete | mean_loss=-8.6102 | duration=102.9s
16:16:49 | INFO | Epoch 105 summary | train=-8.6102 (validation skipped)
16:16:49 | INFO | Epoch 106 started | validation=False
16:16:49 | INFO | Epoch 106 | train | batches=1500
16:17:09 | INFO | Epoch 106 | train batch 300/1500 | loss=-7.9639 | nll=-8.1239 | mse=0.0000
16:17:33 | INFO | Epoch 106 | train batch 600/1500 | loss=-8.1474 | nll=-8.3074 | mse=0.0000
16:17:55 | INFO | Epoch 106 | train batch 900/1500 | loss=-8.3978 | nll=-8.5394 | mse=0.0000
16:18:13 | INFO | Epoch 106 | train batch 1200/1500 | loss=-8.6619 | nll=-8.8124 | mse=0.0000
16:18:37 | INFO | Epoch 106 | train batch 1500/1500 | loss=-8.9592 | nll=-9.0995 | mse=0.0000
16:18:37 | INFO | Epoch 106 | train complete | mean_loss=-8.3101 | duration=107.6s
16:18:37 | INFO | Epoch 106 summary | train=-8.3101 (validation skipped)
16:18:37 | INFO | Epoch 107 started | validation=False
16:18:37 | INFO | Epoch 107 | train | batches=1500
16:18:57 | INFO | Epoch 107 | train batch 300/1500 | loss=-9.3091 | nll=-9.4623 | mse=0.0000
16:19:19 | INFO | Epoch 107 | train batch 600/1500 | loss=-9.9018 | nll=-10.0571 | mse=0.0000
16:19:40 | INFO | Epoch 107 | train batch 900/1500 | loss=-10.6114 | nll=-10.7527 | mse=0.0000
16:19:58 | INFO | Epoch 107 | train batch 1200/1500 | loss=-10.9838 | nll=-11.1361 | mse=0.0000
16:20:19 | INFO | Epoch 107 | train batch 1500/1500 | loss=-9.1938 | nll=-9.3387 | mse=0.0000
16:20:19 | INFO | Epoch 107 | train complete | mean_loss=-9.4084 | duration=101.7s
16:20:19 | INFO | Epoch 107 summary | train=-9.4084 (validation skipped)
16:20:19 | INFO | Epoch 108 started | validation=False
16:20:19 | INFO | Epoch 108 | train | batches=1500
16:20:36 | INFO | Epoch 108 | train batch 300/1500 | loss=-9.8977 | nll=-10.0369 | mse=0.0000
16:20:58 | INFO | Epoch 108 | train batch 600/1500 | loss=-10.0941 | nll=-10.2469 | mse=0.0000
16:21:15 | INFO | Epoch 108 | train batch 900/1500 | loss=-7.6198 | nll=-7.7703 | mse=0.0000
16:21:37 | INFO | Epoch 108 | train batch 1200/1500 | loss=-8.4953 | nll=-8.6366 | mse=0.0000
16:21:55 | INFO | Epoch 108 | train batch 1500/1500 | loss=-9.2285 | nll=-9.3627 | mse=0.0000
16:21:55 | INFO | Epoch 108 | train complete | mean_loss=-9.1461 | duration=96.5s
16:21:55 | INFO | Epoch 108 summary | train=-9.1461 (validation skipped)
16:21:55 | INFO | Epoch 109 started | validation=False
16:21:55 | INFO | Epoch 109 | train | batches=1500
16:22:19 | INFO | Epoch 109 | train batch 300/1500 | loss=-10.3020 | nll=-10.4558 | mse=0.0000
16:22:42 | INFO | Epoch 109 | train batch 600/1500 | loss=-7.5830 | nll=-7.7289 | mse=0.0000
16:23:02 | INFO | Epoch 109 | train batch 900/1500 | loss=-9.2363 | nll=-9.3838 | mse=0.0000
16:23:25 | INFO | Epoch 109 | train batch 1200/1500 | loss=-9.7252 | nll=-9.8668 | mse=0.0000
16:23:44 | INFO | Epoch 109 | train batch 1500/1500 | loss=-8.4453 | nll=-8.6135 | mse=0.0000
16:23:44 | INFO | Epoch 109 | train complete | mean_loss=-9.2368 | duration=108.4s
16:23:44 | INFO | Epoch 109 summary | train=-9.2368 (validation skipped)
16:23:44 | INFO | Epoch 110 started | validation=True
16:23:44 | INFO | Epoch 110 | train | batches=1500
16:24:07 | INFO | Epoch 110 | train batch 300/1500 | loss=-9.2219 | nll=-9.3769 | mse=0.0000
16:24:29 | INFO | Epoch 110 | train batch 600/1500 | loss=-9.8954 | nll=-10.0426 | mse=0.0000
16:24:48 | INFO | Epoch 110 | train batch 900/1500 | loss=-8.9109 | nll=-9.0575 | mse=0.0000
16:25:11 | INFO | Epoch 110 | train batch 1200/1500 | loss=-9.0720 | nll=-9.2188 | mse=0.0000
16:25:31 | INFO | Epoch 110 | train batch 1500/1500 | loss=-9.5646 | nll=-9.7070 | mse=0.0000
16:25:31 | INFO | Epoch 110 | train complete | mean_loss=-9.1784 | duration=106.9s
16:25:31 | INFO | Epoch 110 | val   | batches=500
16:25:34 | INFO | Epoch 110 | val batch 125/500 | loss=-3.5461 | nll=-3.6978 | mse=0.0000
16:25:40 | INFO | Epoch 110 | val batch 250/500 | loss=-3.5992 | nll=-3.7459 | mse=0.0000
16:25:44 | INFO | Epoch 110 | val batch 375/500 | loss=-3.5794 | nll=-3.7234 | mse=0.0000
16:25:47 | INFO | Epoch 110 | val batch 500/500 | loss=-3.5553 | nll=-3.7065 | mse=0.0000
16:25:47 | INFO | Epoch 110 | val complete   | mean_loss=-3.5641 | duration=16.5s
16:25:47 | INFO | Epoch 110 | test  | batches=500
16:25:49 | INFO | Epoch 110 | test batch 125/500 | nll=-3.6849 | mse=0.0000 | psnr=62.40
16:25:52 | INFO | Epoch 110 | test batch 250/500 | nll=-3.7704 | mse=0.0000 | psnr=62.55
16:25:55 | INFO | Epoch 110 | test batch 375/500 | nll=-3.7307 | mse=0.0000 | psnr=62.63
16:25:57 | INFO | Epoch 110 | test batch 500/500 | nll=-3.7278 | mse=0.0000 | psnr=62.43
16:25:57 | INFO | Epoch 110 | test complete  | mean_nll=-3.7291 | duration=9.6s
16:25:57 | INFO | Checkpoint saved to /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models/epoch_110_nf_model_net.pth (epoch 110)
16:25:57 | INFO | Epoch 110 summary | train=-9.1784 | val=-3.5641 | test=-3.7291 | smpl=0.0000 | best=False
16:25:57 | INFO | Epoch 111 started | validation=False
16:25:57 | INFO | Epoch 111 | train | batches=1500
16:26:19 | INFO | Epoch 111 | train batch 300/1500 | loss=-9.8860 | nll=-10.0366 | mse=0.0000
16:26:39 | INFO | Epoch 111 | train batch 600/1500 | loss=-7.6951 | nll=-7.8391 | mse=0.0000
16:27:03 | INFO | Epoch 111 | train batch 900/1500 | loss=-8.6568 | nll=-8.8000 | mse=0.0000
16:27:22 | INFO | Epoch 111 | train batch 1200/1500 | loss=-8.5753 | nll=-8.7151 | mse=0.0000
16:27:46 | INFO | Epoch 111 | train batch 1500/1500 | loss=-8.9516 | nll=-9.1076 | mse=0.0000
16:27:46 | INFO | Epoch 111 | train complete | mean_loss=-8.5654 | duration=109.3s
16:27:46 | INFO | Epoch 111 summary | train=-8.5654 (validation skipped)
16:27:46 | INFO | Epoch 112 started | validation=False
16:27:46 | INFO | Epoch 112 | train | batches=1500
16:28:10 | INFO | Epoch 112 | train batch 300/1500 | loss=-9.4396 | nll=-9.5928 | mse=0.0000
16:28:30 | INFO | Epoch 112 | train batch 600/1500 | loss=-9.3918 | nll=-9.5482 | mse=0.0000
16:28:53 | INFO | Epoch 112 | train batch 900/1500 | loss=-6.9316 | nll=-7.0850 | mse=0.0000
16:29:17 | INFO | Epoch 112 | train batch 1200/1500 | loss=-9.6657 | nll=-9.8110 | mse=0.0000
16:29:37 | INFO | Epoch 112 | train batch 1500/1500 | loss=-9.9177 | nll=-10.0579 | mse=0.0000
16:29:37 | INFO | Epoch 112 | train complete | mean_loss=-9.0350 | duration=111.1s
16:29:37 | INFO | Epoch 112 summary | train=-9.0350 (validation skipped)
16:29:37 | INFO | Epoch 113 started | validation=False
16:29:37 | INFO | Epoch 113 | train | batches=1500
16:29:59 | INFO | Epoch 113 | train batch 300/1500 | loss=-9.5572 | nll=-9.7139 | mse=0.0000
16:30:18 | INFO | Epoch 113 | train batch 600/1500 | loss=-10.0452 | nll=-10.1956 | mse=0.0000
16:30:38 | INFO | Epoch 113 | train batch 900/1500 | loss=-7.6146 | nll=-7.7607 | mse=0.0000
16:31:05 | INFO | Epoch 113 | train batch 1200/1500 | loss=-8.6098 | nll=-8.7573 | mse=0.0000
16:31:25 | INFO | Epoch 113 | train batch 1500/1500 | loss=-8.9883 | nll=-9.1339 | mse=0.0000
16:31:25 | INFO | Epoch 113 | train complete | mean_loss=-8.9290 | duration=108.4s
16:31:25 | INFO | Epoch 113 summary | train=-8.9290 (validation skipped)
16:31:25 | INFO | Epoch 114 started | validation=False
16:31:25 | INFO | Epoch 114 | train | batches=1500
16:31:45 | INFO | Epoch 114 | train batch 300/1500 | loss=-8.7169 | nll=-8.8582 | mse=0.0000
16:32:06 | INFO | Epoch 114 | train batch 600/1500 | loss=-8.8394 | nll=-8.9889 | mse=0.0000
16:32:28 | INFO | Epoch 114 | train batch 900/1500 | loss=-9.7800 | nll=-9.9355 | mse=0.0000
16:32:52 | INFO | Epoch 114 | train batch 1200/1500 | loss=-10.5371 | nll=-10.6876 | mse=0.0000
16:33:12 | INFO | Epoch 114 | train batch 1500/1500 | loss=-9.9473 | nll=-10.0949 | mse=0.0000
16:33:12 | INFO | Epoch 114 | train complete | mean_loss=-9.5882 | duration=106.3s
16:33:12 | INFO | Epoch 114 summary | train=-9.5882 (validation skipped)
16:33:12 | INFO | Epoch 115 started | validation=False
16:33:12 | INFO | Epoch 115 | train | batches=1500
16:33:34 | INFO | Epoch 115 | train batch 300/1500 | loss=-9.2211 | nll=-9.3502 | mse=0.0000
16:33:53 | INFO | Epoch 115 | train batch 600/1500 | loss=-10.7690 | nll=-10.9212 | mse=0.0000
16:34:17 | INFO | Epoch 115 | train batch 900/1500 | loss=-8.8076 | nll=-8.9506 | mse=0.0000
16:34:38 | INFO | Epoch 115 | train batch 1200/1500 | loss=-9.6716 | nll=-9.8282 | mse=0.0000
16:34:58 | INFO | Epoch 115 | train batch 1500/1500 | loss=-10.5985 | nll=-10.7391 | mse=0.0000
16:34:58 | INFO | Epoch 115 | train complete | mean_loss=-9.4211 | duration=106.1s
16:34:58 | INFO | Epoch 115 summary | train=-9.4211 (validation skipped)
16:34:58 | INFO | Epoch 116 started | validation=False
16:34:58 | INFO | Epoch 116 | train | batches=1500
16:35:21 | INFO | Epoch 116 | train batch 300/1500 | loss=-10.7510 | nll=-10.8876 | mse=0.0000
16:35:44 | INFO | Epoch 116 | train batch 600/1500 | loss=-8.6178 | nll=-8.7676 | mse=0.0000
16:36:04 | INFO | Epoch 116 | train batch 900/1500 | loss=-9.1995 | nll=-9.3551 | mse=0.0000
16:36:27 | INFO | Epoch 116 | train batch 1200/1500 | loss=-9.5443 | nll=-9.6949 | mse=0.0000
16:36:48 | INFO | Epoch 116 | train batch 1500/1500 | loss=-9.8682 | nll=-10.0145 | mse=0.0000
16:36:48 | INFO | Epoch 116 | train complete | mean_loss=-9.5484 | duration=110.2s
16:36:48 | INFO | Epoch 116 summary | train=-9.5484 (validation skipped)
16:36:48 | INFO | Epoch 117 started | validation=False
16:36:48 | INFO | Epoch 117 | train | batches=1500
16:37:11 | INFO | Epoch 117 | train batch 300/1500 | loss=-9.7628 | nll=-9.9309 | mse=0.0000
16:37:34 | INFO | Epoch 117 | train batch 600/1500 | loss=-9.5528 | nll=-9.6929 | mse=0.0000
16:37:52 | INFO | Epoch 117 | train batch 900/1500 | loss=-7.9270 | nll=-8.0695 | mse=0.0000
16:38:13 | INFO | Epoch 117 | train batch 1200/1500 | loss=-8.6293 | nll=-8.7775 | mse=0.0000
16:38:31 | INFO | Epoch 117 | train batch 1500/1500 | loss=-9.2553 | nll=-9.4088 | mse=0.0000
16:38:31 | INFO | Epoch 117 | train complete | mean_loss=-8.7567 | duration=103.1s
16:38:31 | INFO | Epoch 117 summary | train=-8.7567 (validation skipped)
16:38:31 | INFO | Epoch 118 started | validation=False
16:38:31 | INFO | Epoch 118 | train | batches=1500
16:38:55 | INFO | Epoch 118 | train batch 300/1500 | loss=-9.6911 | nll=-9.8500 | mse=0.0000
16:39:15 | INFO | Epoch 118 | train batch 600/1500 | loss=-10.2491 | nll=-10.3975 | mse=0.0000
16:39:33 | INFO | Epoch 118 | train batch 900/1500 | loss=-11.0376 | nll=-11.1863 | mse=0.0000
16:39:55 | INFO | Epoch 118 | train batch 1200/1500 | loss=-7.7499 | nll=-7.9020 | mse=0.0000
16:40:15 | INFO | Epoch 118 | train batch 1500/1500 | loss=-8.0633 | nll=-8.2173 | mse=0.0000
16:40:15 | INFO | Epoch 118 | train complete | mean_loss=-9.2136 | duration=104.0s
16:40:15 | INFO | Epoch 118 summary | train=-9.2136 (validation skipped)
16:40:15 | INFO | Epoch 119 started | validation=False
16:40:15 | INFO | Epoch 119 | train | batches=1500
16:40:36 | INFO | Epoch 119 | train batch 300/1500 | loss=-8.3085 | nll=-8.4529 | mse=0.0000
16:40:55 | INFO | Epoch 119 | train batch 600/1500 | loss=-8.5699 | nll=-8.7164 | mse=0.0000
16:41:17 | INFO | Epoch 119 | train batch 900/1500 | loss=-8.9729 | nll=-9.1073 | mse=0.0000
16:41:39 | INFO | Epoch 119 | train batch 1200/1500 | loss=-9.7439 | nll=-9.8911 | mse=0.0000
16:41:58 | INFO | Epoch 119 | train batch 1500/1500 | loss=-10.4468 | nll=-10.5920 | mse=0.0000
16:41:58 | INFO | Epoch 119 | train complete | mean_loss=-8.9490 | duration=102.8s
16:41:58 | INFO | Epoch 119 summary | train=-8.9490 (validation skipped)
16:41:58 | INFO | Epoch 120 started | validation=True
16:41:58 | INFO | Epoch 120 | train | batches=1500
16:42:19 | INFO | Epoch 120 | train batch 300/1500 | loss=-10.8398 | nll=-10.9911 | mse=0.0000
16:42:38 | INFO | Epoch 120 | train batch 600/1500 | loss=-11.2854 | nll=-11.4326 | mse=0.0000
16:43:02 | INFO | Epoch 120 | train batch 900/1500 | loss=1.1359 | nll=0.9898 | mse=0.0000
16:43:22 | INFO | Epoch 120 | train batch 1200/1500 | loss=-8.5268 | nll=-8.6729 | mse=0.0000
16:43:42 | INFO | Epoch 120 | train batch 1500/1500 | loss=-8.8389 | nll=-8.9903 | mse=0.0000
16:43:42 | INFO | Epoch 120 | train complete | mean_loss=-9.5899 | duration=104.0s
16:43:42 | INFO | Epoch 120 | val   | batches=500
16:43:46 | INFO | Epoch 120 | val batch 125/500 | loss=-8.7385 | nll=-8.8901 | mse=0.0000
16:43:49 | INFO | Epoch 120 | val batch 250/500 | loss=-8.7544 | nll=-8.9010 | mse=0.0000
16:43:56 | INFO | Epoch 120 | val batch 375/500 | loss=-8.7722 | nll=-8.9161 | mse=0.0000
16:43:59 | INFO | Epoch 120 | val batch 500/500 | loss=-8.7480 | nll=-8.8991 | mse=0.0000
16:43:59 | INFO | Epoch 120 | val complete   | mean_loss=-8.7532 | duration=16.8s
16:43:59 | INFO | Epoch 120 | test  | batches=500
16:44:01 | INFO | Epoch 120 | test batch 125/500 | nll=-8.8946 | mse=0.0000 | psnr=62.40
16:44:04 | INFO | Epoch 120 | test batch 250/500 | nll=-8.8972 | mse=0.0000 | psnr=62.55
16:44:06 | INFO | Epoch 120 | test batch 375/500 | nll=-8.9143 | mse=0.0000 | psnr=62.63
16:44:08 | INFO | Epoch 120 | test batch 500/500 | nll=-8.8967 | mse=0.0000 | psnr=62.43
16:44:08 | INFO | Epoch 120 | test complete  | mean_nll=-8.9009 | duration=9.5s
16:44:08 | INFO | Checkpoint saved to /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models/epoch_120_nf_model_net.pth (epoch 120)
16:44:08 | INFO | Checkpoint saved to /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models/best_model.pth (epoch 120)
16:44:08 | INFO | Epoch 120 summary | train=-9.5899 | val=-8.7532 | test=-8.9009 | smpl=0.0000 | best=True
16:44:08 | INFO | Epoch 121 started | validation=False
16:44:08 | INFO | Epoch 121 | train | batches=1500
16:44:29 | INFO | Epoch 121 | train batch 300/1500 | loss=-9.2006 | nll=-9.3531 | mse=0.0000
16:44:49 | INFO | Epoch 121 | train batch 600/1500 | loss=-9.4284 | nll=-9.5840 | mse=0.0000
16:45:12 | INFO | Epoch 121 | train batch 900/1500 | loss=-9.7719 | nll=-9.9228 | mse=0.0000
16:45:31 | INFO | Epoch 121 | train batch 1200/1500 | loss=-9.9521 | nll=-10.0988 | mse=0.0000
16:45:52 | INFO | Epoch 121 | train batch 1500/1500 | loss=-10.0914 | nll=-10.2495 | mse=0.0000
16:45:52 | INFO | Epoch 121 | train complete | mean_loss=-9.5114 | duration=103.6s
16:45:52 | INFO | Epoch 121 summary | train=-9.5114 (validation skipped)
16:45:52 | INFO | Epoch 122 started | validation=False
16:45:52 | INFO | Epoch 122 | train | batches=1500
16:46:14 | INFO | Epoch 122 | train batch 300/1500 | loss=-9.0935 | nll=-9.2357 | mse=0.0000
16:46:34 | INFO | Epoch 122 | train batch 600/1500 | loss=-9.5643 | nll=-9.7119 | mse=0.0000
16:46:56 | INFO | Epoch 122 | train batch 900/1500 | loss=-10.1706 | nll=-10.3253 | mse=0.0000
16:47:16 | INFO | Epoch 122 | train batch 1200/1500 | loss=-9.3014 | nll=-9.4613 | mse=0.0000
16:47:38 | INFO | Epoch 122 | train batch 1500/1500 | loss=-10.4826 | nll=-10.6377 | mse=0.0000
16:47:38 | INFO | Epoch 122 | train complete | mean_loss=-9.7482 | duration=106.2s
16:47:38 | INFO | Epoch 122 summary | train=-9.7482 (validation skipped)
16:47:38 | INFO | Epoch 123 started | validation=False
16:47:38 | INFO | Epoch 123 | train | batches=1500
16:47:59 | INFO | Epoch 123 | train batch 300/1500 | loss=-10.3046 | nll=-10.4498 | mse=0.0000
16:48:16 | INFO | Epoch 123 | train batch 600/1500 | loss=-10.8188 | nll=-10.9704 | mse=0.0000
16:48:39 | INFO | Epoch 123 | train batch 900/1500 | loss=-11.0397 | nll=-11.1865 | mse=0.0000
16:48:59 | INFO | Epoch 123 | train batch 1200/1500 | loss=-8.5205 | nll=-8.6693 | mse=0.0000
16:49:21 | INFO | Epoch 123 | train batch 1500/1500 | loss=-9.3865 | nll=-9.5267 | mse=0.0000
16:49:21 | INFO | Epoch 123 | train complete | mean_loss=-9.5420 | duration=102.5s
16:49:21 | INFO | Epoch 123 summary | train=-9.5420 (validation skipped)
16:49:21 | INFO | Epoch 124 started | validation=False
16:49:21 | INFO | Epoch 124 | train | batches=1500
16:49:39 | INFO | Epoch 124 | train batch 300/1500 | loss=-10.9711 | nll=-11.1313 | mse=0.0000
16:50:02 | INFO | Epoch 124 | train batch 600/1500 | loss=-7.3536 | nll=-7.5059 | mse=0.0000
16:50:22 | INFO | Epoch 124 | train batch 900/1500 | loss=-7.9005 | nll=-8.0565 | mse=0.0000
16:50:41 | INFO | Epoch 124 | train batch 1200/1500 | loss=-8.2769 | nll=-8.4123 | mse=0.0000
16:51:02 | INFO | Epoch 124 | train batch 1500/1500 | loss=-8.6773 | nll=-8.8232 | mse=0.0000
16:51:02 | INFO | Epoch 124 | train complete | mean_loss=-8.5292 | duration=100.7s
16:51:02 | INFO | Epoch 124 summary | train=-8.5292 (validation skipped)
16:51:02 | INFO | Epoch 125 started | validation=False
16:51:02 | INFO | Epoch 125 | train | batches=1500
16:51:20 | INFO | Epoch 125 | train batch 300/1500 | loss=-8.8379 | nll=-8.9955 | mse=0.0000
16:51:41 | INFO | Epoch 125 | train batch 600/1500 | loss=-8.9403 | nll=-9.0840 | mse=0.0000
16:51:59 | INFO | Epoch 125 | train batch 900/1500 | loss=-8.9187 | nll=-9.0773 | mse=0.0000
16:52:20 | INFO | Epoch 125 | train batch 1200/1500 | loss=-8.8010 | nll=-8.9438 | mse=0.0000
16:52:41 | INFO | Epoch 125 | train batch 1500/1500 | loss=-8.9676 | nll=-9.1188 | mse=0.0000
16:52:41 | INFO | Epoch 125 | train complete | mean_loss=-8.9058 | duration=100.0s
16:52:41 | INFO | Epoch 125 summary | train=-8.9058 (validation skipped)
16:52:41 | INFO | Epoch 126 started | validation=False
16:52:41 | INFO | Epoch 126 | train | batches=1500
16:53:00 | INFO | Epoch 126 | train batch 300/1500 | loss=-8.3882 | nll=-8.5466 | mse=0.0000
16:53:21 | INFO | Epoch 126 | train batch 600/1500 | loss=-9.5233 | nll=-9.6791 | mse=0.0000
16:53:39 | INFO | Epoch 126 | train batch 900/1500 | loss=-9.6728 | nll=-9.8180 | mse=0.0000
16:54:00 | INFO | Epoch 126 | train batch 1200/1500 | loss=-10.1122 | nll=-10.2619 | mse=0.0000
16:54:18 | INFO | Epoch 126 | train batch 1500/1500 | loss=-10.3860 | nll=-10.5353 | mse=0.0000
16:54:18 | INFO | Epoch 126 | train complete | mean_loss=-9.6155 | duration=96.7s
16:54:18 | INFO | Epoch 126 summary | train=-9.6155 (validation skipped)
16:54:18 | INFO | Epoch 127 started | validation=False
16:54:18 | INFO | Epoch 127 | train | batches=1500
16:54:39 | INFO | Epoch 127 | train batch 300/1500 | loss=-10.7093 | nll=-10.8632 | mse=0.0000
16:55:00 | INFO | Epoch 127 | train batch 600/1500 | loss=-11.0182 | nll=-11.1619 | mse=0.0000
16:55:19 | INFO | Epoch 127 | train batch 900/1500 | loss=-9.9738 | nll=-10.1254 | mse=0.0000
16:55:40 | INFO | Epoch 127 | train batch 1200/1500 | loss=-10.6154 | nll=-10.7714 | mse=0.0000
16:55:58 | INFO | Epoch 127 | train batch 1500/1500 | loss=-10.9773 | nll=-11.1294 | mse=0.0000
16:55:58 | INFO | Epoch 127 | train complete | mean_loss=-10.2825 | duration=99.8s
16:55:58 | INFO | Epoch 127 summary | train=-10.2825 (validation skipped)
16:55:58 | INFO | Epoch 128 started | validation=False
16:55:58 | INFO | Epoch 128 | train | batches=1500
16:56:19 | INFO | Epoch 128 | train batch 300/1500 | loss=-7.9669 | nll=-8.1125 | mse=0.0000
16:56:37 | INFO | Epoch 128 | train batch 600/1500 | loss=-8.2699 | nll=-8.4185 | mse=0.0000
16:56:58 | INFO | Epoch 128 | train batch 900/1500 | loss=-8.4289 | nll=-8.5794 | mse=0.0000
16:57:16 | INFO | Epoch 128 | train batch 1200/1500 | loss=-8.6927 | nll=-8.8440 | mse=0.0000
16:57:37 | INFO | Epoch 128 | train batch 1500/1500 | loss=-9.0376 | nll=-9.1820 | mse=0.0000
16:57:37 | INFO | Epoch 128 | train complete | mean_loss=-8.2317 | duration=99.4s
16:57:37 | INFO | Epoch 128 summary | train=-8.2317 (validation skipped)
16:57:37 | INFO | Epoch 129 started | validation=False
16:57:37 | INFO | Epoch 129 | train | batches=1500
16:57:59 | INFO | Epoch 129 | train batch 300/1500 | loss=-9.3762 | nll=-9.5187 | mse=0.0000
16:58:17 | INFO | Epoch 129 | train batch 600/1500 | loss=-9.6877 | nll=-9.8440 | mse=0.0000
16:58:37 | INFO | Epoch 129 | train batch 900/1500 | loss=-9.9460 | nll=-10.0926 | mse=0.0000
16:58:55 | INFO | Epoch 129 | train batch 1200/1500 | loss=-10.2817 | nll=-10.4284 | mse=0.0000
16:59:16 | INFO | Epoch 129 | train batch 1500/1500 | loss=-10.4061 | nll=-10.5727 | mse=0.0000
16:59:16 | INFO | Epoch 129 | train complete | mean_loss=-9.7670 | duration=98.3s
16:59:16 | INFO | Epoch 129 summary | train=-9.7670 (validation skipped)
16:59:16 | INFO | Epoch 130 started | validation=True
16:59:16 | INFO | Epoch 130 | train | batches=1500
16:59:34 | INFO | Epoch 130 | train batch 300/1500 | loss=-10.3335 | nll=-10.4858 | mse=0.0000
16:59:54 | INFO | Epoch 130 | train batch 600/1500 | loss=-9.6645 | nll=-9.8216 | mse=0.0000
17:00:13 | INFO | Epoch 130 | train batch 900/1500 | loss=-10.8728 | nll=-11.0227 | mse=0.0000
17:00:33 | INFO | Epoch 130 | train batch 1200/1500 | loss=-10.8423 | nll=-10.9981 | mse=0.0000
17:00:54 | INFO | Epoch 130 | train batch 1500/1500 | loss=-10.6677 | nll=-10.8190 | mse=0.0000
17:00:54 | INFO | Epoch 130 | train complete | mean_loss=-10.3359 | duration=98.4s
17:00:54 | INFO | Epoch 130 | val   | batches=500
17:00:57 | INFO | Epoch 130 | val batch 125/500 | loss=-1.9461 | nll=-2.0978 | mse=0.0000
17:01:00 | INFO | Epoch 130 | val batch 250/500 | loss=-1.9170 | nll=-2.0637 | mse=0.0000
17:01:03 | INFO | Epoch 130 | val batch 375/500 | loss=-1.9713 | nll=-2.1152 | mse=0.0000
17:01:06 | INFO | Epoch 130 | val batch 500/500 | loss=-1.9466 | nll=-2.0977 | mse=0.0000
17:01:06 | INFO | Epoch 130 | val complete   | mean_loss=-1.9500 | duration=11.5s
17:01:06 | INFO | Epoch 130 | test  | batches=500
17:01:08 | INFO | Epoch 130 | test batch 125/500 | nll=-2.2825 | mse=0.0000 | psnr=62.40
17:01:10 | INFO | Epoch 130 | test batch 250/500 | nll=-1.9840 | mse=0.0000 | psnr=62.55
17:01:12 | INFO | Epoch 130 | test batch 375/500 | nll=-2.0582 | mse=0.0000 | psnr=62.63
17:01:14 | INFO | Epoch 130 | test batch 500/500 | nll=-1.8718 | mse=0.0000 | psnr=62.43
17:01:14 | INFO | Epoch 130 | test complete  | mean_nll=-1.9577 | duration=8.6s
17:01:14 | INFO | Checkpoint saved to /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models/epoch_130_nf_model_net.pth (epoch 130)
17:01:14 | INFO | Epoch 130 summary | train=-10.3359 | val=-1.9500 | test=-1.9577 | smpl=0.0000 | best=False
17:01:14 | INFO | Epoch 131 started | validation=False
17:01:14 | INFO | Epoch 131 | train | batches=1500
17:01:35 | INFO | Epoch 131 | train batch 300/1500 | loss=-11.2587 | nll=-11.4015 | mse=0.0000
17:01:53 | INFO | Epoch 131 | train batch 600/1500 | loss=-11.1627 | nll=-11.3130 | mse=0.0000
17:02:14 | INFO | Epoch 131 | train batch 900/1500 | loss=-7.7219 | nll=-7.8730 | mse=0.0000
17:02:33 | INFO | Epoch 131 | train batch 1200/1500 | loss=-8.1378 | nll=-8.3022 | mse=0.0000
17:02:54 | INFO | Epoch 131 | train batch 1500/1500 | loss=-8.5421 | nll=-8.7000 | mse=0.0000
17:02:54 | INFO | Epoch 131 | train complete | mean_loss=-9.4223 | duration=99.6s
17:02:54 | INFO | Epoch 131 summary | train=-9.4223 (validation skipped)
17:02:54 | INFO | Epoch 132 started | validation=False
17:02:54 | INFO | Epoch 132 | train | batches=1500
17:03:15 | INFO | Epoch 132 | train batch 300/1500 | loss=-8.8030 | nll=-8.9522 | mse=0.0000
17:03:33 | INFO | Epoch 132 | train batch 600/1500 | loss=-8.6327 | nll=-8.7685 | mse=0.0000
17:03:54 | INFO | Epoch 132 | train batch 900/1500 | loss=-9.1774 | nll=-9.3347 | mse=0.0000
17:04:13 | INFO | Epoch 132 | train batch 1200/1500 | loss=-9.3941 | nll=-9.5479 | mse=0.0000
17:04:33 | INFO | Epoch 132 | train batch 1500/1500 | loss=-9.8985 | nll=-10.0382 | mse=0.0000
17:04:33 | INFO | Epoch 132 | train complete | mean_loss=-8.9216 | duration=99.5s
17:04:33 | INFO | Epoch 132 summary | train=-8.9216 (validation skipped)
17:04:33 | INFO | Epoch 133 started | validation=False
17:04:33 | INFO | Epoch 133 | train | batches=1500
17:04:51 | INFO | Epoch 133 | train batch 300/1500 | loss=-9.7078 | nll=-9.8511 | mse=0.0000
17:05:12 | INFO | Epoch 133 | train batch 600/1500 | loss=-10.9814 | nll=-11.1315 | mse=0.0000
17:05:33 | INFO | Epoch 133 | train batch 900/1500 | loss=-6.6290 | nll=-6.7881 | mse=0.0000
17:05:52 | INFO | Epoch 133 | train batch 1200/1500 | loss=-7.3138 | nll=-7.4745 | mse=0.0000
17:06:13 | INFO | Epoch 133 | train batch 1500/1500 | loss=-7.6987 | nll=-7.8429 | mse=0.0000
17:06:13 | INFO | Epoch 133 | train complete | mean_loss=-8.1288 | duration=99.3s
17:06:13 | INFO | Epoch 133 summary | train=-8.1288 (validation skipped)
17:06:13 | INFO | Epoch 134 started | validation=False
17:06:13 | INFO | Epoch 134 | train | batches=1500
17:06:31 | INFO | Epoch 134 | train batch 300/1500 | loss=-7.9340 | nll=-8.0798 | mse=0.0000
17:06:52 | INFO | Epoch 134 | train batch 600/1500 | loss=-8.0308 | nll=-8.1763 | mse=0.0000
17:07:10 | INFO | Epoch 134 | train batch 900/1500 | loss=-8.1734 | nll=-8.3284 | mse=0.0000
17:07:31 | INFO | Epoch 134 | train batch 1200/1500 | loss=-8.4115 | nll=-8.5574 | mse=0.0000
17:07:52 | INFO | Epoch 134 | train batch 1500/1500 | loss=-8.4948 | nll=-8.6360 | mse=0.0000
17:07:52 | INFO | Epoch 134 | train complete | mean_loss=-8.1327 | duration=99.4s
17:07:52 | INFO | Epoch 134 summary | train=-8.1327 (validation skipped)
17:07:52 | INFO | Epoch 135 started | validation=False
17:07:52 | INFO | Epoch 135 | train | batches=1500
17:08:11 | INFO | Epoch 135 | train batch 300/1500 | loss=-8.2652 | nll=-8.4020 | mse=0.0000
17:08:31 | INFO | Epoch 135 | train batch 600/1500 | loss=-8.9536 | nll=-9.0958 | mse=0.0000
17:08:49 | INFO | Epoch 135 | train batch 900/1500 | loss=-8.5865 | nll=-8.7523 | mse=0.0000
17:09:10 | INFO | Epoch 135 | train batch 1200/1500 | loss=-7.4959 | nll=-7.6353 | mse=0.0000
17:09:28 | INFO | Epoch 135 | train batch 1500/1500 | loss=-9.2739 | nll=-9.4179 | mse=0.0000
17:09:28 | INFO | Epoch 135 | train complete | mean_loss=-8.8934 | duration=96.0s
17:09:28 | INFO | Epoch 135 summary | train=-8.8934 (validation skipped)
17:09:28 | INFO | Epoch 136 started | validation=False
17:09:28 | INFO | Epoch 136 | train | batches=1500
17:09:50 | INFO | Epoch 136 | train batch 300/1500 | loss=-9.3286 | nll=-9.4710 | mse=0.0000
17:10:08 | INFO | Epoch 136 | train batch 600/1500 | loss=-9.3985 | nll=-9.5364 | mse=0.0000
17:10:29 | INFO | Epoch 136 | train batch 900/1500 | loss=-9.5636 | nll=-9.7207 | mse=0.0000
17:10:50 | INFO | Epoch 136 | train batch 1200/1500 | loss=-9.2879 | nll=-9.4340 | mse=0.0000
17:11:08 | INFO | Epoch 136 | train batch 1500/1500 | loss=-9.0744 | nll=-9.2281 | mse=0.0000
17:11:08 | INFO | Epoch 136 | train complete | mean_loss=-9.3159 | duration=100.2s
17:11:08 | INFO | Epoch 136 summary | train=-9.3159 (validation skipped)
17:11:08 | INFO | Epoch 137 started | validation=False
17:11:08 | INFO | Epoch 137 | train | batches=1500
17:11:29 | INFO | Epoch 137 | train batch 300/1500 | loss=-9.9865 | nll=-10.1303 | mse=0.0000
17:11:47 | INFO | Epoch 137 | train batch 600/1500 | loss=-9.7983 | nll=-9.9527 | mse=0.0000
17:12:08 | INFO | Epoch 137 | train batch 900/1500 | loss=-9.8288 | nll=-9.9820 | mse=0.0000
17:12:26 | INFO | Epoch 137 | train batch 1200/1500 | loss=-10.1471 | nll=-10.3052 | mse=0.0000
17:12:47 | INFO | Epoch 137 | train batch 1500/1500 | loss=-10.3022 | nll=-10.4475 | mse=0.0000
17:12:47 | INFO | Epoch 137 | train complete | mean_loss=-9.7645 | duration=99.0s
17:12:47 | INFO | Epoch 137 summary | train=-9.7645 (validation skipped)
17:12:47 | INFO | Epoch 138 started | validation=False
17:12:47 | INFO | Epoch 138 | train | batches=1500
17:13:06 | INFO | Epoch 138 | train batch 300/1500 | loss=-9.3643 | nll=-9.5222 | mse=0.0000
17:13:27 | INFO | Epoch 138 | train batch 600/1500 | loss=-10.5142 | nll=-10.6788 | mse=0.0000
17:13:48 | INFO | Epoch 138 | train batch 900/1500 | loss=-10.4105 | nll=-10.5542 | mse=0.0000
17:14:05 | INFO | Epoch 138 | train batch 1200/1500 | loss=-6.7392 | nll=-6.9001 | mse=0.0000
17:14:26 | INFO | Epoch 138 | train batch 1500/1500 | loss=-7.4833 | nll=-7.6262 | mse=0.0000
17:14:26 | INFO | Epoch 138 | train complete | mean_loss=-7.8602 | duration=98.8s
17:14:26 | INFO | Epoch 138 summary | train=-7.8602 (validation skipped)
17:14:26 | INFO | Epoch 139 started | validation=False
17:14:26 | INFO | Epoch 139 | train | batches=1500
17:14:44 | INFO | Epoch 139 | train batch 300/1500 | loss=-7.5206 | nll=-7.6797 | mse=0.0000
17:15:05 | INFO | Epoch 139 | train batch 600/1500 | loss=-7.6166 | nll=-7.7680 | mse=0.0000
17:15:23 | INFO | Epoch 139 | train batch 900/1500 | loss=-7.7296 | nll=-7.8714 | mse=0.0000
17:15:44 | INFO | Epoch 139 | train batch 1200/1500 | loss=-7.7860 | nll=-7.9380 | mse=0.0000
17:16:05 | INFO | Epoch 139 | train batch 1500/1500 | loss=-7.8600 | nll=-8.0207 | mse=0.0000
17:16:05 | INFO | Epoch 139 | train complete | mean_loss=-7.6657 | duration=99.3s
17:16:05 | INFO | Epoch 139 summary | train=-7.6657 (validation skipped)
17:16:05 | INFO | Epoch 140 started | validation=True
17:16:05 | INFO | Epoch 140 | train | batches=1500
17:16:23 | INFO | Epoch 140 | train batch 300/1500 | loss=-7.9885 | nll=-8.1344 | mse=0.0000
17:16:44 | INFO | Epoch 140 | train batch 600/1500 | loss=-8.0995 | nll=-8.2521 | mse=0.0000
17:17:02 | INFO | Epoch 140 | train batch 900/1500 | loss=-8.1755 | nll=-8.3353 | mse=0.0000
17:17:23 | INFO | Epoch 140 | train batch 1200/1500 | loss=-8.3419 | nll=-8.4842 | mse=0.0000
17:17:40 | INFO | Epoch 140 | train batch 1500/1500 | loss=-8.4581 | nll=-8.6065 | mse=0.0000
17:17:40 | INFO | Epoch 140 | train complete | mean_loss=-8.1581 | duration=94.8s
17:17:40 | INFO | Epoch 140 | val   | batches=500
17:17:43 | INFO | Epoch 140 | val batch 125/500 | loss=-8.4479 | nll=-8.5995 | mse=0.0000
17:17:46 | INFO | Epoch 140 | val batch 250/500 | loss=-8.4625 | nll=-8.6092 | mse=0.0000
17:17:52 | INFO | Epoch 140 | val batch 375/500 | loss=-8.4741 | nll=-8.6180 | mse=0.0000
17:17:54 | INFO | Epoch 140 | val batch 500/500 | loss=-8.4497 | nll=-8.6008 | mse=0.0000
17:17:54 | INFO | Epoch 140 | val complete   | mean_loss=-8.4556 | duration=14.2s
17:17:54 | INFO | Epoch 140 | test  | batches=500
17:17:56 | INFO | Epoch 140 | test batch 125/500 | nll=-8.5972 | mse=0.0000 | psnr=62.40
17:17:58 | INFO | Epoch 140 | test batch 250/500 | nll=-8.6118 | mse=0.0000 | psnr=62.55
17:18:00 | INFO | Epoch 140 | test batch 375/500 | nll=-8.6158 | mse=0.0000 | psnr=62.63
17:18:02 | INFO | Epoch 140 | test batch 500/500 | nll=-8.5982 | mse=0.0000 | psnr=62.43
17:18:02 | INFO | Epoch 140 | test complete  | mean_nll=-8.6047 | duration=8.1s
17:18:03 | INFO | Checkpoint saved to /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models/epoch_140_nf_model_net.pth (epoch 140)
17:18:03 | INFO | Epoch 140 summary | train=-8.1581 | val=-8.4556 | test=-8.6047 | smpl=0.0000 | best=False
17:18:03 | INFO | Epoch 141 started | validation=False
17:18:03 | INFO | Epoch 141 | train | batches=1500
17:18:20 | INFO | Epoch 141 | train batch 300/1500 | loss=-8.5625 | nll=-8.7145 | mse=0.0000
17:18:42 | INFO | Epoch 141 | train batch 600/1500 | loss=-8.6666 | nll=-8.8182 | mse=0.0000
17:19:03 | INFO | Epoch 141 | train batch 900/1500 | loss=-8.7657 | nll=-8.9161 | mse=0.0000
17:19:21 | INFO | Epoch 141 | train batch 1200/1500 | loss=-8.8812 | nll=-9.0362 | mse=0.0000
17:19:42 | INFO | Epoch 141 | train batch 1500/1500 | loss=-9.0209 | nll=-9.1683 | mse=0.0000
17:19:42 | INFO | Epoch 141 | train complete | mean_loss=-8.7243 | duration=99.4s
17:19:42 | INFO | Epoch 141 summary | train=-8.7243 (validation skipped)
17:19:42 | INFO | Epoch 142 started | validation=False
17:19:42 | INFO | Epoch 142 | train | batches=1500
17:20:00 | INFO | Epoch 142 | train batch 300/1500 | loss=-9.1199 | nll=-9.2700 | mse=0.0000
17:20:21 | INFO | Epoch 142 | train batch 600/1500 | loss=-9.1889 | nll=-9.3458 | mse=0.0000
17:20:38 | INFO | Epoch 142 | train batch 900/1500 | loss=-9.2793 | nll=-9.4176 | mse=0.0000
17:21:00 | INFO | Epoch 142 | train batch 1200/1500 | loss=-9.3236 | nll=-9.4892 | mse=0.0000
17:21:18 | INFO | Epoch 142 | train batch 1500/1500 | loss=-9.2926 | nll=-9.4407 | mse=0.0000
17:21:18 | INFO | Epoch 142 | train complete | mean_loss=-9.1925 | duration=96.2s
17:21:18 | INFO | Epoch 142 summary | train=-9.1925 (validation skipped)
17:21:18 | INFO | Epoch 143 started | validation=False
17:21:18 | INFO | Epoch 143 | train | batches=1500
17:21:39 | INFO | Epoch 143 | train batch 300/1500 | loss=-9.5417 | nll=-9.6828 | mse=0.0000
17:21:57 | INFO | Epoch 143 | train batch 600/1500 | loss=-9.4778 | nll=-9.6255 | mse=0.0000
17:22:18 | INFO | Epoch 143 | train batch 900/1500 | loss=-9.6020 | nll=-9.7471 | mse=0.0000
17:22:39 | INFO | Epoch 143 | train batch 1200/1500 | loss=-9.6303 | nll=-9.7758 | mse=0.0000
17:22:57 | INFO | Epoch 143 | train batch 1500/1500 | loss=-9.5547 | nll=-9.7054 | mse=0.0000
17:22:57 | INFO | Epoch 143 | train complete | mean_loss=-9.4915 | duration=98.9s
17:22:57 | INFO | Epoch 143 summary | train=-9.4915 (validation skipped)
17:22:57 | INFO | Epoch 144 started | validation=False
17:22:57 | INFO | Epoch 144 | train | batches=1500
17:23:18 | INFO | Epoch 144 | train batch 300/1500 | loss=-9.7154 | nll=-9.8627 | mse=0.0000
17:23:37 | INFO | Epoch 144 | train batch 600/1500 | loss=-9.8114 | nll=-9.9532 | mse=0.0000
17:23:58 | INFO | Epoch 144 | train batch 900/1500 | loss=-9.7538 | nll=-9.9094 | mse=0.0000
17:24:16 | INFO | Epoch 144 | train batch 1200/1500 | loss=-9.6450 | nll=-9.7891 | mse=0.0000
17:24:37 | INFO | Epoch 144 | train batch 1500/1500 | loss=-9.8358 | nll=-9.9819 | mse=0.0000
17:24:37 | INFO | Epoch 144 | train complete | mean_loss=-9.7438 | duration=100.0s
17:24:37 | INFO | Epoch 144 summary | train=-9.7438 (validation skipped)
17:24:37 | INFO | Epoch 145 started | validation=False
17:24:37 | INFO | Epoch 145 | train | batches=1500
17:24:58 | INFO | Epoch 145 | train batch 300/1500 | loss=-9.9464 | nll=-10.0899 | mse=0.0000
17:25:16 | INFO | Epoch 145 | train batch 600/1500 | loss=-9.9491 | nll=-10.0954 | mse=0.0000
17:25:37 | INFO | Epoch 145 | train batch 900/1500 | loss=-10.0413 | nll=-10.1909 | mse=0.0000
17:25:55 | INFO | Epoch 145 | train batch 1200/1500 | loss=-10.1526 | nll=-10.2930 | mse=0.0000
17:26:17 | INFO | Epoch 145 | train batch 1500/1500 | loss=-10.1344 | nll=-10.2830 | mse=0.0000
17:26:17 | INFO | Epoch 145 | train complete | mean_loss=-9.9383 | duration=99.8s
17:26:17 | INFO | Epoch 145 summary | train=-9.9383 (validation skipped)
17:26:17 | INFO | Epoch 146 started | validation=False
17:26:17 | INFO | Epoch 146 | train | batches=1500
17:26:35 | INFO | Epoch 146 | train batch 300/1500 | loss=-9.6946 | nll=-9.8621 | mse=0.0000
17:26:56 | INFO | Epoch 146 | train batch 600/1500 | loss=-10.2219 | nll=-10.3629 | mse=0.0000
17:27:14 | INFO | Epoch 146 | train batch 900/1500 | loss=-9.8383 | nll=-9.9885 | mse=0.0000
17:27:35 | INFO | Epoch 146 | train batch 1200/1500 | loss=-10.2659 | nll=-10.4104 | mse=0.0000
17:27:56 | INFO | Epoch 146 | train batch 1500/1500 | loss=-10.2162 | nll=-10.3487 | mse=0.0000
17:27:56 | INFO | Epoch 146 | train complete | mean_loss=-10.0940 | duration=99.5s
17:27:56 | INFO | Epoch 146 summary | train=-10.0940 (validation skipped)
17:27:56 | INFO | Epoch 147 started | validation=False
17:27:56 | INFO | Epoch 147 | train | batches=1500
17:28:14 | INFO | Epoch 147 | train batch 300/1500 | loss=-10.2215 | nll=-10.3889 | mse=0.0000
17:28:35 | INFO | Epoch 147 | train batch 600/1500 | loss=-10.3004 | nll=-10.4416 | mse=0.0000
17:28:53 | INFO | Epoch 147 | train batch 900/1500 | loss=-10.3775 | nll=-10.5247 | mse=0.0000
17:29:14 | INFO | Epoch 147 | train batch 1200/1500 | loss=-10.3080 | nll=-10.4562 | mse=0.0000
17:29:32 | INFO | Epoch 147 | train batch 1500/1500 | loss=-10.3417 | nll=-10.4960 | mse=0.0000
17:29:32 | INFO | Epoch 147 | train complete | mean_loss=-10.2104 | duration=96.0s
17:29:32 | INFO | Epoch 147 summary | train=-10.2104 (validation skipped)
17:29:32 | INFO | Epoch 148 started | validation=False
17:29:32 | INFO | Epoch 148 | train | batches=1500
17:29:53 | INFO | Epoch 148 | train batch 300/1500 | loss=-10.3828 | nll=-10.5383 | mse=0.0000
17:30:11 | INFO | Epoch 148 | train batch 600/1500 | loss=-10.4496 | nll=-10.5952 | mse=0.0000
17:30:32 | INFO | Epoch 148 | train batch 900/1500 | loss=-10.3361 | nll=-10.4836 | mse=0.0000
17:30:54 | INFO | Epoch 148 | train batch 1200/1500 | loss=-10.5228 | nll=-10.6668 | mse=0.0000
17:31:12 | INFO | Epoch 148 | train batch 1500/1500 | loss=-10.4354 | nll=-10.5840 | mse=0.0000
17:31:12 | INFO | Epoch 148 | train complete | mean_loss=-10.3102 | duration=99.3s
17:31:12 | INFO | Epoch 148 summary | train=-10.3102 (validation skipped)
17:31:12 | INFO | Epoch 149 started | validation=False
17:31:12 | INFO | Epoch 149 | train | batches=1500
17:31:33 | INFO | Epoch 149 | train batch 300/1500 | loss=-10.4514 | nll=-10.6024 | mse=0.0000
17:31:51 | INFO | Epoch 149 | train batch 600/1500 | loss=-10.1497 | nll=-10.2969 | mse=0.0000
17:32:12 | INFO | Epoch 149 | train batch 900/1500 | loss=-10.4768 | nll=-10.6381 | mse=0.0000
17:32:30 | INFO | Epoch 149 | train batch 1200/1500 | loss=-10.4961 | nll=-10.6506 | mse=0.0000
17:32:51 | INFO | Epoch 149 | train batch 1500/1500 | loss=-10.5370 | nll=-10.6732 | mse=0.0000
17:32:51 | INFO | Epoch 149 | train complete | mean_loss=-10.3723 | duration=99.8s
17:32:51 | INFO | Epoch 149 summary | train=-10.3723 (validation skipped)
17:32:51 | INFO | Epoch 150 started | validation=True
17:32:51 | INFO | Epoch 150 | train | batches=1500
17:33:09 | INFO | Epoch 150 | train batch 300/1500 | loss=-10.5272 | nll=-10.6757 | mse=0.0000
17:33:30 | INFO | Epoch 150 | train batch 600/1500 | loss=-10.4992 | nll=-10.6286 | mse=0.0000
17:33:51 | INFO | Epoch 150 | train batch 900/1500 | loss=-10.3976 | nll=-10.5449 | mse=0.0000
17:34:09 | INFO | Epoch 150 | train batch 1200/1500 | loss=-10.5266 | nll=-10.6861 | mse=0.0000
17:34:30 | INFO | Epoch 150 | train batch 1500/1500 | loss=-10.5244 | nll=-10.6736 | mse=0.0000
17:34:30 | INFO | Epoch 150 | train complete | mean_loss=-10.4215 | duration=98.7s
17:34:30 | INFO | Epoch 150 | val   | batches=500
17:34:33 | INFO | Epoch 150 | val batch 125/500 | loss=364.5059 | nll=364.3542 | mse=0.0000
17:34:36 | INFO | Epoch 150 | val batch 250/500 | loss=365.3087 | nll=365.1620 | mse=0.0000
17:34:39 | INFO | Epoch 150 | val batch 375/500 | loss=368.2803 | nll=368.1363 | mse=0.0000
17:34:41 | INFO | Epoch 150 | val batch 500/500 | loss=364.6151 | nll=364.4639 | mse=0.0000
17:34:41 | INFO | Epoch 150 | val complete   | mean_loss=365.7727 | duration=11.3s
17:34:41 | INFO | Epoch 150 | test  | batches=500
17:34:43 | INFO | Epoch 150 | test batch 125/500 | nll=362.7794 | mse=0.0000 | psnr=62.40
17:34:45 | INFO | Epoch 150 | test batch 250/500 | nll=365.5579 | mse=0.0000 | psnr=62.55
17:34:47 | INFO | Epoch 150 | test batch 375/500 | nll=368.1102 | mse=0.0000 | psnr=62.63
17:34:49 | INFO | Epoch 150 | test batch 500/500 | nll=365.0847 | mse=0.0000 | psnr=62.43
17:34:49 | INFO | Epoch 150 | test complete  | mean_nll=366.0290 | duration=8.1s
17:34:50 | INFO | Checkpoint saved to /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models/epoch_150_nf_model_net.pth (epoch 150)
17:34:50 | INFO | Epoch 150 summary | train=-10.4215 | val=365.7727 | test=366.0290 | smpl=0.0000 | best=False
17:34:50 | INFO | Epoch 151 started | validation=False
17:34:50 | INFO | Epoch 151 | train | batches=1500
17:35:10 | INFO | Epoch 151 | train batch 300/1500 | loss=-10.5042 | nll=-10.6562 | mse=0.0000
17:35:28 | INFO | Epoch 151 | train batch 600/1500 | loss=-10.1279 | nll=-10.2730 | mse=0.0000
17:35:49 | INFO | Epoch 151 | train batch 900/1500 | loss=-10.5347 | nll=-10.6794 | mse=0.0000
17:36:07 | INFO | Epoch 151 | train batch 1200/1500 | loss=-10.7020 | nll=-10.8474 | mse=0.0000
17:36:29 | INFO | Epoch 151 | train batch 1500/1500 | loss=-10.3809 | nll=-10.5283 | mse=0.0000
17:36:29 | INFO | Epoch 151 | train complete | mean_loss=-10.4653 | duration=99.1s
17:36:29 | INFO | Epoch 151 summary | train=-10.4653 (validation skipped)
17:36:29 | INFO | Epoch 152 started | validation=False
17:36:29 | INFO | Epoch 152 | train | batches=1500
17:36:49 | INFO | Epoch 152 | train batch 300/1500 | loss=-10.5585 | nll=-10.7103 | mse=0.0000
17:37:07 | INFO | Epoch 152 | train batch 600/1500 | loss=-10.6169 | nll=-10.7609 | mse=0.0000
17:37:28 | INFO | Epoch 152 | train batch 900/1500 | loss=-10.4356 | nll=-10.5762 | mse=0.0000
17:37:46 | INFO | Epoch 152 | train batch 1200/1500 | loss=-10.5212 | nll=-10.6738 | mse=0.0000
17:38:08 | INFO | Epoch 152 | train batch 1500/1500 | loss=-8.1938 | nll=-8.3341 | mse=0.0000
17:38:08 | INFO | Epoch 152 | train complete | mean_loss=-0.0131 | duration=99.0s
17:38:08 | INFO | Epoch 152 summary | train=-0.0131 (validation skipped)
17:38:08 | INFO | Epoch 153 started | validation=False
17:38:08 | INFO | Epoch 153 | train | batches=1500
17:38:26 | INFO | Epoch 153 | train batch 300/1500 | loss=-8.2714 | nll=-8.4263 | mse=0.0000
17:38:47 | INFO | Epoch 153 | train batch 600/1500 | loss=-8.3789 | nll=-8.5243 | mse=0.0000
17:39:05 | INFO | Epoch 153 | train batch 900/1500 | loss=-8.4654 | nll=-8.6084 | mse=0.0000
17:39:26 | INFO | Epoch 153 | train batch 1200/1500 | loss=-8.5134 | nll=-8.6515 | mse=0.0000
17:39:47 | INFO | Epoch 153 | train batch 1500/1500 | loss=-8.4989 | nll=-8.6464 | mse=0.0000
17:39:47 | INFO | Epoch 153 | train complete | mean_loss=-8.3634 | duration=99.0s
17:39:47 | INFO | Epoch 153 summary | train=-8.3634 (validation skipped)
17:39:47 | INFO | Epoch 154 started | validation=False
17:39:47 | INFO | Epoch 154 | train | batches=1500
17:40:05 | INFO | Epoch 154 | train batch 300/1500 | loss=-8.5391 | nll=-8.6878 | mse=0.0000
17:40:26 | INFO | Epoch 154 | train batch 600/1500 | loss=-8.6113 | nll=-8.7573 | mse=0.0000
17:40:44 | INFO | Epoch 154 | train batch 900/1500 | loss=-8.6723 | nll=-8.8031 | mse=0.0000
17:41:06 | INFO | Epoch 154 | train batch 1200/1500 | loss=-8.6272 | nll=-8.7761 | mse=0.0000
17:41:23 | INFO | Epoch 154 | train batch 1500/1500 | loss=-8.7459 | nll=-8.9015 | mse=0.0000
17:41:23 | INFO | Epoch 154 | train complete | mean_loss=-8.6044 | duration=96.9s
17:41:23 | INFO | Epoch 154 summary | train=-8.6044 (validation skipped)
17:41:23 | INFO | Epoch 155 started | validation=False
17:41:23 | INFO | Epoch 155 | train | batches=1500
17:41:45 | INFO | Epoch 155 | train batch 300/1500 | loss=-8.7630 | nll=-8.9163 | mse=0.0000
17:42:03 | INFO | Epoch 155 | train batch 600/1500 | loss=-8.8669 | nll=-9.0154 | mse=0.0000
17:42:24 | INFO | Epoch 155 | train batch 900/1500 | loss=-8.8851 | nll=-9.0465 | mse=0.0000
17:42:46 | INFO | Epoch 155 | train batch 1200/1500 | loss=-8.9403 | nll=-9.0951 | mse=0.0000
17:43:04 | INFO | Epoch 155 | train batch 1500/1500 | loss=-9.0125 | nll=-9.1595 | mse=0.0000
17:43:04 | INFO | Epoch 155 | train complete | mean_loss=-8.8676 | duration=100.2s
17:43:04 | INFO | Epoch 155 summary | train=-8.8676 (validation skipped)
17:43:04 | INFO | Epoch 156 started | validation=False
17:43:04 | INFO | Epoch 156 | train | batches=1500
17:43:25 | INFO | Epoch 156 | train batch 300/1500 | loss=-9.0973 | nll=-9.2504 | mse=0.0000
17:43:43 | INFO | Epoch 156 | train batch 600/1500 | loss=-9.0978 | nll=-9.2476 | mse=0.0000
17:44:04 | INFO | Epoch 156 | train batch 900/1500 | loss=-9.2724 | nll=-9.4224 | mse=0.0000
17:44:22 | INFO | Epoch 156 | train batch 1200/1500 | loss=-9.3912 | nll=-9.5441 | mse=0.0000
17:44:43 | INFO | Epoch 156 | train batch 1500/1500 | loss=-9.4662 | nll=-9.6261 | mse=0.0000
17:44:43 | INFO | Epoch 156 | train complete | mean_loss=-9.2375 | duration=99.6s
17:44:43 | INFO | Epoch 156 summary | train=-9.2375 (validation skipped)
17:44:43 | INFO | Epoch 157 started | validation=False
17:44:43 | INFO | Epoch 157 | train | batches=1500
17:45:01 | INFO | Epoch 157 | train batch 300/1500 | loss=-9.7537 | nll=-9.8985 | mse=0.0000
17:45:22 | INFO | Epoch 157 | train batch 600/1500 | loss=-9.7808 | nll=-9.9359 | mse=0.0000
17:45:40 | INFO | Epoch 157 | train batch 900/1500 | loss=-9.9647 | nll=-10.1168 | mse=0.0000
17:46:01 | INFO | Epoch 157 | train batch 1200/1500 | loss=-10.0834 | nll=-10.2283 | mse=0.0000
17:46:22 | INFO | Epoch 157 | train batch 1500/1500 | loss=-10.2180 | nll=-10.3688 | mse=0.0000
17:46:22 | INFO | Epoch 157 | train complete | mean_loss=-9.8737 | duration=99.1s
17:46:22 | INFO | Epoch 157 summary | train=-9.8737 (validation skipped)
17:46:22 | INFO | Epoch 158 started | validation=False
17:46:22 | INFO | Epoch 158 | train | batches=1500
17:46:40 | INFO | Epoch 158 | train batch 300/1500 | loss=-9.5943 | nll=-9.7485 | mse=0.0000
17:47:02 | INFO | Epoch 158 | train batch 600/1500 | loss=-10.2613 | nll=-10.4077 | mse=0.0000
17:47:20 | INFO | Epoch 158 | train batch 900/1500 | loss=-10.1516 | nll=-10.2982 | mse=0.0000
17:47:41 | INFO | Epoch 158 | train batch 1200/1500 | loss=-10.0157 | nll=-10.1615 | mse=0.0000
17:47:59 | INFO | Epoch 158 | train batch 1500/1500 | loss=-10.2060 | nll=-10.3471 | mse=0.0000
17:47:59 | INFO | Epoch 158 | train complete | mean_loss=-10.0429 | duration=96.5s
17:47:59 | INFO | Epoch 158 summary | train=-10.0429 (validation skipped)
17:47:59 | INFO | Epoch 159 started | validation=False
17:47:59 | INFO | Epoch 159 | train | batches=1500
17:48:20 | INFO | Epoch 159 | train batch 300/1500 | loss=-10.0583 | nll=-10.2079 | mse=0.0000
17:48:38 | INFO | Epoch 159 | train batch 600/1500 | loss=-10.2050 | nll=-10.3660 | mse=0.0000
17:48:58 | INFO | Epoch 159 | train batch 900/1500 | loss=-9.8152 | nll=-9.9647 | mse=0.0000
17:49:20 | INFO | Epoch 159 | train batch 1200/1500 | loss=-10.3754 | nll=-10.5175 | mse=0.0000
17:49:38 | INFO | Epoch 159 | train batch 1500/1500 | loss=-10.2988 | nll=-10.4516 | mse=0.0000
17:49:38 | INFO | Epoch 159 | train complete | mean_loss=-10.0325 | duration=98.9s
17:49:38 | INFO | Epoch 159 summary | train=-10.0325 (validation skipped)
17:49:38 | INFO | Epoch 160 started | validation=True
17:49:38 | INFO | Epoch 160 | train | batches=1500
17:49:59 | INFO | Epoch 160 | train batch 300/1500 | loss=-10.1416 | nll=-10.2925 | mse=0.0000
17:50:17 | INFO | Epoch 160 | train batch 600/1500 | loss=-9.8469 | nll=-9.9948 | mse=0.0000
17:50:38 | INFO | Epoch 160 | train batch 900/1500 | loss=-10.2889 | nll=-10.4405 | mse=0.0000
17:50:55 | INFO | Epoch 160 | train batch 1200/1500 | loss=-9.7620 | nll=-9.9162 | mse=0.0000
17:51:17 | INFO | Epoch 160 | train batch 1500/1500 | loss=-9.3614 | nll=-9.5052 | mse=0.0000
17:51:17 | INFO | Epoch 160 | train complete | mean_loss=-9.9391 | duration=99.1s
17:51:17 | INFO | Epoch 160 | val   | batches=500
17:51:20 | INFO | Epoch 160 | val batch 125/500 | loss=-1.4124 | nll=-1.5641 | mse=0.0000
17:51:23 | INFO | Epoch 160 | val batch 250/500 | loss=-1.4180 | nll=-1.5647 | mse=0.0000
17:51:25 | INFO | Epoch 160 | val batch 375/500 | loss=-1.4105 | nll=-1.5544 | mse=0.0000
17:51:28 | INFO | Epoch 160 | val batch 500/500 | loss=-1.3811 | nll=-1.5322 | mse=0.0000
17:51:28 | INFO | Epoch 160 | val complete   | mean_loss=-1.4214 | duration=11.4s
17:51:28 | INFO | Epoch 160 | test  | batches=500
17:51:30 | INFO | Epoch 160 | test batch 125/500 | nll=-1.7736 | mse=0.0000 | psnr=62.40
17:51:33 | INFO | Epoch 160 | test batch 250/500 | nll=-1.4718 | mse=0.0000 | psnr=62.55
17:51:35 | INFO | Epoch 160 | test batch 375/500 | nll=-1.5453 | mse=0.0000 | psnr=62.63
17:51:40 | INFO | Epoch 160 | test batch 500/500 | nll=-1.3750 | mse=0.0000 | psnr=62.43
17:51:40 | INFO | Epoch 160 | test complete  | mean_nll=-1.4560 | duration=11.9s
17:51:40 | INFO | Checkpoint saved to /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models/epoch_160_nf_model_net.pth (epoch 160)
17:51:40 | INFO | Epoch 160 summary | train=-9.9391 | val=-1.4214 | test=-1.4560 | smpl=0.0000 | best=False
17:51:40 | INFO | Epoch 161 started | validation=False
17:51:40 | INFO | Epoch 161 | train | batches=1500
17:51:58 | INFO | Epoch 161 | train batch 300/1500 | loss=-10.1634 | nll=-10.3140 | mse=0.0000
17:52:19 | INFO | Epoch 161 | train batch 600/1500 | loss=-9.4346 | nll=-9.5857 | mse=0.0000
17:52:37 | INFO | Epoch 161 | train batch 900/1500 | loss=-9.9117 | nll=-10.0597 | mse=0.0000
17:52:59 | INFO | Epoch 161 | train batch 1200/1500 | loss=-9.7287 | nll=-9.8805 | mse=0.0000
17:53:17 | INFO | Epoch 161 | train batch 1500/1500 | loss=-10.2667 | nll=-10.4091 | mse=0.0000
17:53:17 | INFO | Epoch 161 | train complete | mean_loss=-9.8350 | duration=96.6s
17:53:17 | INFO | Epoch 161 summary | train=-9.8350 (validation skipped)
17:53:17 | INFO | Epoch 162 started | validation=False
17:53:17 | INFO | Epoch 162 | train | batches=1500
17:53:38 | INFO | Epoch 162 | train batch 300/1500 | loss=-9.3894 | nll=-9.5496 | mse=0.0000
17:53:56 | INFO | Epoch 162 | train batch 600/1500 | loss=-10.0293 | nll=-10.1712 | mse=0.0000
17:54:18 | INFO | Epoch 162 | train batch 900/1500 | loss=-9.5301 | nll=-9.6872 | mse=0.0000
17:54:39 | INFO | Epoch 162 | train batch 1200/1500 | loss=-8.9269 | nll=-9.0869 | mse=0.0000
17:54:57 | INFO | Epoch 162 | train batch 1500/1500 | loss=-10.3401 | nll=-10.4839 | mse=0.0000
17:54:57 | INFO | Epoch 162 | train complete | mean_loss=-9.7417 | duration=100.3s
17:54:57 | INFO | Epoch 162 summary | train=-9.7417 (validation skipped)
17:54:57 | INFO | Epoch 163 started | validation=False
17:54:57 | INFO | Epoch 163 | train | batches=1500
17:55:18 | INFO | Epoch 163 | train batch 300/1500 | loss=-10.4323 | nll=-10.5873 | mse=0.0000
17:55:36 | INFO | Epoch 163 | train batch 600/1500 | loss=-9.6233 | nll=-9.7749 | mse=0.0000
17:55:57 | INFO | Epoch 163 | train batch 900/1500 | loss=-9.9557 | nll=-10.1098 | mse=0.0000
17:56:15 | INFO | Epoch 163 | train batch 1200/1500 | loss=-10.1030 | nll=-10.2552 | mse=0.0000
17:56:37 | INFO | Epoch 163 | train batch 1500/1500 | loss=-10.1570 | nll=-10.3145 | mse=0.0000
17:56:37 | INFO | Epoch 163 | train complete | mean_loss=-9.7553 | duration=100.2s
17:56:37 | INFO | Epoch 163 summary | train=-9.7553 (validation skipped)
17:56:37 | INFO | Epoch 164 started | validation=False
17:56:37 | INFO | Epoch 164 | train | batches=1500
17:56:55 | INFO | Epoch 164 | train batch 300/1500 | loss=-6.1440 | nll=-6.2977 | mse=0.0000
17:57:16 | INFO | Epoch 164 | train batch 600/1500 | loss=-10.3077 | nll=-10.4529 | mse=0.0000
17:57:38 | INFO | Epoch 164 | train batch 900/1500 | loss=-10.2117 | nll=-10.3631 | mse=0.0000
17:57:56 | INFO | Epoch 164 | train batch 1200/1500 | loss=-9.4497 | nll=-9.6067 | mse=0.0000
17:58:17 | INFO | Epoch 164 | train batch 1500/1500 | loss=-10.3899 | nll=-10.5346 | mse=0.0000
17:58:17 | INFO | Epoch 164 | train complete | mean_loss=-10.0119 | duration=99.5s
17:58:17 | INFO | Epoch 164 summary | train=-10.0119 (validation skipped)
17:58:17 | INFO | Epoch 165 started | validation=False
17:58:17 | INFO | Epoch 165 | train | batches=1500
17:58:35 | INFO | Epoch 165 | train batch 300/1500 | loss=-10.4972 | nll=-10.6539 | mse=0.0000
17:58:57 | INFO | Epoch 165 | train batch 600/1500 | loss=-4.7711 | nll=-4.9271 | mse=0.0000
17:59:15 | INFO | Epoch 165 | train batch 900/1500 | loss=-9.4725 | nll=-9.6091 | mse=0.0000
17:59:36 | INFO | Epoch 165 | train batch 1200/1500 | loss=-9.5863 | nll=-9.7442 | mse=0.0000
17:59:54 | INFO | Epoch 165 | train batch 1500/1500 | loss=-9.9015 | nll=-10.0543 | mse=0.0000
17:59:54 | INFO | Epoch 165 | train complete | mean_loss=-9.2511 | duration=96.8s
17:59:54 | INFO | Epoch 165 summary | train=-9.2511 (validation skipped)
17:59:54 | INFO | Epoch 166 started | validation=False
17:59:54 | INFO | Epoch 166 | train | batches=1500
18:00:15 | INFO | Epoch 166 | train batch 300/1500 | loss=-10.0117 | nll=-10.1674 | mse=0.0000
18:00:36 | INFO | Epoch 166 | train batch 600/1500 | loss=-10.1990 | nll=-10.3456 | mse=0.0000
18:00:54 | INFO | Epoch 166 | train batch 900/1500 | loss=-9.2902 | nll=-9.4492 | mse=0.0000
18:01:15 | INFO | Epoch 166 | train batch 1200/1500 | loss=-9.9631 | nll=-10.1236 | mse=0.0000
18:01:33 | INFO | Epoch 166 | train batch 1500/1500 | loss=-10.1046 | nll=-10.2491 | mse=0.0000
18:01:33 | INFO | Epoch 166 | train complete | mean_loss=-9.5366 | duration=99.4s
18:01:33 | INFO | Epoch 166 summary | train=-9.5366 (validation skipped)
18:01:33 | INFO | Epoch 167 started | validation=False
18:01:33 | INFO | Epoch 167 | train | batches=1500
18:01:55 | INFO | Epoch 167 | train batch 300/1500 | loss=-10.1338 | nll=-10.2603 | mse=0.0000
18:02:13 | INFO | Epoch 167 | train batch 600/1500 | loss=-9.7612 | nll=-9.9176 | mse=0.0000
18:02:34 | INFO | Epoch 167 | train batch 900/1500 | loss=-9.2835 | nll=-9.4441 | mse=0.0000
18:02:52 | INFO | Epoch 167 | train batch 1200/1500 | loss=-10.3826 | nll=-10.5339 | mse=0.0000
18:03:13 | INFO | Epoch 167 | train batch 1500/1500 | loss=-9.8211 | nll=-9.9770 | mse=0.0000
18:03:13 | INFO | Epoch 167 | train complete | mean_loss=-9.9053 | duration=100.0s
18:03:13 | INFO | Epoch 167 summary | train=-9.9053 (validation skipped)
18:03:13 | INFO | Epoch 168 started | validation=False
18:03:13 | INFO | Epoch 168 | train | batches=1500
18:03:34 | INFO | Epoch 168 | train batch 300/1500 | loss=-9.0903 | nll=-9.2394 | mse=0.0000
18:03:52 | INFO | Epoch 168 | train batch 600/1500 | loss=-10.3457 | nll=-10.4834 | mse=0.0000
18:04:14 | INFO | Epoch 168 | train batch 900/1500 | loss=-9.5978 | nll=-9.7382 | mse=0.0000
18:04:32 | INFO | Epoch 168 | train batch 1200/1500 | loss=-10.2745 | nll=-10.4184 | mse=0.0000
18:04:53 | INFO | Epoch 168 | train batch 1500/1500 | loss=-10.1176 | nll=-10.2645 | mse=0.0000
18:04:53 | INFO | Epoch 168 | train complete | mean_loss=-9.8775 | duration=99.7s
18:04:53 | INFO | Epoch 168 summary | train=-9.8775 (validation skipped)
18:04:53 | INFO | Epoch 169 started | validation=False
18:04:53 | INFO | Epoch 169 | train | batches=1500
18:05:11 | INFO | Epoch 169 | train batch 300/1500 | loss=-10.3672 | nll=-10.5123 | mse=0.0000
18:05:32 | INFO | Epoch 169 | train batch 600/1500 | loss=-9.7194 | nll=-9.8617 | mse=0.0000
18:05:50 | INFO | Epoch 169 | train batch 900/1500 | loss=-10.1942 | nll=-10.3472 | mse=0.0000
18:06:12 | INFO | Epoch 169 | train batch 1200/1500 | loss=-10.4629 | nll=-10.6086 | mse=0.0000
18:06:33 | INFO | Epoch 169 | train batch 1500/1500 | loss=-9.2652 | nll=-9.4310 | mse=0.0000
18:06:33 | INFO | Epoch 169 | train complete | mean_loss=-10.0535 | duration=100.5s
18:06:33 | INFO | Epoch 169 summary | train=-10.0535 (validation skipped)
18:06:33 | INFO | Epoch 170 started | validation=True
18:06:33 | INFO | Epoch 170 | train | batches=1500
18:06:51 | INFO | Epoch 170 | train batch 300/1500 | loss=-10.1151 | nll=-10.2673 | mse=0.0000
18:07:12 | INFO | Epoch 170 | train batch 600/1500 | loss=-10.1600 | nll=-10.3051 | mse=0.0000
18:07:30 | INFO | Epoch 170 | train batch 900/1500 | loss=-10.3685 | nll=-10.5156 | mse=0.0000
18:07:52 | INFO | Epoch 170 | train batch 1200/1500 | loss=-10.3543 | nll=-10.4995 | mse=0.0000
18:08:09 | INFO | Epoch 170 | train batch 1500/1500 | loss=-9.0370 | nll=-9.1822 | mse=0.0000
18:08:09 | INFO | Epoch 170 | train complete | mean_loss=-9.9957 | duration=95.9s
18:08:09 | INFO | Epoch 170 | val   | batches=500
18:08:12 | INFO | Epoch 170 | val batch 125/500 | loss=-5.0825 | nll=-5.2342 | mse=0.0000
18:08:15 | INFO | Epoch 170 | val batch 250/500 | loss=-5.0915 | nll=-5.2382 | mse=0.0000
18:08:21 | INFO | Epoch 170 | val batch 375/500 | loss=-5.0930 | nll=-5.2369 | mse=0.0000
18:08:24 | INFO | Epoch 170 | val batch 500/500 | loss=-5.0824 | nll=-5.2336 | mse=0.0000
18:08:24 | INFO | Epoch 170 | val complete   | mean_loss=-5.0861 | duration=14.4s
18:08:24 | INFO | Epoch 170 | test  | batches=500
18:08:26 | INFO | Epoch 170 | test batch 125/500 | nll=-5.2550 | mse=0.0000 | psnr=62.40
18:08:28 | INFO | Epoch 170 | test batch 250/500 | nll=-5.2479 | mse=0.0000 | psnr=62.55
18:08:30 | INFO | Epoch 170 | test batch 375/500 | nll=-5.2537 | mse=0.0000 | psnr=62.63
18:08:32 | INFO | Epoch 170 | test batch 500/500 | nll=-5.2388 | mse=0.0000 | psnr=62.43
18:08:32 | INFO | Epoch 170 | test complete  | mean_nll=-5.2474 | duration=8.3s
18:08:32 | INFO | Checkpoint saved to /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models/epoch_170_nf_model_net.pth (epoch 170)
18:08:32 | INFO | Epoch 170 summary | train=-9.9957 | val=-5.0861 | test=-5.2474 | smpl=0.0000 | best=False
18:08:32 | INFO | Epoch 171 started | validation=False
18:08:32 | INFO | Epoch 171 | train | batches=1500
18:08:49 | INFO | Epoch 171 | train batch 300/1500 | loss=-9.7849 | nll=-9.9316 | mse=0.0000
18:09:11 | INFO | Epoch 171 | train batch 600/1500 | loss=-9.4445 | nll=-9.5966 | mse=0.0000
18:09:31 | INFO | Epoch 171 | train batch 900/1500 | loss=-9.9708 | nll=-10.1199 | mse=0.0000
18:09:49 | INFO | Epoch 171 | train batch 1200/1500 | loss=-10.0984 | nll=-10.2488 | mse=0.0000
18:10:11 | INFO | Epoch 171 | train batch 1500/1500 | loss=-9.5342 | nll=-9.6917 | mse=0.0000
18:10:11 | INFO | Epoch 171 | train complete | mean_loss=-9.7617 | duration=99.2s
18:10:11 | INFO | Epoch 171 summary | train=-9.7617 (validation skipped)
18:10:11 | INFO | Epoch 172 started | validation=False
18:10:11 | INFO | Epoch 172 | train | batches=1500
18:10:29 | INFO | Epoch 172 | train batch 300/1500 | loss=-10.2981 | nll=-10.4552 | mse=0.0000
18:10:50 | INFO | Epoch 172 | train batch 600/1500 | loss=-8.6854 | nll=-8.8320 | mse=0.0000
18:11:07 | INFO | Epoch 172 | train batch 900/1500 | loss=-9.7664 | nll=-9.9110 | mse=0.0000
18:11:28 | INFO | Epoch 172 | train batch 1200/1500 | loss=-8.5524 | nll=-8.6973 | mse=0.0000
18:11:47 | INFO | Epoch 172 | train batch 1500/1500 | loss=-9.3270 | nll=-9.4778 | mse=0.0000
18:11:47 | INFO | Epoch 172 | train complete | mean_loss=-9.4411 | duration=95.3s
18:11:47 | INFO | Epoch 172 summary | train=-9.4411 (validation skipped)
18:11:47 | INFO | Epoch 173 started | validation=False
18:11:47 | INFO | Epoch 173 | train | batches=1500
18:12:08 | INFO | Epoch 173 | train batch 300/1500 | loss=-10.3700 | nll=-10.5182 | mse=0.0000
18:12:29 | INFO | Epoch 173 | train batch 600/1500 | loss=-10.5851 | nll=-10.7402 | mse=0.0000
18:12:47 | INFO | Epoch 173 | train batch 900/1500 | loss=-9.0638 | nll=-9.2137 | mse=0.0000
18:13:08 | INFO | Epoch 173 | train batch 1200/1500 | loss=-10.2004 | nll=-10.3426 | mse=0.0000
18:13:25 | INFO | Epoch 173 | train batch 1500/1500 | loss=-10.2298 | nll=-10.3901 | mse=0.0000
18:13:25 | INFO | Epoch 173 | train complete | mean_loss=-10.0191 | duration=98.8s
18:13:25 | INFO | Epoch 173 summary | train=-10.0191 (validation skipped)
18:13:25 | INFO | Epoch 174 started | validation=False
18:13:25 | INFO | Epoch 174 | train | batches=1500
18:13:46 | INFO | Epoch 174 | train batch 300/1500 | loss=-9.3828 | nll=-9.5252 | mse=0.0000
18:14:04 | INFO | Epoch 174 | train batch 600/1500 | loss=-9.7463 | nll=-9.8892 | mse=0.0000
18:14:25 | INFO | Epoch 174 | train batch 900/1500 | loss=-9.9423 | nll=-10.0856 | mse=0.0000
18:14:43 | INFO | Epoch 174 | train batch 1200/1500 | loss=-9.8005 | nll=-9.9575 | mse=0.0000
18:15:04 | INFO | Epoch 174 | train batch 1500/1500 | loss=-10.2381 | nll=-10.3807 | mse=0.0000
18:15:04 | INFO | Epoch 174 | train complete | mean_loss=-9.7997 | duration=98.8s
18:15:04 | INFO | Epoch 174 summary | train=-9.7997 (validation skipped)
18:15:04 | INFO | Epoch 175 started | validation=False
18:15:04 | INFO | Epoch 175 | train | batches=1500
18:15:22 | INFO | Epoch 175 | train batch 300/1500 | loss=-10.5460 | nll=-10.6954 | mse=0.0000
18:15:43 | INFO | Epoch 175 | train batch 600/1500 | loss=-10.6521 | nll=-10.8082 | mse=0.0000
18:16:04 | INFO | Epoch 175 | train batch 900/1500 | loss=-8.6780 | nll=-8.8490 | mse=0.0000
18:16:22 | INFO | Epoch 175 | train batch 1200/1500 | loss=-9.1940 | nll=-9.3359 | mse=0.0000
18:16:43 | INFO | Epoch 175 | train batch 1500/1500 | loss=-9.9021 | nll=-10.0412 | mse=0.0000
18:16:43 | INFO | Epoch 175 | train complete | mean_loss=-9.8337 | duration=99.4s
18:16:43 | INFO | Epoch 175 summary | train=-9.8337 (validation skipped)
18:16:43 | INFO | Epoch 176 started | validation=False
18:16:43 | INFO | Epoch 176 | train | batches=1500
18:17:02 | INFO | Epoch 176 | train batch 300/1500 | loss=-9.5342 | nll=-9.6820 | mse=0.0000
18:17:23 | INFO | Epoch 176 | train batch 600/1500 | loss=-9.0907 | nll=-9.2355 | mse=0.0000
18:17:41 | INFO | Epoch 176 | train batch 900/1500 | loss=-10.3627 | nll=-10.5105 | mse=0.0000
18:18:02 | INFO | Epoch 176 | train batch 1200/1500 | loss=-10.6433 | nll=-10.7966 | mse=0.0000
18:18:20 | INFO | Epoch 176 | train batch 1500/1500 | loss=-9.0454 | nll=-9.2132 | mse=0.0000
18:18:20 | INFO | Epoch 176 | train complete | mean_loss=-9.8373 | duration=96.2s
18:18:20 | INFO | Epoch 176 summary | train=-9.8373 (validation skipped)
18:18:20 | INFO | Epoch 177 started | validation=False
18:18:20 | INFO | Epoch 177 | train | batches=1500
18:18:41 | INFO | Epoch 177 | train batch 300/1500 | loss=-10.1402 | nll=-10.2836 | mse=0.0000
18:19:02 | INFO | Epoch 177 | train batch 600/1500 | loss=-10.2898 | nll=-10.4355 | mse=0.0000
18:19:20 | INFO | Epoch 177 | train batch 900/1500 | loss=-10.5130 | nll=-10.6601 | mse=0.0000
18:19:41 | INFO | Epoch 177 | train batch 1200/1500 | loss=-9.5482 | nll=-9.7146 | mse=0.0000
18:20:00 | INFO | Epoch 177 | train batch 1500/1500 | loss=-8.3261 | nll=-8.4803 | mse=0.0000
18:20:00 | INFO | Epoch 177 | train complete | mean_loss=-9.8046 | duration=100.0s
18:20:00 | INFO | Epoch 177 summary | train=-9.8046 (validation skipped)
18:20:00 | INFO | Epoch 178 started | validation=False
18:20:00 | INFO | Epoch 178 | train | batches=1500
18:20:21 | INFO | Epoch 178 | train batch 300/1500 | loss=-8.5543 | nll=-8.7087 | mse=0.0000
18:20:39 | INFO | Epoch 178 | train batch 600/1500 | loss=-8.7997 | nll=-8.9424 | mse=0.0000
18:21:00 | INFO | Epoch 178 | train batch 900/1500 | loss=-8.9745 | nll=-9.1320 | mse=0.0000
18:21:18 | INFO | Epoch 178 | train batch 1200/1500 | loss=-9.1840 | nll=-9.3324 | mse=0.0000
18:21:39 | INFO | Epoch 178 | train batch 1500/1500 | loss=-9.3670 | nll=-9.5093 | mse=0.0000
18:21:39 | INFO | Epoch 178 | train complete | mean_loss=-8.8845 | duration=99.6s
18:21:39 | INFO | Epoch 178 summary | train=-8.8845 (validation skipped)
18:21:39 | INFO | Epoch 179 started | validation=False
18:21:39 | INFO | Epoch 179 | train | batches=1500
18:21:57 | INFO | Epoch 179 | train batch 300/1500 | loss=-9.7872 | nll=-9.9425 | mse=0.0000
18:22:19 | INFO | Epoch 179 | train batch 600/1500 | loss=-10.1683 | nll=-10.3132 | mse=0.0000
18:22:40 | INFO | Epoch 179 | train batch 900/1500 | loss=-7.9280 | nll=-8.0790 | mse=0.0000
18:22:57 | INFO | Epoch 179 | train batch 1200/1500 | loss=-8.8188 | nll=-8.9728 | mse=0.0000
18:23:19 | INFO | Epoch 179 | train batch 1500/1500 | loss=-9.0953 | nll=-9.2441 | mse=0.0000
18:23:19 | INFO | Epoch 179 | train complete | mean_loss=-8.8799 | duration=99.6s
18:23:19 | INFO | Epoch 179 summary | train=-8.8799 (validation skipped)
18:23:19 | INFO | Epoch 180 started | validation=True
18:23:19 | INFO | Epoch 180 | train | batches=1500
18:23:37 | INFO | Epoch 180 | train batch 300/1500 | loss=-9.2203 | nll=-9.3719 | mse=0.0000
18:23:58 | INFO | Epoch 180 | train batch 600/1500 | loss=-9.3298 | nll=-9.4808 | mse=0.0000
18:24:16 | INFO | Epoch 180 | train batch 900/1500 | loss=-9.4115 | nll=-9.5721 | mse=0.0000
18:24:37 | INFO | Epoch 180 | train batch 1200/1500 | loss=-9.5784 | nll=-9.7237 | mse=0.0000
18:24:56 | INFO | Epoch 180 | train batch 1500/1500 | loss=-9.7272 | nll=-9.8708 | mse=0.0000
18:24:56 | INFO | Epoch 180 | train complete | mean_loss=-9.3914 | duration=96.8s
18:24:56 | INFO | Epoch 180 | val   | batches=500
18:25:02 | INFO | Epoch 180 | val batch 125/500 | loss=-9.7055 | nll=-9.8572 | mse=0.0000
18:25:04 | INFO | Epoch 180 | val batch 250/500 | loss=-9.7161 | nll=-9.8628 | mse=0.0000
18:25:07 | INFO | Epoch 180 | val batch 375/500 | loss=-9.7318 | nll=-9.8758 | mse=0.0000
18:25:10 | INFO | Epoch 180 | val batch 500/500 | loss=-9.7107 | nll=-9.8618 | mse=0.0000
18:25:10 | INFO | Epoch 180 | val complete   | mean_loss=-9.7154 | duration=14.6s
18:25:10 | INFO | Epoch 180 | test  | batches=500
18:25:12 | INFO | Epoch 180 | test batch 125/500 | nll=-9.8647 | mse=0.0000 | psnr=62.40
18:25:15 | INFO | Epoch 180 | test batch 250/500 | nll=-9.8620 | mse=0.0000 | psnr=62.55
18:25:17 | INFO | Epoch 180 | test batch 375/500 | nll=-9.8773 | mse=0.0000 | psnr=62.63
18:25:19 | INFO | Epoch 180 | test batch 500/500 | nll=-9.8581 | mse=0.0000 | psnr=62.43
18:25:19 | INFO | Epoch 180 | test complete  | mean_nll=-9.8628 | duration=8.8s
18:25:19 | INFO | Checkpoint saved to /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models/epoch_180_nf_model_net.pth (epoch 180)
18:25:19 | INFO | Checkpoint saved to /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models/best_model.pth (epoch 180)
18:25:19 | INFO | Epoch 180 summary | train=-9.3914 | val=-9.7154 | test=-9.8628 | smpl=0.0000 | best=True
18:25:19 | INFO | Epoch 181 started | validation=False
18:25:19 | INFO | Epoch 181 | train | batches=1500
18:25:40 | INFO | Epoch 181 | train batch 300/1500 | loss=-9.8850 | nll=-10.0443 | mse=0.0000
18:25:58 | INFO | Epoch 181 | train batch 600/1500 | loss=5.4682 | nll=5.3171 | mse=0.0000
18:26:20 | INFO | Epoch 181 | train batch 900/1500 | loss=-9.7553 | nll=-9.9040 | mse=0.0000
18:26:38 | INFO | Epoch 181 | train batch 1200/1500 | loss=-9.9114 | nll=-10.0760 | mse=0.0000
18:26:59 | INFO | Epoch 181 | train batch 1500/1500 | loss=-9.9133 | nll=-10.0717 | mse=0.0000
18:26:59 | INFO | Epoch 181 | train complete | mean_loss=-9.5763 | duration=99.9s
18:26:59 | INFO | Epoch 181 summary | train=-9.5763 (validation skipped)
18:26:59 | INFO | Epoch 182 started | validation=False
18:26:59 | INFO | Epoch 182 | train | batches=1500
18:27:17 | INFO | Epoch 182 | train batch 300/1500 | loss=1.6889 | nll=1.5410 | mse=0.0000
18:27:38 | INFO | Epoch 182 | train batch 600/1500 | loss=-9.6979 | nll=-9.8347 | mse=0.0000
18:27:59 | INFO | Epoch 182 | train batch 900/1500 | loss=-9.9151 | nll=-10.0705 | mse=0.0000
18:28:17 | INFO | Epoch 182 | train batch 1200/1500 | loss=-10.2156 | nll=-10.3685 | mse=0.0000
18:28:39 | INFO | Epoch 182 | train batch 1500/1500 | loss=-10.4913 | nll=-10.6487 | mse=0.0000
18:28:39 | INFO | Epoch 182 | train complete | mean_loss=-9.5738 | duration=99.6s
18:28:39 | INFO | Epoch 182 summary | train=-9.5738 (validation skipped)
18:28:39 | INFO | Epoch 183 started | validation=False
18:28:39 | INFO | Epoch 183 | train | batches=1500
18:28:57 | INFO | Epoch 183 | train batch 300/1500 | loss=-6.1565 | nll=-6.3149 | mse=0.0000
18:29:18 | INFO | Epoch 183 | train batch 600/1500 | loss=-7.1513 | nll=-7.3063 | mse=0.0000
18:29:36 | INFO | Epoch 183 | train batch 900/1500 | loss=-7.4413 | nll=-7.6007 | mse=0.0000
18:29:57 | INFO | Epoch 183 | train batch 1200/1500 | loss=-7.7399 | nll=-7.8758 | mse=0.0000
18:30:14 | INFO | Epoch 183 | train batch 1500/1500 | loss=-7.8931 | nll=-8.0320 | mse=0.0000
18:30:14 | INFO | Epoch 183 | train complete | mean_loss=-6.1845 | duration=95.6s
18:30:14 | INFO | Epoch 183 summary | train=-6.1845 (validation skipped)
18:30:14 | INFO | Epoch 184 started | validation=False
18:30:14 | INFO | Epoch 184 | train | batches=1500
18:30:36 | INFO | Epoch 184 | train batch 300/1500 | loss=-8.0525 | nll=-8.1994 | mse=0.0000
18:30:57 | INFO | Epoch 184 | train batch 600/1500 | loss=-8.2663 | nll=-8.4190 | mse=0.0000
18:31:14 | INFO | Epoch 184 | train batch 900/1500 | loss=-8.5280 | nll=-8.6751 | mse=0.0000
18:31:36 | INFO | Epoch 184 | train batch 1200/1500 | loss=-8.7995 | nll=-8.9576 | mse=0.0000
18:31:54 | INFO | Epoch 184 | train batch 1500/1500 | loss=-9.1695 | nll=-9.3155 | mse=0.0000
18:31:54 | INFO | Epoch 184 | train complete | mean_loss=-8.4336 | duration=99.3s
18:31:54 | INFO | Epoch 184 summary | train=-8.4336 (validation skipped)
18:31:54 | INFO | Epoch 185 started | validation=False
18:31:54 | INFO | Epoch 185 | train | batches=1500
18:32:15 | INFO | Epoch 185 | train batch 300/1500 | loss=-9.5594 | nll=-9.6977 | mse=0.0000
18:32:33 | INFO | Epoch 185 | train batch 600/1500 | loss=-9.9383 | nll=-10.0894 | mse=0.0000
18:32:54 | INFO | Epoch 185 | train batch 900/1500 | loss=-10.2693 | nll=-10.4243 | mse=0.0000
18:33:12 | INFO | Epoch 185 | train batch 1200/1500 | loss=-9.9349 | nll=-10.0857 | mse=0.0000
18:33:33 | INFO | Epoch 185 | train batch 1500/1500 | loss=-10.1226 | nll=-10.2677 | mse=0.0000
18:33:33 | INFO | Epoch 185 | train complete | mean_loss=-9.8213 | duration=99.2s
18:33:33 | INFO | Epoch 185 summary | train=-9.8213 (validation skipped)
18:33:33 | INFO | Epoch 186 started | validation=False
18:33:33 | INFO | Epoch 186 | train | batches=1500
18:33:50 | INFO | Epoch 186 | train batch 300/1500 | loss=-8.9682 | nll=-9.1206 | mse=0.0000
18:34:11 | INFO | Epoch 186 | train batch 600/1500 | loss=-9.1989 | nll=-9.3454 | mse=0.0000
18:34:32 | INFO | Epoch 186 | train batch 900/1500 | loss=-9.3315 | nll=-9.4797 | mse=0.0000
18:34:50 | INFO | Epoch 186 | train batch 1200/1500 | loss=-9.4553 | nll=-9.5994 | mse=0.0000
18:35:10 | INFO | Epoch 186 | train batch 1500/1500 | loss=-9.5573 | nll=-9.7098 | mse=0.0000
18:35:10 | INFO | Epoch 186 | train complete | mean_loss=-8.3950 | duration=97.3s
18:35:10 | INFO | Epoch 186 summary | train=-8.3950 (validation skipped)
18:35:10 | INFO | Epoch 187 started | validation=False
18:35:10 | INFO | Epoch 187 | train | batches=1500
18:35:28 | INFO | Epoch 187 | train batch 300/1500 | loss=-9.6844 | nll=-9.8298 | mse=0.0000
18:35:48 | INFO | Epoch 187 | train batch 600/1500 | loss=-9.8172 | nll=-9.9604 | mse=0.0000
18:36:06 | INFO | Epoch 187 | train batch 900/1500 | loss=-9.9618 | nll=-10.1060 | mse=0.0000
18:36:26 | INFO | Epoch 187 | train batch 1200/1500 | loss=-10.1192 | nll=-10.2648 | mse=0.0000
18:36:44 | INFO | Epoch 187 | train batch 1500/1500 | loss=-10.3261 | nll=-10.4649 | mse=0.0000
18:36:44 | INFO | Epoch 187 | train complete | mean_loss=-9.8918 | duration=93.8s
18:36:44 | INFO | Epoch 187 summary | train=-9.8918 (validation skipped)
18:36:44 | INFO | Epoch 188 started | validation=False
18:36:44 | INFO | Epoch 188 | train | batches=1500
18:37:05 | INFO | Epoch 188 | train batch 300/1500 | loss=-9.7412 | nll=-9.8974 | mse=0.0000
18:37:22 | INFO | Epoch 188 | train batch 600/1500 | loss=32.7746 | nll=32.6297 | mse=0.0000
18:37:43 | INFO | Epoch 188 | train batch 900/1500 | loss=-9.5027 | nll=-9.6488 | mse=0.0000
18:38:04 | INFO | Epoch 188 | train batch 1200/1500 | loss=-9.7927 | nll=-9.9464 | mse=0.0000
18:38:21 | INFO | Epoch 188 | train batch 1500/1500 | loss=-10.0072 | nll=-10.1641 | mse=0.0000
18:38:21 | INFO | Epoch 188 | train complete | mean_loss=-9.6032 | duration=96.7s
18:38:21 | INFO | Epoch 188 summary | train=-9.6032 (validation skipped)
18:38:21 | INFO | Epoch 189 started | validation=False
18:38:21 | INFO | Epoch 189 | train | batches=1500
18:38:42 | INFO | Epoch 189 | train batch 300/1500 | loss=-7.4185 | nll=-7.5630 | mse=0.0000
18:38:59 | INFO | Epoch 189 | train batch 600/1500 | loss=-8.1520 | nll=-8.2968 | mse=0.0000
18:39:20 | INFO | Epoch 189 | train batch 900/1500 | loss=-10.0686 | nll=-10.2097 | mse=0.0000
18:39:38 | INFO | Epoch 189 | train batch 1200/1500 | loss=-10.2970 | nll=-10.4433 | mse=0.0000
18:39:58 | INFO | Epoch 189 | train batch 1500/1500 | loss=-10.1584 | nll=-10.3130 | mse=0.0000
18:39:58 | INFO | Epoch 189 | train complete | mean_loss=-9.7453 | duration=97.5s
18:39:58 | INFO | Epoch 189 summary | train=-9.7453 (validation skipped)
18:39:58 | INFO | Epoch 190 started | validation=True
18:39:58 | INFO | Epoch 190 | train | batches=1500
18:40:16 | INFO | Epoch 190 | train batch 300/1500 | loss=-8.7472 | nll=-8.8907 | mse=0.0000
18:40:36 | INFO | Epoch 190 | train batch 600/1500 | loss=-9.1760 | nll=-9.3173 | mse=0.0000
18:40:54 | INFO | Epoch 190 | train batch 900/1500 | loss=-9.5835 | nll=-9.7381 | mse=0.0000
18:41:11 | INFO | Epoch 190 | train batch 1200/1500 | loss=-9.9076 | nll=-10.0503 | mse=0.0000
18:41:34 | INFO | Epoch 190 | train batch 1500/1500 | loss=-10.0158 | nll=-10.1641 | mse=0.0000
18:41:34 | INFO | Epoch 190 | train complete | mean_loss=-9.1600 | duration=95.6s
18:41:34 | INFO | Epoch 190 | val   | batches=500
18:41:37 | INFO | Epoch 190 | val batch 125/500 | loss=-8.2245 | nll=-8.3762 | mse=0.0000
18:41:39 | INFO | Epoch 190 | val batch 250/500 | loss=-8.2221 | nll=-8.3688 | mse=0.0000
18:41:42 | INFO | Epoch 190 | val batch 375/500 | loss=-8.2304 | nll=-8.3744 | mse=0.0000
18:41:45 | INFO | Epoch 190 | val batch 500/500 | loss=-8.2169 | nll=-8.3680 | mse=0.0000
18:41:45 | INFO | Epoch 190 | val complete   | mean_loss=-8.2256 | duration=11.1s
18:41:45 | INFO | Epoch 190 | test  | batches=500
18:41:47 | INFO | Epoch 190 | test batch 125/500 | nll=-8.4774 | mse=0.0000 | psnr=62.40
18:41:49 | INFO | Epoch 190 | test batch 250/500 | nll=-8.3528 | mse=0.0000 | psnr=62.55
18:41:52 | INFO | Epoch 190 | test batch 375/500 | nll=-8.3839 | mse=0.0000 | psnr=62.63
18:41:54 | INFO | Epoch 190 | test batch 500/500 | nll=-8.3308 | mse=0.0000 | psnr=62.43
18:41:54 | INFO | Epoch 190 | test complete  | mean_nll=-8.3498 | duration=9.2s
18:41:54 | INFO | Checkpoint saved to /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models/epoch_190_nf_model_net.pth (epoch 190)
18:41:54 | INFO | Epoch 190 summary | train=-9.1600 | val=-8.2256 | test=-8.3498 | smpl=0.0000 | best=False
18:41:54 | INFO | Epoch 191 started | validation=False
18:41:54 | INFO | Epoch 191 | train | batches=1500
18:42:17 | INFO | Epoch 191 | train batch 300/1500 | loss=-10.2306 | nll=-10.3772 | mse=0.0000
18:42:34 | INFO | Epoch 191 | train batch 600/1500 | loss=-9.6078 | nll=-9.7610 | mse=0.0000
18:42:51 | INFO | Epoch 191 | train batch 900/1500 | loss=-10.3910 | nll=-10.5435 | mse=0.0000
18:43:10 | INFO | Epoch 191 | train batch 1200/1500 | loss=-8.6873 | nll=-8.8421 | mse=0.0000
18:43:36 | INFO | Epoch 191 | train batch 1500/1500 | loss=-8.9994 | nll=-9.1412 | mse=0.0000
18:43:36 | INFO | Epoch 191 | train complete | mean_loss=-9.6976 | duration=101.8s
18:43:36 | INFO | Epoch 191 summary | train=-9.6976 (validation skipped)
18:43:36 | INFO | Epoch 192 started | validation=False
18:43:36 | INFO | Epoch 192 | train | batches=1500
18:43:57 | INFO | Epoch 192 | train batch 300/1500 | loss=-9.1937 | nll=-9.3444 | mse=0.0000
18:44:15 | INFO | Epoch 192 | train batch 600/1500 | loss=-9.4870 | nll=-9.6428 | mse=0.0000
18:44:34 | INFO | Epoch 192 | train batch 900/1500 | loss=-10.0498 | nll=-10.1798 | mse=0.0000
18:44:53 | INFO | Epoch 192 | train batch 1200/1500 | loss=-10.5513 | nll=-10.7016 | mse=0.0000
18:45:13 | INFO | Epoch 192 | train batch 1500/1500 | loss=-9.8632 | nll=-10.0189 | mse=0.0000
18:45:13 | INFO | Epoch 192 | train complete | mean_loss=-9.5341 | duration=97.4s
18:45:13 | INFO | Epoch 192 summary | train=-9.5341 (validation skipped)
18:45:13 | INFO | Epoch 193 started | validation=False
18:45:13 | INFO | Epoch 193 | train | batches=1500
18:45:32 | INFO | Epoch 193 | train batch 300/1500 | loss=-8.9170 | nll=-9.0633 | mse=0.0000
18:45:53 | INFO | Epoch 193 | train batch 600/1500 | loss=-9.8156 | nll=-9.9624 | mse=0.0000
18:46:14 | INFO | Epoch 193 | train batch 900/1500 | loss=-9.6772 | nll=-9.8171 | mse=0.0000
18:46:32 | INFO | Epoch 193 | train batch 1200/1500 | loss=-10.3959 | nll=-10.5461 | mse=0.0000
18:46:53 | INFO | Epoch 193 | train batch 1500/1500 | loss=-10.4979 | nll=-10.6383 | mse=0.0000
18:46:53 | INFO | Epoch 193 | train complete | mean_loss=-9.7573 | duration=99.4s
18:46:53 | INFO | Epoch 193 summary | train=-9.7573 (validation skipped)
18:46:53 | INFO | Epoch 194 started | validation=False
18:46:53 | INFO | Epoch 194 | train | batches=1500
18:47:11 | INFO | Epoch 194 | train batch 300/1500 | loss=-10.6539 | nll=-10.8099 | mse=0.0000
18:47:32 | INFO | Epoch 194 | train batch 600/1500 | loss=-8.5824 | nll=-8.7129 | mse=0.0000
18:47:51 | INFO | Epoch 194 | train batch 900/1500 | loss=-10.6922 | nll=-10.8429 | mse=0.0000
18:48:12 | INFO | Epoch 194 | train batch 1200/1500 | loss=-10.5742 | nll=-10.7242 | mse=0.0000
18:48:30 | INFO | Epoch 194 | train batch 1500/1500 | loss=-10.4256 | nll=-10.5560 | mse=0.0000
18:48:30 | INFO | Epoch 194 | train complete | mean_loss=-10.1583 | duration=97.4s
18:48:30 | INFO | Epoch 194 summary | train=-10.1583 (validation skipped)
18:48:30 | INFO | Epoch 195 started | validation=False
18:48:30 | INFO | Epoch 195 | train | batches=1500
18:48:51 | INFO | Epoch 195 | train batch 300/1500 | loss=-6.9920 | nll=-7.1368 | mse=0.0000
18:49:12 | INFO | Epoch 195 | train batch 600/1500 | loss=-7.1544 | nll=-7.3099 | mse=0.0000
18:49:30 | INFO | Epoch 195 | train batch 900/1500 | loss=-7.3731 | nll=-7.5219 | mse=0.0000
18:49:51 | INFO | Epoch 195 | train batch 1200/1500 | loss=-7.5739 | nll=-7.7235 | mse=0.0000
18:50:09 | INFO | Epoch 195 | train batch 1500/1500 | loss=-7.7935 | nll=-7.9504 | mse=0.0000
18:50:09 | INFO | Epoch 195 | train complete | mean_loss=-6.9952 | duration=98.7s
18:50:09 | INFO | Epoch 195 summary | train=-6.9952 (validation skipped)
18:50:09 | INFO | Epoch 196 started | validation=False
18:50:09 | INFO | Epoch 196 | train | batches=1500
18:50:30 | INFO | Epoch 196 | train batch 300/1500 | loss=-8.0431 | nll=-8.1891 | mse=0.0000
18:50:49 | INFO | Epoch 196 | train batch 600/1500 | loss=-8.2799 | nll=-8.4353 | mse=0.0000
18:51:10 | INFO | Epoch 196 | train batch 900/1500 | loss=-8.5189 | nll=-8.6727 | mse=0.0000
18:51:31 | INFO | Epoch 196 | train batch 1200/1500 | loss=-8.6178 | nll=-8.7667 | mse=0.0000
18:51:49 | INFO | Epoch 196 | train batch 1500/1500 | loss=-8.6224 | nll=-8.7727 | mse=0.0000
18:51:49 | INFO | Epoch 196 | train complete | mean_loss=-8.3239 | duration=100.2s
18:51:49 | INFO | Epoch 196 summary | train=-8.3239 (validation skipped)
18:51:49 | INFO | Epoch 197 started | validation=False
18:51:49 | INFO | Epoch 197 | train | batches=1500
18:52:10 | INFO | Epoch 197 | train batch 300/1500 | loss=-8.6867 | nll=-8.8490 | mse=0.0000
18:52:28 | INFO | Epoch 197 | train batch 600/1500 | loss=-8.8851 | nll=-9.0387 | mse=0.0000
18:52:49 | INFO | Epoch 197 | train batch 900/1500 | loss=-8.6703 | nll=-8.8164 | mse=0.0000
18:53:07 | INFO | Epoch 197 | train batch 1200/1500 | loss=-8.9915 | nll=-9.1403 | mse=0.0000
18:53:29 | INFO | Epoch 197 | train batch 1500/1500 | loss=-8.9219 | nll=-9.0628 | mse=0.0000
18:53:29 | INFO | Epoch 197 | train complete | mean_loss=-8.8216 | duration=99.5s
18:53:29 | INFO | Epoch 197 summary | train=-8.8216 (validation skipped)
18:53:29 | INFO | Epoch 198 started | validation=False
18:53:29 | INFO | Epoch 198 | train | batches=1500
18:53:46 | INFO | Epoch 198 | train batch 300/1500 | loss=-8.8802 | nll=-9.0265 | mse=0.0000
18:54:07 | INFO | Epoch 198 | train batch 600/1500 | loss=-7.9293 | nll=-8.0915 | mse=0.0000
18:54:28 | INFO | Epoch 198 | train batch 900/1500 | loss=-9.1306 | nll=-9.2719 | mse=0.0000
18:54:47 | INFO | Epoch 198 | train batch 1200/1500 | loss=-9.3591 | nll=-9.5001 | mse=0.0000
18:55:08 | INFO | Epoch 198 | train batch 1500/1500 | loss=-9.1430 | nll=-9.2926 | mse=0.0000
18:55:08 | INFO | Epoch 198 | train complete | mean_loss=-9.0650 | duration=99.0s
18:55:08 | INFO | Epoch 198 summary | train=-9.0650 (validation skipped)
18:55:08 | INFO | Epoch 199 started | validation=False
18:55:08 | INFO | Epoch 199 | train | batches=1500
18:55:26 | INFO | Epoch 199 | train batch 300/1500 | loss=-9.2427 | nll=-9.3937 | mse=0.0000
18:55:47 | INFO | Epoch 199 | train batch 600/1500 | loss=-9.2623 | nll=-9.4068 | mse=0.0000
18:56:05 | INFO | Epoch 199 | train batch 900/1500 | loss=-9.4193 | nll=-9.5675 | mse=0.0000
18:56:26 | INFO | Epoch 199 | train batch 1200/1500 | loss=-9.3916 | nll=-9.5436 | mse=0.0000
18:56:47 | INFO | Epoch 199 | train batch 1500/1500 | loss=-9.4298 | nll=-9.5804 | mse=0.0000
18:56:47 | INFO | Epoch 199 | train complete | mean_loss=-9.2350 | duration=99.2s
18:56:47 | INFO | Epoch 199 summary | train=-9.2350 (validation skipped)
18:56:47 | INFO | Epoch 200 started | validation=True
18:56:47 | INFO | Epoch 200 | train | batches=1500
18:57:05 | INFO | Epoch 200 | train batch 300/1500 | loss=-9.2201 | nll=-9.3564 | mse=0.0000
18:57:27 | INFO | Epoch 200 | train batch 600/1500 | loss=-9.4136 | nll=-9.5616 | mse=0.0000
18:57:45 | INFO | Epoch 200 | train batch 900/1500 | loss=-9.5560 | nll=-9.7034 | mse=0.0000
18:58:06 | INFO | Epoch 200 | train batch 1200/1500 | loss=-9.6455 | nll=-9.7908 | mse=0.0000
18:58:24 | INFO | Epoch 200 | train batch 1500/1500 | loss=-8.9578 | nll=-9.0969 | mse=0.0000
18:58:24 | INFO | Epoch 200 | train complete | mean_loss=-9.4890 | duration=97.2s
18:58:24 | INFO | Epoch 200 | val   | batches=500
18:58:27 | INFO | Epoch 200 | val batch 125/500 | loss=-9.6892 | nll=-9.8408 | mse=0.0000
18:58:32 | INFO | Epoch 200 | val batch 250/500 | loss=-9.7018 | nll=-9.8485 | mse=0.0000
18:58:35 | INFO | Epoch 200 | val batch 375/500 | loss=-9.7194 | nll=-9.8633 | mse=0.0000
18:58:38 | INFO | Epoch 200 | val batch 500/500 | loss=-9.6865 | nll=-9.8376 | mse=0.0000
18:58:38 | INFO | Epoch 200 | val complete   | mean_loss=-9.6984 | duration=14.2s
18:58:38 | INFO | Epoch 200 | test  | batches=500
18:58:40 | INFO | Epoch 200 | test batch 125/500 | nll=-9.8517 | mse=0.0000 | psnr=62.40
18:58:42 | INFO | Epoch 200 | test batch 250/500 | nll=-9.8553 | mse=0.0000 | psnr=62.55
18:58:45 | INFO | Epoch 200 | test batch 375/500 | nll=-9.8713 | mse=0.0000 | psnr=62.63
18:58:47 | INFO | Epoch 200 | test batch 500/500 | nll=-9.8385 | mse=0.0000 | psnr=62.43
18:58:47 | INFO | Epoch 200 | test complete  | mean_nll=-9.8524 | duration=8.6s
18:58:47 | INFO | Checkpoint saved to /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models/epoch_200_nf_model_net.pth (epoch 200)
18:58:47 | INFO | Epoch 200 summary | train=-9.4890 | val=-9.6984 | test=-9.8524 | smpl=0.0000 | best=False
18:58:47 | INFO | Epoch 201 started | validation=False
18:58:47 | INFO | Epoch 201 | train | batches=1500
18:59:08 | INFO | Epoch 201 | train batch 300/1500 | loss=-9.6624 | nll=-9.8079 | mse=0.0000
18:59:26 | INFO | Epoch 201 | train batch 600/1500 | loss=-9.3073 | nll=-9.4511 | mse=0.0000
18:59:47 | INFO | Epoch 201 | train batch 900/1500 | loss=-10.2049 | nll=-10.3507 | mse=0.0000
19:00:05 | INFO | Epoch 201 | train batch 1200/1500 | loss=-10.1342 | nll=-10.2712 | mse=0.0000
19:00:26 | INFO | Epoch 201 | train batch 1500/1500 | loss=-10.3007 | nll=-10.4509 | mse=0.0000
19:00:26 | INFO | Epoch 201 | train complete | mean_loss=-9.9069 | duration=98.9s
19:00:26 | INFO | Epoch 201 summary | train=-9.9069 (validation skipped)
19:00:26 | INFO | Epoch 202 started | validation=False
19:00:26 | INFO | Epoch 202 | train | batches=1500
19:00:44 | INFO | Epoch 202 | train batch 300/1500 | loss=-10.1892 | nll=-10.3470 | mse=0.0000
19:01:05 | INFO | Epoch 202 | train batch 600/1500 | loss=-9.9060 | nll=-10.0512 | mse=0.0000
19:01:23 | INFO | Epoch 202 | train batch 900/1500 | loss=-10.3032 | nll=-10.4499 | mse=0.0000
19:01:44 | INFO | Epoch 202 | train batch 1200/1500 | loss=-10.1006 | nll=-10.2503 | mse=0.0000
19:02:05 | INFO | Epoch 202 | train batch 1500/1500 | loss=-10.0849 | nll=-10.2361 | mse=0.0000
19:02:05 | INFO | Epoch 202 | train complete | mean_loss=-10.0512 | duration=99.5s
19:02:05 | INFO | Epoch 202 summary | train=-10.0512 (validation skipped)
19:02:05 | INFO | Epoch 203 started | validation=False
19:02:05 | INFO | Epoch 203 | train | batches=1500
19:02:23 | INFO | Epoch 203 | train batch 300/1500 | loss=-10.4305 | nll=-10.5886 | mse=0.0000
19:02:44 | INFO | Epoch 203 | train batch 600/1500 | loss=-9.4910 | nll=-9.6344 | mse=0.0000
19:03:02 | INFO | Epoch 203 | train batch 900/1500 | loss=-9.9616 | nll=-10.1160 | mse=0.0000
19:03:23 | INFO | Epoch 203 | train batch 1200/1500 | loss=-9.7412 | nll=-9.8965 | mse=0.0000
19:03:42 | INFO | Epoch 203 | train batch 1500/1500 | loss=-9.3862 | nll=-9.5312 | mse=0.0000
19:03:42 | INFO | Epoch 203 | train complete | mean_loss=-9.8162 | duration=96.5s
19:03:42 | INFO | Epoch 203 summary | train=-9.8162 (validation skipped)
19:03:42 | INFO | Epoch 204 started | validation=False
19:03:42 | INFO | Epoch 204 | train | batches=1500
19:04:03 | INFO | Epoch 204 | train batch 300/1500 | loss=-10.2713 | nll=-10.4055 | mse=0.0000
19:04:21 | INFO | Epoch 204 | train batch 600/1500 | loss=-9.7221 | nll=-9.8695 | mse=0.0000
19:04:41 | INFO | Epoch 204 | train batch 900/1500 | loss=-10.4510 | nll=-10.5955 | mse=0.0000
19:05:02 | INFO | Epoch 204 | train batch 1200/1500 | loss=-5.1309 | nll=-5.2895 | mse=0.0000
19:05:20 | INFO | Epoch 204 | train batch 1500/1500 | loss=-9.6274 | nll=-9.7763 | mse=0.0000
19:05:20 | INFO | Epoch 204 | train complete | mean_loss=-9.6525 | duration=98.5s
19:05:20 | INFO | Epoch 204 summary | train=-9.6525 (validation skipped)
19:05:20 | INFO | Epoch 205 started | validation=False
19:05:20 | INFO | Epoch 205 | train | batches=1500
19:05:42 | INFO | Epoch 205 | train batch 300/1500 | loss=-9.8863 | nll=-10.0397 | mse=0.0000
19:06:00 | INFO | Epoch 205 | train batch 600/1500 | loss=-10.2156 | nll=-10.3626 | mse=0.0000
19:06:21 | INFO | Epoch 205 | train batch 900/1500 | loss=-10.3845 | nll=-10.5349 | mse=0.0000
19:06:39 | INFO | Epoch 205 | train batch 1200/1500 | loss=-10.5923 | nll=-10.7336 | mse=0.0000
19:07:00 | INFO | Epoch 205 | train batch 1500/1500 | loss=-9.4117 | nll=-9.5637 | mse=0.0000
19:07:00 | INFO | Epoch 205 | train complete | mean_loss=-9.8386 | duration=99.6s
19:07:00 | INFO | Epoch 205 summary | train=-9.8386 (validation skipped)
19:07:00 | INFO | Epoch 206 started | validation=False
19:07:00 | INFO | Epoch 206 | train | batches=1500
19:07:21 | INFO | Epoch 206 | train batch 300/1500 | loss=-9.8511 | nll=-10.0115 | mse=0.0000
19:07:39 | INFO | Epoch 206 | train batch 600/1500 | loss=-10.2887 | nll=-10.4373 | mse=0.0000
19:07:57 | INFO | Epoch 206 | train batch 900/1500 | loss=-10.5448 | nll=-10.6908 | mse=0.0000
19:08:20 | INFO | Epoch 206 | train batch 1200/1500 | loss=-8.3542 | nll=-8.5116 | mse=0.0000
19:08:38 | INFO | Epoch 206 | train batch 1500/1500 | loss=-8.7582 | nll=-8.9135 | mse=0.0000
19:08:38 | INFO | Epoch 206 | train complete | mean_loss=-9.1270 | duration=98.1s
19:08:38 | INFO | Epoch 206 summary | train=-9.1270 (validation skipped)
19:08:38 | INFO | Epoch 207 started | validation=False
19:08:38 | INFO | Epoch 207 | train | batches=1500
19:08:59 | INFO | Epoch 207 | train batch 300/1500 | loss=-8.9298 | nll=-9.0896 | mse=0.0000
19:09:17 | INFO | Epoch 207 | train batch 600/1500 | loss=-9.1836 | nll=-9.3342 | mse=0.0000
19:09:38 | INFO | Epoch 207 | train batch 900/1500 | loss=-9.4795 | nll=-9.6317 | mse=0.0000
19:09:59 | INFO | Epoch 207 | train batch 1200/1500 | loss=-10.0481 | nll=-10.1976 | mse=0.0000
19:10:18 | INFO | Epoch 207 | train batch 1500/1500 | loss=-10.4229 | nll=-10.5697 | mse=0.0000
19:10:18 | INFO | Epoch 207 | train complete | mean_loss=-9.4511 | duration=99.8s
19:10:18 | INFO | Epoch 207 summary | train=-9.4511 (validation skipped)
19:10:18 | INFO | Epoch 208 started | validation=False
19:10:18 | INFO | Epoch 208 | train | batches=1500
19:10:39 | INFO | Epoch 208 | train batch 300/1500 | loss=-9.1898 | nll=-9.3393 | mse=0.0000
19:10:57 | INFO | Epoch 208 | train batch 600/1500 | loss=-9.4777 | nll=-9.6225 | mse=0.0000
19:11:18 | INFO | Epoch 208 | train batch 900/1500 | loss=-9.7628 | nll=-9.9154 | mse=0.0000
19:11:36 | INFO | Epoch 208 | train batch 1200/1500 | loss=-10.0729 | nll=-10.2179 | mse=0.0000
19:11:57 | INFO | Epoch 208 | train batch 1500/1500 | loss=-10.3309 | nll=-10.4912 | mse=0.0000
19:11:57 | INFO | Epoch 208 | train complete | mean_loss=-9.4107 | duration=99.5s
19:11:57 | INFO | Epoch 208 summary | train=-9.4107 (validation skipped)
19:11:57 | INFO | Epoch 209 started | validation=False
19:11:57 | INFO | Epoch 209 | train | batches=1500
19:12:15 | INFO | Epoch 209 | train batch 300/1500 | loss=-10.5054 | nll=-10.6491 | mse=0.0000
19:12:37 | INFO | Epoch 209 | train batch 600/1500 | loss=-10.5224 | nll=-10.6623 | mse=0.0000
19:12:57 | INFO | Epoch 209 | train batch 900/1500 | loss=-9.2120 | nll=-9.3701 | mse=0.0000
19:13:16 | INFO | Epoch 209 | train batch 1200/1500 | loss=-9.5245 | nll=-9.6698 | mse=0.0000
19:13:37 | INFO | Epoch 209 | train batch 1500/1500 | loss=-9.7011 | nll=-9.8615 | mse=0.0000
19:13:37 | INFO | Epoch 209 | train complete | mean_loss=-9.1890 | duration=99.7s
19:13:37 | INFO | Epoch 209 summary | train=-9.1890 (validation skipped)
19:13:37 | INFO | Epoch 210 started | validation=True
19:13:37 | INFO | Epoch 210 | train | batches=1500
19:13:55 | INFO | Epoch 210 | train batch 300/1500 | loss=-9.8667 | nll=-10.0198 | mse=0.0000
19:14:16 | INFO | Epoch 210 | train batch 600/1500 | loss=-9.9865 | nll=-10.1403 | mse=0.0000
19:14:34 | INFO | Epoch 210 | train batch 900/1500 | loss=-10.0833 | nll=-10.2361 | mse=0.0000
19:14:56 | INFO | Epoch 210 | train batch 1200/1500 | loss=-10.3609 | nll=-10.5110 | mse=0.0000
19:15:17 | INFO | Epoch 210 | train batch 1500/1500 | loss=-10.6040 | nll=-10.7521 | mse=0.0000
19:15:17 | INFO | Epoch 210 | train complete | mean_loss=-10.0941 | duration=99.8s
19:15:17 | INFO | Epoch 210 | val   | batches=500
19:15:20 | INFO | Epoch 210 | val batch 125/500 | loss=-10.1977 | nll=-10.3494 | mse=0.0000
19:15:23 | INFO | Epoch 210 | val batch 250/500 | loss=-10.2075 | nll=-10.3542 | mse=0.0000
19:15:25 | INFO | Epoch 210 | val batch 375/500 | loss=-10.2186 | nll=-10.3626 | mse=0.0000
19:15:28 | INFO | Epoch 210 | val batch 500/500 | loss=-10.2013 | nll=-10.3524 | mse=0.0000
19:15:28 | INFO | Epoch 210 | val complete   | mean_loss=-10.2016 | duration=11.6s
19:15:28 | INFO | Epoch 210 | test  | batches=500
19:15:30 | INFO | Epoch 210 | test batch 125/500 | nll=-10.3472 | mse=0.0000 | psnr=62.40
19:15:32 | INFO | Epoch 210 | test batch 250/500 | nll=-10.3484 | mse=0.0000 | psnr=62.55
19:15:35 | INFO | Epoch 210 | test batch 375/500 | nll=-10.3587 | mse=0.0000 | psnr=62.63
19:15:37 | INFO | Epoch 210 | test batch 500/500 | nll=-10.3465 | mse=0.0000 | psnr=62.43
19:15:37 | INFO | Epoch 210 | test complete  | mean_nll=-10.3466 | duration=8.4s
19:15:37 | INFO | Checkpoint saved to /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models/epoch_210_nf_model_net.pth (epoch 210)
19:15:37 | INFO | Checkpoint saved to /home/krissatom/Noise2NoiseFlow/noise2noiseflow/experiments/paper/n2nf/saved_models/best_model.pth (epoch 210)
19:15:37 | INFO | Epoch 210 summary | train=-10.0941 | val=-10.2016 | test=-10.3466 | smpl=0.0000 | best=True
19:15:37 | INFO | Epoch 211 started | validation=False
19:15:37 | INFO | Epoch 211 | train | batches=1500
19:15:58 | INFO | Epoch 211 | train batch 300/1500 | loss=-10.7474 | nll=-10.9007 | mse=0.0000
19:16:16 | INFO | Epoch 211 | train batch 600/1500 | loss=-11.0969 | nll=-11.2374 | mse=0.0000
19:16:37 | INFO | Epoch 211 | train batch 900/1500 | loss=-11.3135 | nll=-11.4481 | mse=0.0000
19:16:55 | INFO | Epoch 211 | train batch 1200/1500 | loss=-9.2261 | nll=-9.3706 | mse=0.0000
19:17:16 | INFO | Epoch 211 | train batch 1500/1500 | loss=-9.3557 | nll=-9.5077 | mse=0.0000
19:17:16 | INFO | Epoch 211 | train complete | mean_loss=-8.2094 | duration=99.2s
19:17:16 | INFO | Epoch 211 summary | train=-8.2094 (validation skipped)
19:17:16 | INFO | Epoch 212 started | validation=False
19:17:16 | INFO | Epoch 212 | train | batches=1500
19:17:37 | INFO | Epoch 212 | train batch 300/1500 | loss=-9.4327 | nll=-9.5911 | mse=0.0000
19:17:56 | INFO | Epoch 212 | train batch 600/1500 | loss=-9.5850 | nll=-9.7250 | mse=0.0000
19:18:16 | INFO | Epoch 212 | train batch 900/1500 | loss=-9.6082 | nll=-9.7539 | mse=0.0000
19:18:35 | INFO | Epoch 212 | train batch 1200/1500 | loss=-9.8392 | nll=-9.9864 | mse=0.0000
19:18:56 | INFO | Epoch 212 | train batch 1500/1500 | loss=-9.9500 | nll=-10.0845 | mse=0.0000
19:18:56 | INFO | Epoch 212 | train complete | mean_loss=-9.6194 | duration=99.4s
19:18:56 | INFO | Epoch 212 summary | train=-9.6194 (validation skipped)
19:18:56 | INFO | Epoch 213 started | validation=False
19:18:56 | INFO | Epoch 213 | train | batches=1500
19:19:14 | INFO | Epoch 213 | train batch 300/1500 | loss=-9.8595 | nll=-10.0059 | mse=0.0000
19:19:35 | INFO | Epoch 213 | train batch 600/1500 | loss=-10.2529 | nll=-10.4040 | mse=0.0000
19:19:53 | INFO | Epoch 213 | train batch 900/1500 | loss=-10.4229 | nll=-10.5767 | mse=0.0000
19:20:14 | INFO | Epoch 213 | train batch 1200/1500 | loss=-10.7678 | nll=-10.8988 | mse=0.0000
19:20:35 | INFO | Epoch 213 | train batch 1500/1500 | loss=-10.6244 | nll=-10.7684 | mse=0.0000
19:20:35 | INFO | Epoch 213 | train complete | mean_loss=-10.1949 | duration=99.6s
19:20:35 | INFO | Epoch 213 summary | train=-10.1949 (validation skipped)
19:20:35 | INFO | Epoch 214 started | validation=False
19:20:35 | INFO | Epoch 214 | train | batches=1500
19:20:53 | INFO | Epoch 214 | train batch 300/1500 | loss=-10.9155 | nll=-11.0669 | mse=0.0000
19:21:14 | INFO | Epoch 214 | train batch 600/1500 | loss=-9.8088 | nll=-9.9522 | mse=0.0000
19:21:32 | INFO | Epoch 214 | train batch 900/1500 | loss=-10.1865 | nll=-10.3352 | mse=0.0000
19:21:53 | INFO | Epoch 214 | train batch 1200/1500 | loss=-10.3808 | nll=-10.5284 | mse=0.0000
19:22:11 | INFO | Epoch 214 | train batch 1500/1500 | loss=-10.5725 | nll=-10.7319 | mse=0.0000
19:22:11 | INFO | Epoch 214 | train complete | mean_loss=-9.8852 | duration=95.6s
19:22:11 | INFO | Epoch 214 summary | train=-9.8852 (validation skipped)
19:22:11 | INFO | Epoch 215 started | validation=False
19:22:11 | INFO | Epoch 215 | train | batches=1500
19:22:33 | INFO | Epoch 215 | train batch 300/1500 | loss=-10.7971 | nll=-10.9511 | mse=0.0000
19:22:54 | INFO | Epoch 215 | train batch 600/1500 | loss=-10.4907 | nll=-10.6526 | mse=0.0000
19:23:12 | INFO | Epoch 215 | train batch 900/1500 | loss=-10.6643 | nll=-10.8143 | mse=0.0000
19:23:33 | INFO | Epoch 215 | train batch 1200/1500 | loss=-10.9227 | nll=-11.0654 | mse=0.0000
19:23:51 | INFO | Epoch 215 | train batch 1500/1500 | loss=-10.0000 | nll=-10.1391 | mse=0.0000
19:23:51 | INFO | Epoch 215 | train complete | mean_loss=-10.4290 | duration=100.2s
19:23:51 | INFO | Epoch 215 summary | train=-10.4290 (validation skipped)
19:23:51 | INFO | Epoch 216 started | validation=False
19:23:51 | INFO | Epoch 216 | train | batches=1500
19:24:12 | INFO | Epoch 216 | train batch 300/1500 | loss=-10.6360 | nll=-10.7777 | mse=0.0000
19:24:30 | INFO | Epoch 216 | train batch 600/1500 | loss=-10.8638 | nll=-11.0211 | mse=0.0000
19:24:52 | INFO | Epoch 216 | train batch 900/1500 | loss=-11.1419 | nll=-11.2918 | mse=0.0000
19:25:13 | INFO | Epoch 216 | train batch 1200/1500 | loss=-9.9655 | nll=-10.1085 | mse=0.0000
19:25:31 | INFO | Epoch 216 | train batch 1500/1500 | loss=-10.2171 | nll=-10.3616 | mse=0.0000
19:25:31 | INFO | Epoch 216 | train complete | mean_loss=-9.8334 | duration=100.2s
19:25:31 | INFO | Epoch 216 summary | train=-9.8334 (validation skipped)
19:25:31 | INFO | Epoch 217 started | validation=False
19:25:31 | INFO | Epoch 217 | train | batches=1500
19:25:52 | INFO | Epoch 217 | train batch 300/1500 | loss=-10.3929 | nll=-10.5293 | mse=0.0000
19:26:10 | INFO | Epoch 217 | train batch 600/1500 | loss=-10.4163 | nll=-10.5651 | mse=0.0000
19:26:31 | INFO | Epoch 217 | train batch 900/1500 | loss=-10.6584 | nll=-10.8170 | mse=0.0000
19:26:50 | INFO | Epoch 217 | train batch 1200/1500 | loss=-10.8010 | nll=-10.9454 | mse=0.0000
19:27:10 | INFO | Epoch 217 | train batch 1500/1500 | loss=-9.6212 | nll=-9.7857 | mse=0.0000
19:27:10 | INFO | Epoch 217 | train complete | mean_loss=-9.8900 | duration=99.2s
19:27:10 | INFO | Epoch 217 summary | train=-9.8900 (validation skipped)
19:27:10 | INFO | Epoch 218 started | validation=False
19:27:10 | INFO | Epoch 218 | train | batches=1500
19:27:29 | INFO | Epoch 218 | train batch 300/1500 | loss=-9.7046 | nll=-9.8619 | mse=0.0000
19:27:50 | INFO | Epoch 218 | train batch 600/1500 | loss=-9.7852 | nll=-9.9489 | mse=0.0000
19:28:11 | INFO | Epoch 218 | train batch 900/1500 | loss=-9.9952 | nll=-10.1331 | mse=0.0000
19:28:30 | INFO | Epoch 218 | train batch 1200/1500 | loss=-10.3275 | nll=-10.4784 | mse=0.0000
19:28:51 | INFO | Epoch 218 | train batch 1500/1500 | loss=-10.3822 | nll=-10.5289 | mse=0.0000
19:28:51 | INFO | Epoch 218 | train complete | mean_loss=-10.0475 | duration=100.1s
19:28:51 | INFO | Epoch 218 summary | train=-10.0475 (validation skipped)
19:28:51 | INFO | Epoch 219 started | validation=False
19:28:51 | INFO | Epoch 219 | train | batches=1500
19:29:09 | INFO | Epoch 219 | train batch 300/1500 | loss=-10.4768 | nll=-10.6285 | mse=0.0000
19:29:29 | INFO | Epoch 219 | train batch 600/1500 | loss=-10.5592 | nll=-10.7151 | mse=0.0000
19:29:48 | INFO | Epoch 219 | train batch 900/1500 | loss=-10.3955 | nll=-10.5399 | mse=0.0000
Fatal Python error: Segmentation fault

Current thread 0x00007c89cba0b6c0 (most recent call first):
  <no Python frame>

Thread 0x00007c8a1abff6c0 (most recent call first):
  File "/home/krissatom/miniconda3/envs/n2nf/lib/python3.10/threading.py", line 324 in wait
  File "/home/krissatom/miniconda3/envs/n2nf/lib/python3.10/queue.py", line 180 in get
  File "/home/krissatom/miniconda3/envs/n2nf/lib/python3.10/site-packages/tensorboard/summary/writer/event_file_writer.py", line 269 in _run
  File "/home/krissatom/miniconda3/envs/n2nf/lib/python3.10/site-packages/tensorboard/summary/writer/event_file_writer.py", line 244 in run
  File "/home/krissatom/miniconda3/envs/n2nf/lib/python3.10/threading.py", line 1016 in _bootstrap_inner
  File "/home/krissatom/miniconda3/envs/n2nf/lib/python3.10/threading.py", line 973 in _bootstrap

Thread 0x00007c8baa248600 (most recent call first):
  File "/home/krissatom/miniconda3/envs/n2nf/lib/python3.10/site-packages/torch/autograd/graph.py", line 823 in _engine_run_backward
  File "/home/krissatom/miniconda3/envs/n2nf/lib/python3.10/site-packages/torch/autograd/__init__.py", line 347 in backward
  File "/home/krissatom/miniconda3/envs/n2nf/lib/python3.10/site-packages/torch/_tensor.py", line 626 in backward
  File "/home/krissatom/Noise2NoiseFlow/noise2noiseflow/train_atom.py", line 479 in train_one_epoch
  File "/home/krissatom/Noise2NoiseFlow/noise2noiseflow/train_atom.py", line 776 in run_training
  File "/home/krissatom/Noise2NoiseFlow/noise2noiseflow/train_atom.py", line 902 in main
  File "/home/krissatom/Noise2NoiseFlow/noise2noiseflow/train_atom.py", line 910 in <module>

Extension modules: mkl._mklinit, mkl._py_mkl_service, numpy._core._multiarray_umath, numpy.linalg._umath_linalg, torch._C, torch._C._dynamo.autograd_compiler, torch._C._dynamo.eval_frame, torch._C._dynamo.guards, torch._C._dynamo.utils, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, PIL._imaging, google._upb._message, scipy._lib._ccallback_c, scipy.linalg._fblas, scipy.linalg._flapack, scipy.linalg.cython_lapack, scipy.linalg._cythonized_array_utils, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, scipy.linalg._solve_toeplitz, scipy.linalg._decomp_lu_cython, scipy.linalg._matfuncs_sqrtm_triu, scipy.linalg._matfuncs_expm, scipy.linalg._linalg_pythran, scipy.linalg.cython_blas, scipy.linalg._decomp_update, scipy.sparse._sparsetools, _csparsetools, scipy.sparse._csparsetools, scipy.sparse.linalg._dsolve._superlu, scipy.sparse.linalg._eigen.arpack._arpack, scipy.sparse.linalg._propack._spropack, scipy.sparse.linalg._propack._dpropack, scipy.sparse.linalg._propack._cpropack, scipy.sparse.linalg._propack._zpropack, scipy.sparse.csgraph._tools, scipy.sparse.csgraph._shortest_path, scipy.sparse.csgraph._traversal, scipy.sparse.csgraph._min_spanning_tree, scipy.sparse.csgraph._flow, scipy.sparse.csgraph._matching, scipy.sparse.csgraph._reordering, scipy.spatial._ckdtree, scipy._lib.messagestream, scipy.spatial._qhull, scipy.spatial._voronoi, scipy.spatial._distance_wrap, scipy.spatial._hausdorff, scipy.special._ufuncs_cxx, scipy.special._ufuncs, scipy.special._specfun, scipy.special._comb, scipy.special._ellip_harm_2, scipy.spatial.transform._rotation, scipy.optimize._group_columns, scipy.optimize._trlib._trlib, scipy.optimize._lbfgsb, _moduleTNC, scipy.optimize._moduleTNC, scipy.optimize._cobyla, scipy.optimize._slsqp, scipy.optimize._minpack, scipy.optimize._lsq.givens_elimination, scipy.optimize._zeros, scipy.optimize._cython_nnls, scipy._lib._uarray._uarray, scipy.linalg._decomp_interpolative, scipy.optimize._bglu_dense, scipy.optimize._lsap, scipy.optimize._direct, scipy.integrate._odepack, scipy.integrate._quadpack, scipy.integrate._vode, scipy.integrate._dop, scipy.integrate._lsoda, scipy.interpolate._fitpack, scipy.interpolate._dfitpack, scipy.interpolate._dierckx, scipy.interpolate._ppoly, scipy.interpolate._interpnd, scipy.interpolate._rbfinterp_pythran, scipy.interpolate._rgi_cython, scipy.interpolate._bspl, scipy.special.cython_special, scipy.stats._stats, scipy.stats._sobol, scipy.stats._qmc_cy, scipy.stats._biasedurn, scipy.stats._stats_pythran, scipy.stats._levy_stable.levyst, scipy.stats._ansari_swilk_statistics, scipy.stats._mvn, scipy.stats._rcont.rcont, scipy.ndimage._nd_image, scipy.ndimage._rank_filter_1d, _ni_label, scipy.ndimage._ni_label, h5py._errors, h5py.defs, h5py._objects, h5py.h5, h5py.utils, h5py.h5t, h5py.h5s, h5py.h5ac, h5py.h5p, h5py.h5r, h5py._npystrings, h5py._proxy, h5py._conv, h5py.h5z, h5py.h5a, h5py.h5d, h5py.h5ds, h5py.h5g, h5py.h5i, h5py.h5o, h5py.h5f, h5py.h5fd, h5py.h5pl, h5py.h5l, h5py._selector, scipy.io.matlab._mio_utils, scipy.io.matlab._streams, scipy.io.matlab._mio5_utils, sklearn.__check_build._check_build, _cyutility, sklearn._cyutility, sklearn.utils._isfinite, sklearn.utils.sparsefuncs_fast, sklearn.utils.murmurhash, sklearn.utils._openmp_helpers, kiwisolver._cext (total: 145)
Segmentation fault (core dumped)
